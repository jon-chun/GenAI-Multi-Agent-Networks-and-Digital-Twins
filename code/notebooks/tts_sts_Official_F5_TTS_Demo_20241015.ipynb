{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "* https://github.com/SWivid/F5-TTS/blob/main/gradio_app.py"
      ],
      "metadata": {
        "id": "a3cf5GEAv3ux"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HPhTeIlJXe4d"
      },
      "outputs": [],
      "source": [
        "#@title Install F5-TTS and Restart Session\n",
        "\n",
        "!git clone https://github.com/SWivid/F5-TTS.git\n",
        "%cd /content/F5-TTS\n",
        "!pip install -r requirements.txt\n",
        "from IPython.display import clear_output\n",
        "clear_output()\n",
        "import time\n",
        "time.sleep(5)\n",
        "import os\n",
        "os.kill(os.getpid(), 9)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/F5-TTS\n",
        "!python gradio_app.py --share"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RUNBiTLLYN49",
        "outputId": "975b8d2f-c210-49ed-998c-18260e6da4aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/F5-TTS\n",
            "2024-10-16 00:33:56.159050: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-10-16 00:33:56.196192: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-10-16 00:33:56.206251: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-10-16 00:33:56.229009: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-10-16 00:33:57.905081: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Using cuda device\n",
            "config.json: 100% 1.26k/1.26k [00:00<00:00, 8.19MB/s]\n",
            "model.safetensors: 100% 1.62G/1.62G [00:10<00:00, 155MB/s]\n",
            "generation_config.json: 100% 3.77k/3.77k [00:00<00:00, 26.4MB/s]\n",
            "tokenizer_config.json: 100% 283k/283k [00:00<00:00, 23.1MB/s]\n",
            "vocab.json: 100% 1.04M/1.04M [00:00<00:00, 2.25MB/s]\n",
            "tokenizer.json: 100% 2.71M/2.71M [00:01<00:00, 1.67MB/s]\n",
            "merges.txt: 100% 494k/494k [00:00<00:00, 717kB/s]\n",
            "normalizer.json: 100% 52.7k/52.7k [00:00<00:00, 151MB/s]\n",
            "added_tokens.json: 100% 34.6k/34.6k [00:00<00:00, 111MB/s]\n",
            "special_tokens_map.json: 100% 2.19k/2.19k [00:00<00:00, 13.0MB/s]\n",
            "preprocessor_config.json: 100% 340/340 [00:00<00:00, 1.98MB/s]\n",
            "config.yaml: 100% 461/461 [00:00<00:00, 2.46MB/s]\n",
            "pytorch_model.bin: 100% 54.4M/54.4M [00:00<00:00, 259MB/s]\n",
            "/usr/local/lib/python3.10/dist-packages/vocos/pretrained.py:70: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  state_dict = torch.load(model_path, map_location=\"cpu\")\n",
            "model_1200000.safetensors: 100% 1.35G/1.35G [00:07<00:00, 181MB/s]\n",
            "model_1200000.safetensors: 100% 1.33G/1.33G [00:05<00:00, 261MB/s]\n",
            "/usr/local/lib/python3.10/dist-packages/gradio/analytics.py:106: UserWarning: IMPORTANT: You are using gradio version 4.44.1, however version 5.0.1 is available, please upgrade. \n",
            "--------\n",
            "  warnings.warn(\n",
            "Starting app...\n",
            "Running on local URL:  http://127.0.0.1:7860\n",
            "Running on public URL: https://cbec90c42a3e22c306.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n",
            "Four score and seven years ago our fathers brought forth on this continent, a new nation, conceived in Liberty, and dedicated to the proposition that all men are created equal.\n",
            "\n",
            "Now we are engaged in a great civil war, testing whether that nation, or any nation so conceived and so dedicated, can long endure. We are met on a great battle-field of that war. We have come to dedicate a portion of that field, as a final resting place for those who here gave their lives that that nation might live. It is altogether fitting and proper that we should do this.\n",
            "\n",
            "But, in a larger sense, we can not dedicate—we can not consecrate—we can not hallow—this ground. The brave men, living and dead, who struggled here, have consecrated it, far above our poor power to add or detract. The world will little note, nor long remember what we say here, but it can never forget what they did here. It is for us the living, rather, to be dedicated here to the unfinished work which they who fought here have thus far so nobly advanced. It is rather for us to be here dedicated to the great task remaining before us—that from these honored dead we take increased devotion to that cause for which they gave the last full measure of devotion—that we here highly resolve that these dead shall not have died in vain—that this nation, under God, shall have a new birth of freedom—and that government of the people, by the people, for the people, shall not perish from the earth.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/queueing.py\", line 536, in process_events\n",
            "    response = await route_utils.call_process_api(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/route_utils.py\", line 322, in call_process_api\n",
            "    output = await app.get_blocks().process_api(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/blocks.py\", line 1935, in process_api\n",
            "    result = await self.call_function(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/blocks.py\", line 1520, in call_function\n",
            "    prediction = await anyio.to_thread.run_sync(  # type: ignore\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/anyio/to_thread.py\", line 33, in run_sync\n",
            "    return await get_asynclib().run_sync_in_worker_thread(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/anyio/_backends/_asyncio.py\", line 877, in run_sync_in_worker_thread\n",
            "    return await future\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/anyio/_backends/_asyncio.py\", line 807, in run\n",
            "    result = context.run(func, *args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/utils.py\", line 826, in wrapper\n",
            "    response = f(*args, **kwargs)\n",
            "  File \"/content/F5-TTS/gradio_app.py\", line 258, in infer\n",
            "    aseg = AudioSegment.from_file(ref_audio_orig)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pydub/audio_segment.py\", line 723, in from_file\n",
            "    stdin_data = file.read()\n",
            "AttributeError: 'NoneType' object has no attribute 'read'\n",
            "Four score and seven years ago our fathers brought forth on this continent, a new nation, conceived in Liberty, and dedicated to the proposition that all men are created equal.\n",
            "\n",
            "Now we are engaged in a great civil war, testing whether that nation, or any nation so conceived and so dedicated, can long endure. We are met on a great battle-field of that war. We have come to dedicate a portion of that field, as a final resting place for those who here gave their lives that that nation might live. It is altogether fitting and proper that we should do this.\n",
            "\n",
            "But, in a larger sense, we can not dedicate—we can not consecrate—we can not hallow—this ground. The brave men, living and dead, who struggled here, have consecrated it, far above our poor power to add or detract. The world will little note, nor long remember what we say here, but it can never forget what they did here. It is for us the living, rather, to be dedicated here to the unfinished work which they who fought here have thus far so nobly advanced. It is rather for us to be here dedicated to the great task remaining before us—that from these honored dead we take increased devotion to that cause for which they gave the last full measure of devotion—that we here highly resolve that these dead shall not have died in vain—that this nation, under God, shall have a new birth of freedom—and that government of the people, by the people, for the people, shall not perish from the earth.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/queueing.py\", line 536, in process_events\n",
            "    response = await route_utils.call_process_api(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/route_utils.py\", line 322, in call_process_api\n",
            "    output = await app.get_blocks().process_api(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/blocks.py\", line 1935, in process_api\n",
            "    result = await self.call_function(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/blocks.py\", line 1520, in call_function\n",
            "    prediction = await anyio.to_thread.run_sync(  # type: ignore\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/anyio/to_thread.py\", line 33, in run_sync\n",
            "    return await get_asynclib().run_sync_in_worker_thread(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/anyio/_backends/_asyncio.py\", line 877, in run_sync_in_worker_thread\n",
            "    return await future\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/anyio/_backends/_asyncio.py\", line 807, in run\n",
            "    result = context.run(func, *args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/utils.py\", line 826, in wrapper\n",
            "    response = f(*args, **kwargs)\n",
            "  File \"/content/F5-TTS/gradio_app.py\", line 258, in infer\n",
            "    aseg = AudioSegment.from_file(ref_audio_orig)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pydub/audio_segment.py\", line 723, in from_file\n",
            "    stdin_data = file.read()\n",
            "AttributeError: 'NoneType' object has no attribute 'read'\n",
            "Four score and seven years ago our fathers brought forth on this continent, a new nation, conceived in Liberty, and dedicated to the proposition that all men are created equal.\n",
            "\n",
            "Now we are engaged in a great civil war, testing whether that nation, or any nation so conceived and so dedicated, can long endure. We are met on a great battle-field of that war. We have come to dedicate a portion of that field, as a final resting place for those who here gave their lives that that nation might live. It is altogether fitting and proper that we should do this.\n",
            "\n",
            "But, in a larger sense, we can not dedicate—we can not consecrate—we can not hallow—this ground. The brave men, living and dead, who struggled here, have consecrated it, far above our poor power to add or detract. The world will little note, nor long remember what we say here, but it can never forget what they did here. It is for us the living, rather, to be dedicated here to the unfinished work which they who fought here have thus far so nobly advanced. It is rather for us to be here dedicated to the great task remaining before us—that from these honored dead we take increased devotion to that cause for which they gave the last full measure of devotion—that we here highly resolve that these dead shall not have died in vain—that this nation, under God, shall have a new birth of freedom—and that government of the people, by the people, for the people, shall not perish from the earth.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
            "  warnings.warn(\n",
            "You have passed task=transcribe, but also have set `forced_decoder_ids` to [[1, None], [2, 50360]] which creates a conflict. `forced_decoder_ids` will be ignored in favor of task=transcribe.\n",
            "Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.43.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n",
            "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "ref_text Some call me nature. Others call me Mother Nature. \n",
            "gen_text 0 Four score and seven years ago our fathers brought forth on this continent, a new nation, conceived in Liberty, and dedicated to the proposition that all men are created equal.\n",
            "gen_text 1 Now we are engaged in a great civil war, testing whether that nation, or any nation so conceived and so dedicated, can long endure. We are met on a great battle-field of that war.\n",
            "gen_text 2 We have come to dedicate a portion of that field, as a final resting place for those who here gave their lives that that nation might live.\n",
            "gen_text 3 It is altogether fitting and proper that we should do this. But, in a larger sense, we can not dedicate—we can not consecrate—we can not hallow—this ground. The brave men,\n",
            "gen_text 4 living and dead, who struggled here, have consecrated it, far above our poor power to add or detract. The world will little note, nor long remember what we say here,\n",
            "gen_text 5 but it can never forget what they did here. It is for us the living, rather, to be dedicated here to the unfinished work which they who fought here have thus far so nobly advanced.\n",
            "gen_text 6 It is rather for us to be here dedicated to the great task remaining before us—that from these honored dead we take increased devotion to that cause for which they gave the last full measure of devotion—that we here highly resolve that these dead shall not have died in vain—that this nation,\n",
            "gen_text 7 under God, shall have a new birth of freedom—and that government of the people, by the people, for the people, shall not perish from the earth.\n",
            "Building prefix dict from the default dictionary ...\n",
            "Dumping model to file cache /tmp/jieba.cache\n",
            "Loading model cost 0.738 seconds.\n",
            "Prefix dict has been built successfully.\n",
            "/usr/local/lib/python3.10/dist-packages/gradio/processing_utils.py:574: UserWarning: Trying to convert audio automatically from float64 to 16-bit int format.\n",
            "  warnings.warn(warning.format(data.dtype))\n",
            "Four score and seven years ago our fathers brought forth on this continent, a new nation, conceived in Liberty, and dedicated to the proposition that all men are created equal.\n",
            "\n",
            "Now we are engaged in a great civil war, testing whether that nation, or any nation so conceived and so dedicated, can long endure. We are met on a great battle-field of that war. We have come to dedicate a portion of that field, as a final resting place for those who here gave their lives that that nation might live. It is altogether fitting and proper that we should do this.\n",
            "\n",
            "But, in a larger sense, we can not dedicate—we can not consecrate—we can not hallow—this ground. The brave men, living and dead, who struggled here, have consecrated it, far above our poor power to add or detract. The world will little note, nor long remember what we say here, but it can never forget what they did here. It is for us the living, rather, to be dedicated here to the unfinished work which they who fought here have thus far so nobly advanced. It is rather for us to be here dedicated to the great task remaining before us—that from these honored dead we take increased devotion to that cause for which they gave the last full measure of devotion—that we here highly resolve that these dead shall not have died in vain—that this nation, under God, shall have a new birth of freedom—and that government of the people, by the people, for the people, shall not perish from the earth.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
            "  warnings.warn(\n",
            "ref_text Ezekiel 25, 17. The path of the righteous man is beset on all sides by the inequities of the selfish and the tyranny of evil men. Blessed is he. \n",
            "gen_text 0 Four score and seven years ago our fathers brought forth on this continent, a new nation,\n",
            "gen_text 1 conceived in Liberty, and dedicated to the proposition that all men are created equal.\n",
            "gen_text 2 Now we are engaged in a great civil war, testing whether that nation,\n",
            "gen_text 3 or any nation so conceived and so dedicated, can long endure.\n",
            "gen_text 4 We are met on a great battle-field of that war.\n",
            "gen_text 5 We have come to dedicate a portion of that field,\n",
            "gen_text 6 as a final resting place for those who here gave their lives that that nation might live.\n",
            "gen_text 7 It is altogether fitting and proper that we should do this. But, in a larger sense,\n",
            "gen_text 8 we can not dedicate—we can not consecrate—we can not hallow—this ground. The brave men,\n",
            "gen_text 9 living and dead, who struggled here, have consecrated it,\n",
            "gen_text 10 far above our poor power to add or detract. The world will little note,\n",
            "gen_text 11 nor long remember what we say here, but it can never forget what they did here.\n",
            "gen_text 12 It is for us the living, rather,\n",
            "gen_text 13 to be dedicated here to the unfinished work which they who fought here have thus far so nobly advanced.\n",
            "gen_text 14 It is rather for us to be here dedicated to the great task remaining before us—that from these honored dead we take increased devotion to that cause for which they gave the last full measure of devotion—that we here highly resolve that these dead shall not have died in vain—that this nation,\n",
            "gen_text 15 under God, shall have a new birth of freedom—and that government of the people, by the people,\n",
            "gen_text 16 for the people, shall not perish from the earth.\n",
            "/usr/local/lib/python3.10/dist-packages/gradio/processing_utils.py:574: UserWarning: Trying to convert audio automatically from float64 to 16-bit int format.\n",
            "  warnings.warn(warning.format(data.dtype))\n",
            "My name is Elle Woods, and for my admissions essay, I’m gonna tell all of you at Harvard why I’m gonna make an amazing lawyer.\n",
            "\n",
            "As president of my sorority, I’m skilled at commanding the attention of a room, and discussing very important issues.\n",
            "\n",
            "It has come to my attention that the maintenance staff is switching our toilet paper from Charmin to generic.\n",
            "\n",
            "All those opposed to chafing, say “aye Aye'\n",
            "\n",
            "I'm able to recall hundreds of important details at the drop of a hat.\n",
            "\n",
            "Hey, Elle, do you know what happened on Days of Our Lives yesterday?\n",
            "\n",
            "Why yes, Margot, I do.\n",
            "\n",
            "Once again, we joined Hope in the search for her identity.\n",
            "\n",
            "She's been brainwashed by the evil Stefano.\n",
            "\n",
            "Three... Get set, and go!\n",
            "\n",
            "I feel comfortable using legal jargon in everyday life.\n",
            "\n",
            "I object!\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
            "  warnings.warn(\n",
            "ref_text When a mighty empire embarks upon the ultimate conquest, every weapon is powerless against it and every army faces defeat. When a mighty empire,. \n",
            "gen_text 0 My name is Elle Woods, and for my admissions essay,\n",
            "gen_text 1 I’m gonna tell all of you at Harvard why I’m gonna make an amazing lawyer.\n",
            "gen_text 2 As president of my sorority, I’m skilled at commanding the attention of a room,\n",
            "gen_text 3 and discussing very important issues.\n",
            "gen_text 4 It has come to my attention that the maintenance staff is switching our toilet paper from Charmin to generic.\n",
            "gen_text 5 All those opposed to chafing,\n",
            "gen_text 6 say “aye Aye'\n",
            "\n",
            "I'm able to recall hundreds of important details at the drop of a hat. Hey,\n",
            "gen_text 7 Elle, do you know what happened on Days of Our Lives yesterday? Why yes, Margot, I do.\n",
            "gen_text 8 Once again, we joined Hope in the search for her identity.\n",
            "gen_text 9 She's been brainwashed by the evil Stefano. Three... Get set, and go!\n",
            "gen_text 10 I feel comfortable using legal jargon in everyday life. I object!\n",
            "/usr/local/lib/python3.10/dist-packages/gradio/processing_utils.py:574: UserWarning: Trying to convert audio automatically from float64 to 16-bit int format.\n",
            "  warnings.warn(warning.format(data.dtype))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "v8xbudf-Xqpa"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}