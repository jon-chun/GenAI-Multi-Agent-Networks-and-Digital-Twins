{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "* https://github.com/h2oai/h2ogpt\n",
        "\n",
        "Modified: 2 Oct 2024, Jon Chun"
      ],
      "metadata": {
        "id": "Ex_z1UQLkNNV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Document Question-Answer [h2oGPT](https://github.com/h2oai/h2ogpt)\n",
        "\n",
        "In this notebook, we demonstrate how one can use h2oGPT with a large language model.\n",
        "\n",
        "To begin, please get free ngrok account to get auth token (e.g.) using your Google email/login and get token: https://dashboard.ngrok.com/get-started/setup .  You will be asked for this token below in an input box."
      ],
      "metadata": {
        "id": "a5WqLjn4-chc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "# NOTE: 21s\n",
        "\n",
        "!git clone https://github.com/h2oai/h2ogpt.git\n",
        "!cd h2ogpt && git checkout 2668694581347b0d1afe76760213db46f7214126 -q\n",
        "!cp -ar h2ogpt/. ./\n",
        "!rm -r h2ogpt"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-19T05:04:22.652611Z",
          "iopub.execute_input": "2023-04-19T05:04:22.653611Z",
          "iopub.status.idle": "2023-04-19T05:04:28.381885Z",
          "shell.execute_reply.started": "2023-04-19T05:04:22.653556Z",
          "shell.execute_reply": "2023-04-19T05:04:28.380315Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CD1TvqW8-che",
        "outputId": "9f636fab-70cb-4084-a9f3-5b5e78794c9c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'h2ogpt'...\n",
            "remote: Enumerating objects: 40043, done.\u001b[K\n",
            "remote: Counting objects: 100% (1512/1512), done.\u001b[K\n",
            "remote: Compressing objects: 100% (552/552), done.\u001b[K\n",
            "remote: Total 40043 (delta 1000), reused 1295 (delta 960), pack-reused 38531 (from 1)\u001b[K\n",
            "Receiving objects: 100% (40043/40043), 53.13 MiB | 4.58 MiB/s, done.\n",
            "Resolving deltas: 100% (28402/28402), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "# NOTE: 32s\n",
        "\n",
        "# Install pyhon 3.10 that will be used within pipenv\n",
        "!sudo add-apt-repository ppa:deadsnakes/ppa -y > /dev/null\n",
        "!sudo apt install python3.10 python3.10-distutils psmisc -y > /dev/null\n",
        "!curl -sS https://bootstrap.pypa.io/get-pip.py | python3.10 > /dev/null"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-19T05:04:36.253404Z",
          "iopub.execute_input": "2023-04-19T05:04:36.254498Z",
          "iopub.status.idle": "2023-04-19T05:09:08.846475Z",
          "shell.execute_reply.started": "2023-04-19T05:04:36.254436Z",
          "shell.execute_reply": "2023-04-19T05:09:08.844973Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YWdHujUB-chf",
        "outputId": "05faef37-e38a-4a08-81c0-b0915e1969d1"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "\n",
            "WARNING: apt does not have a stable CLI interface. Use with caution in scripts.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "# NOTE:\n",
        "\n",
        "# Install dependencies\n",
        "!for fil in requirements.txt reqs_optional/requirements_optional_langchain.txt reqs_optional/requirements_optional_gpt4all.txt reqs_optional/requirements_optional_langchain.gpllike.txt reqs_optional/requirements_optional_langchain.urls.txt ; do pip install -r $fil ; done\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RGWAnUt2sA-V",
        "outputId": "fc5000ef-7ebe-40fe-a072-02126d9f7b9e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/huggingface/peft.git@0b62b4378b4ce9367932c73540349da9a41bdea8 (from -r requirements.txt (line 22))\n",
            "  Cloning https://github.com/huggingface/peft.git (to revision 0b62b4378b4ce9367932c73540349da9a41bdea8) to /tmp/pip-req-build-m0y_k1gi\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/peft.git /tmp/pip-req-build-m0y_k1gi\n",
            "  Running command git rev-parse -q --verify 'sha^0b62b4378b4ce9367932c73540349da9a41bdea8'\n",
            "  Running command git fetch -q https://github.com/huggingface/peft.git 0b62b4378b4ce9367932c73540349da9a41bdea8\n",
            "  Running command git checkout -q 0b62b4378b4ce9367932c73540349da9a41bdea8\n",
            "  Resolved https://github.com/huggingface/peft.git to commit 0b62b4378b4ce9367932c73540349da9a41bdea8\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Ignoring pypandoc: markers 'sys_platform == \"darwin\" and platform_machine == \"arm64\"' don't match your environment\n",
            "Collecting datasets==2.13.0 (from -r requirements.txt (line 2))\n",
            "  Downloading datasets-2.13.0-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting sentencepiece==0.1.99 (from -r requirements.txt (line 3))\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
            "Collecting gradio==3.35.2 (from -r requirements.txt (line 4))\n",
            "  Downloading gradio-3.35.2-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting huggingface_hub==0.15.1 (from -r requirements.txt (line 5))\n",
            "  Downloading huggingface_hub-0.15.1-py3-none-any.whl.metadata (8.0 kB)\n",
            "Collecting appdirs==1.4.4 (from -r requirements.txt (line 6))\n",
            "  Downloading appdirs-1.4.4-py2.py3-none-any.whl.metadata (9.0 kB)\n",
            "Collecting fire==0.5.0 (from -r requirements.txt (line 7))\n",
            "  Downloading fire-0.5.0.tar.gz (88 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting docutils==0.20.1 (from -r requirements.txt (line 8))\n",
            "  Downloading docutils-0.20.1-py3-none-any.whl.metadata (2.8 kB)\n",
            "Collecting torch==2.0.1 (from -r requirements.txt (line 9))\n",
            "  Downloading torch-2.0.1-cp310-cp310-manylinux1_x86_64.whl.metadata (24 kB)\n",
            "Collecting evaluate==0.4.0 (from -r requirements.txt (line 10))\n",
            "  Downloading evaluate-0.4.0-py3-none-any.whl.metadata (9.4 kB)\n",
            "Collecting rouge_score==0.1.2 (from -r requirements.txt (line 11))\n",
            "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting sacrebleu==2.3.1 (from -r requirements.txt (line 12))\n",
            "  Downloading sacrebleu-2.3.1-py3-none-any.whl.metadata (57 kB)\n",
            "Collecting scikit-learn==1.2.2 (from -r requirements.txt (line 13))\n",
            "  Downloading scikit_learn-1.2.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Collecting alt-profanity-check==1.2.2 (from -r requirements.txt (line 14))\n",
            "  Downloading alt-profanity-check-1.2.2.tar.gz (1.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m29.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting better-profanity==0.7.0 (from -r requirements.txt (line 15))\n",
            "  Downloading better_profanity-0.7.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting numpy==1.24.3 (from -r requirements.txt (line 16))\n",
            "  Downloading numpy-1.24.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)\n",
            "Collecting pandas==2.0.2 (from -r requirements.txt (line 17))\n",
            "  Downloading pandas-2.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
            "Requirement already satisfied: matplotlib==3.7.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 18)) (3.7.1)\n",
            "Collecting loralib==0.1.1 (from -r requirements.txt (line 19))\n",
            "  Downloading loralib-0.1.1-py3-none-any.whl.metadata (14 kB)\n",
            "Collecting bitsandbytes==0.39.0 (from -r requirements.txt (line 20))\n",
            "  Downloading bitsandbytes-0.39.0-py3-none-any.whl.metadata (9.8 kB)\n",
            "Collecting accelerate==0.20.3 (from -r requirements.txt (line 21))\n",
            "  Downloading accelerate-0.20.3-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting transformers==4.30.2 (from -r requirements.txt (line 23))\n",
            "  Downloading transformers-4.30.2-py3-none-any.whl.metadata (113 kB)\n",
            "Collecting tokenizers==0.13.3 (from -r requirements.txt (line 24))\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Collecting APScheduler==3.10.1 (from -r requirements.txt (line 25))\n",
            "  Downloading APScheduler-3.10.1-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting pynvml==11.5.0 (from -r requirements.txt (line 28))\n",
            "  Downloading pynvml-11.5.0-py3-none-any.whl.metadata (7.8 kB)\n",
            "Requirement already satisfied: psutil==5.9.5 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 29)) (5.9.5)\n",
            "Collecting boto3==1.26.101 (from -r requirements.txt (line 30))\n",
            "  Downloading boto3-1.26.101-py3-none-any.whl.metadata (7.0 kB)\n",
            "Collecting botocore==1.29.101 (from -r requirements.txt (line 31))\n",
            "  Downloading botocore-1.29.101-py3-none-any.whl.metadata (5.9 kB)\n",
            "Collecting tensorboard==2.13.0 (from -r requirements.txt (line 34))\n",
            "  Downloading tensorboard-2.13.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting neptune==1.2.0 (from -r requirements.txt (line 35))\n",
            "  Downloading neptune-1.2.0-py3-none-any.whl.metadata (18 kB)\n",
            "Collecting gradio_client==0.2.7 (from -r requirements.txt (line 38))\n",
            "  Downloading gradio_client-0.2.7-py3-none-any.whl.metadata (7.0 kB)\n",
            "Collecting beautifulsoup4==4.12.2 (from -r requirements.txt (line 39))\n",
            "  Downloading beautifulsoup4-4.12.2-py3-none-any.whl.metadata (3.6 kB)\n",
            "Collecting markdown==3.4.3 (from -r requirements.txt (line 40))\n",
            "  Downloading Markdown-3.4.3-py3-none-any.whl.metadata (6.7 kB)\n",
            "Collecting pytest==7.2.2 (from -r requirements.txt (line 43))\n",
            "  Downloading pytest-7.2.2-py3-none-any.whl.metadata (7.8 kB)\n",
            "Collecting pytest-xdist==3.2.1 (from -r requirements.txt (line 44))\n",
            "  Downloading pytest_xdist-3.2.1-py3-none-any.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: nltk==3.8.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 45)) (3.8.1)\n",
            "Collecting textstat==0.7.3 (from -r requirements.txt (line 46))\n",
            "  Downloading textstat-0.7.3-py3-none-any.whl.metadata (14 kB)\n",
            "Collecting pypandoc_binary==1.11 (from -r requirements.txt (line 49))\n",
            "  Downloading pypandoc_binary-1.11-py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\n",
            "Collecting openpyxl==3.1.2 (from -r requirements.txt (line 50))\n",
            "  Downloading openpyxl-3.1.2-py2.py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting lm_dataformat==0.0.20 (from -r requirements.txt (line 51))\n",
            "  Downloading lm_dataformat-0.0.20-py3-none-any.whl.metadata (1.2 kB)\n",
            "Collecting bioc==2.0 (from -r requirements.txt (line 52))\n",
            "  Downloading bioc-2.0-py3-none-any.whl.metadata (5.0 kB)\n",
            "Collecting einops==0.6.1 (from -r requirements.txt (line 55))\n",
            "  Downloading einops-0.6.1-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting instructorembedding==1.0.1 (from -r requirements.txt (line 56))\n",
            "  Downloading InstructorEmbedding-1.0.1-py2.py3-none-any.whl.metadata (20 kB)\n",
            "Collecting python-dotenv==1.0.0 (from -r requirements.txt (line 59))\n",
            "  Downloading python_dotenv-1.0.0-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting text-generation==0.6.0 (from -r requirements.txt (line 61))\n",
            "  Downloading text_generation-0.6.0-py3-none-any.whl.metadata (7.5 kB)\n",
            "Collecting tiktoken==0.4.0 (from -r requirements.txt (line 63))\n",
            "  Downloading tiktoken-0.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.2 kB)\n",
            "Collecting openai==0.27.8 (from -r requirements.txt (line 65))\n",
            "  Downloading openai-0.27.8-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets==2.13.0->-r requirements.txt (line 2)) (16.1.0)\n",
            "Collecting dill<0.3.7,>=0.3.0 (from datasets==2.13.0->-r requirements.txt (line 2))\n",
            "  Downloading dill-0.3.6-py3-none-any.whl.metadata (9.8 kB)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets==2.13.0->-r requirements.txt (line 2)) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets==2.13.0->-r requirements.txt (line 2)) (4.66.5)\n",
            "Collecting xxhash (from datasets==2.13.0->-r requirements.txt (line 2))\n",
            "  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess (from datasets==2.13.0->-r requirements.txt (line 2))\n",
            "  Downloading multiprocess-0.70.17-py310-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: fsspec>=2021.11.1 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2021.11.1->datasets==2.13.0->-r requirements.txt (line 2)) (2024.6.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets==2.13.0->-r requirements.txt (line 2)) (3.10.6)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets==2.13.0->-r requirements.txt (line 2)) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets==2.13.0->-r requirements.txt (line 2)) (6.0.2)\n",
            "Collecting aiofiles (from gradio==3.35.2->-r requirements.txt (line 4))\n",
            "  Downloading aiofiles-24.1.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: altair>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.35.2->-r requirements.txt (line 4)) (4.2.2)\n",
            "Collecting fastapi (from gradio==3.35.2->-r requirements.txt (line 4))\n",
            "  Downloading fastapi-0.115.0-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting ffmpy (from gradio==3.35.2->-r requirements.txt (line 4))\n",
            "  Downloading ffmpy-0.4.0-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting httpx (from gradio==3.35.2->-r requirements.txt (line 4))\n",
            "  Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from gradio==3.35.2->-r requirements.txt (line 4)) (3.1.4)\n",
            "Requirement already satisfied: markdown-it-py>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py[linkify]>=2.0.0->gradio==3.35.2->-r requirements.txt (line 4)) (3.0.0)\n",
            "Requirement already satisfied: markupsafe in /usr/local/lib/python3.10/dist-packages (from gradio==3.35.2->-r requirements.txt (line 4)) (2.1.5)\n",
            "Collecting mdit-py-plugins<=0.3.3 (from gradio==3.35.2->-r requirements.txt (line 4))\n",
            "  Downloading mdit_py_plugins-0.3.3-py3-none-any.whl.metadata (2.8 kB)\n",
            "Collecting orjson (from gradio==3.35.2->-r requirements.txt (line 4))\n",
            "  Downloading orjson-3.10.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (50 kB)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from gradio==3.35.2->-r requirements.txt (line 4)) (10.4.0)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.10/dist-packages (from gradio==3.35.2->-r requirements.txt (line 4)) (2.9.2)\n",
            "Collecting pydub (from gradio==3.35.2->-r requirements.txt (line 4))\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: pygments>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.35.2->-r requirements.txt (line 4)) (2.18.0)\n",
            "Collecting python-multipart (from gradio==3.35.2->-r requirements.txt (line 4))\n",
            "  Downloading python_multipart-0.0.12-py3-none-any.whl.metadata (1.9 kB)\n",
            "Collecting semantic-version (from gradio==3.35.2->-r requirements.txt (line 4))\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting uvicorn>=0.14.0 (from gradio==3.35.2->-r requirements.txt (line 4))\n",
            "  Downloading uvicorn-0.31.0-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting websockets>=10.0 (from gradio==3.35.2->-r requirements.txt (line 4))\n",
            "  Downloading websockets-13.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub==0.15.1->-r requirements.txt (line 5)) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub==0.15.1->-r requirements.txt (line 5)) (4.12.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from fire==0.5.0->-r requirements.txt (line 7)) (1.16.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from fire==0.5.0->-r requirements.txt (line 7)) (2.4.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->-r requirements.txt (line 9)) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->-r requirements.txt (line 9)) (3.3)\n",
            "Collecting nvidia-cuda-nvrtc-cu11==11.7.99 (from torch==2.0.1->-r requirements.txt (line 9))\n",
            "  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu11==11.7.99 (from torch==2.0.1->-r requirements.txt (line 9))\n",
            "  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cuda-cupti-cu11==11.7.101 (from torch==2.0.1->-r requirements.txt (line 9))\n",
            "  Downloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu11==8.5.0.96 (from torch==2.0.1->-r requirements.txt (line 9))\n",
            "  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu11==11.10.3.66 (from torch==2.0.1->-r requirements.txt (line 9))\n",
            "  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cufft-cu11==10.9.0.58 (from torch==2.0.1->-r requirements.txt (line 9))\n",
            "  Downloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu11==10.2.10.91 (from torch==2.0.1->-r requirements.txt (line 9))\n",
            "  Downloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusolver-cu11==11.4.0.1 (from torch==2.0.1->-r requirements.txt (line 9))\n",
            "  Downloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu11==11.7.4.91 (from torch==2.0.1->-r requirements.txt (line 9))\n",
            "  Downloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu11==2.14.3 (from torch==2.0.1->-r requirements.txt (line 9))\n",
            "  Downloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu11==11.7.91 (from torch==2.0.1->-r requirements.txt (line 9))\n",
            "  Downloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting triton==2.0.0 (from torch==2.0.1->-r requirements.txt (line 9))\n",
            "  Downloading triton-2.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.0 kB)\n",
            "Collecting responses<0.19 (from evaluate==0.4.0->-r requirements.txt (line 10))\n",
            "  Downloading responses-0.18.0-py3-none-any.whl.metadata (29 kB)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from rouge_score==0.1.2->-r requirements.txt (line 11)) (1.4.0)\n",
            "Collecting portalocker (from sacrebleu==2.3.1->-r requirements.txt (line 12))\n",
            "  Downloading portalocker-2.10.1-py3-none-any.whl.metadata (8.5 kB)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from sacrebleu==2.3.1->-r requirements.txt (line 12)) (2024.9.11)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu==2.3.1->-r requirements.txt (line 12)) (0.9.0)\n",
            "Collecting colorama (from sacrebleu==2.3.1->-r requirements.txt (line 12))\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from sacrebleu==2.3.1->-r requirements.txt (line 12)) (4.9.4)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.2.2->-r requirements.txt (line 13)) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.2.2->-r requirements.txt (line 13)) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.2.2->-r requirements.txt (line 13)) (3.5.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas==2.0.2->-r requirements.txt (line 17)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas==2.0.2->-r requirements.txt (line 17)) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas==2.0.2->-r requirements.txt (line 17)) (2024.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.7.1->-r requirements.txt (line 18)) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.7.1->-r requirements.txt (line 18)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.7.1->-r requirements.txt (line 18)) (4.54.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.7.1->-r requirements.txt (line 18)) (1.4.7)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.7.1->-r requirements.txt (line 18)) (3.1.4)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.30.2->-r requirements.txt (line 23)) (0.4.5)\n",
            "Requirement already satisfied: setuptools>=0.7 in /usr/local/lib/python3.10/dist-packages (from APScheduler==3.10.1->-r requirements.txt (line 25)) (71.0.4)\n",
            "Requirement already satisfied: tzlocal!=3.*,>=2.0 in /usr/local/lib/python3.10/dist-packages (from APScheduler==3.10.1->-r requirements.txt (line 25)) (5.2)\n",
            "Collecting jmespath<2.0.0,>=0.7.1 (from boto3==1.26.101->-r requirements.txt (line 30))\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
            "Collecting s3transfer<0.7.0,>=0.6.0 (from boto3==1.26.101->-r requirements.txt (line 30))\n",
            "  Downloading s3transfer-0.6.2-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting urllib3<1.27,>=1.25.4 (from botocore==1.29.101->-r requirements.txt (line 31))\n",
            "  Downloading urllib3-1.26.20-py2.py3-none-any.whl.metadata (50 kB)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard==2.13.0->-r requirements.txt (line 34)) (1.64.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard==2.13.0->-r requirements.txt (line 34)) (2.27.0)\n",
            "Collecting google-auth-oauthlib<1.1,>=0.5 (from tensorboard==2.13.0->-r requirements.txt (line 34))\n",
            "  Downloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: protobuf>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard==2.13.0->-r requirements.txt (line 34)) (3.20.3)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard==2.13.0->-r requirements.txt (line 34)) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard==2.13.0->-r requirements.txt (line 34)) (3.0.4)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.10/dist-packages (from tensorboard==2.13.0->-r requirements.txt (line 34)) (0.44.0)\n",
            "Collecting GitPython>=2.0.8 (from neptune==1.2.0->-r requirements.txt (line 35))\n",
            "  Downloading GitPython-3.1.43-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: PyJWT in /usr/local/lib/python3.10/dist-packages (from neptune==1.2.0->-r requirements.txt (line 35)) (2.9.0)\n",
            "Collecting bravado<12.0.0,>=11.0.0 (from neptune==1.2.0->-r requirements.txt (line 35))\n",
            "  Downloading bravado-11.0.3-py2.py3-none-any.whl.metadata (5.9 kB)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from neptune==1.2.0->-r requirements.txt (line 35)) (8.1.7)\n",
            "Requirement already satisfied: future>=0.17.1 in /usr/local/lib/python3.10/dist-packages (from neptune==1.2.0->-r requirements.txt (line 35)) (1.0.0)\n",
            "Requirement already satisfied: oauthlib>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from neptune==1.2.0->-r requirements.txt (line 35)) (3.2.2)\n",
            "Requirement already satisfied: requests-oauthlib>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from neptune==1.2.0->-r requirements.txt (line 35)) (1.3.1)\n",
            "Collecting swagger-spec-validator>=2.7.4 (from neptune==1.2.0->-r requirements.txt (line 35))\n",
            "  Downloading swagger_spec_validator-3.0.4-py2.py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: websocket-client!=1.0.0,>=0.35.0 in /usr/local/lib/python3.10/dist-packages (from neptune==1.2.0->-r requirements.txt (line 35)) (1.8.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4==4.12.2->-r requirements.txt (line 39)) (2.6)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.10/dist-packages (from pytest==7.2.2->-r requirements.txt (line 43)) (24.2.0)\n",
            "Requirement already satisfied: iniconfig in /usr/local/lib/python3.10/dist-packages (from pytest==7.2.2->-r requirements.txt (line 43)) (2.0.0)\n",
            "Requirement already satisfied: pluggy<2.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from pytest==7.2.2->-r requirements.txt (line 43)) (1.5.0)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.0rc8 in /usr/local/lib/python3.10/dist-packages (from pytest==7.2.2->-r requirements.txt (line 43)) (1.2.2)\n",
            "Requirement already satisfied: tomli>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from pytest==7.2.2->-r requirements.txt (line 43)) (2.0.1)\n",
            "Collecting execnet>=1.1 (from pytest-xdist==3.2.1->-r requirements.txt (line 44))\n",
            "  Downloading execnet-2.1.1-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting pyphen (from textstat==0.7.3->-r requirements.txt (line 46))\n",
            "  Downloading pyphen-0.16.0-py3-none-any.whl.metadata (3.2 kB)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.10/dist-packages (from openpyxl==3.1.2->-r requirements.txt (line 50)) (1.1.0)\n",
            "Collecting jsonlines (from lm_dataformat==0.0.20->-r requirements.txt (line 51))\n",
            "  Downloading jsonlines-4.0.0-py3-none-any.whl.metadata (1.6 kB)\n",
            "Collecting ujson (from lm_dataformat==0.0.20->-r requirements.txt (line 51))\n",
            "  Downloading ujson-5.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.3 kB)\n",
            "Collecting zstandard (from lm_dataformat==0.0.20->-r requirements.txt (line 51))\n",
            "  Downloading zstandard-0.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
            "Collecting intervaltree (from bioc==2.0->-r requirements.txt (line 52))\n",
            "  Downloading intervaltree-3.1.0.tar.gz (32 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pydantic (from gradio==3.35.2->-r requirements.txt (line 4))\n",
            "  Downloading pydantic-1.10.18-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (152 kB)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.1->-r requirements.txt (line 9)) (3.30.3)\n",
            "Collecting lit (from triton==2.0.0->torch==2.0.1->-r requirements.txt (line 9))\n",
            "  Downloading lit-18.1.8-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.13.0->-r requirements.txt (line 2)) (2.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.13.0->-r requirements.txt (line 2)) (1.3.1)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.13.0->-r requirements.txt (line 2)) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.13.0->-r requirements.txt (line 2)) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.13.0->-r requirements.txt (line 2)) (1.12.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.13.0->-r requirements.txt (line 2)) (4.0.3)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair>=4.2.0->gradio==3.35.2->-r requirements.txt (line 4)) (0.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair>=4.2.0->gradio==3.35.2->-r requirements.txt (line 4)) (4.23.0)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair>=4.2.0->gradio==3.35.2->-r requirements.txt (line 4)) (0.12.1)\n",
            "Collecting bravado-core>=5.16.1 (from bravado<12.0.0,>=11.0.0->neptune==1.2.0->-r requirements.txt (line 35))\n",
            "  Downloading bravado-core-6.1.1.tar.gz (63 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: msgpack in /usr/local/lib/python3.10/dist-packages (from bravado<12.0.0,>=11.0.0->neptune==1.2.0->-r requirements.txt (line 35)) (1.0.8)\n",
            "Collecting simplejson (from bravado<12.0.0,>=11.0.0->neptune==1.2.0->-r requirements.txt (line 35))\n",
            "  Downloading simplejson-3.19.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.2 kB)\n",
            "Collecting monotonic (from bravado<12.0.0,>=11.0.0->neptune==1.2.0->-r requirements.txt (line 35))\n",
            "  Downloading monotonic-1.6-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting gitdb<5,>=4.0.1 (from GitPython>=2.0.8->neptune==1.2.0->-r requirements.txt (line 35))\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard==2.13.0->-r requirements.txt (line 34)) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard==2.13.0->-r requirements.txt (line 34)) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard==2.13.0->-r requirements.txt (line 34)) (4.9)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.0.0->markdown-it-py[linkify]>=2.0.0->gradio==3.35.2->-r requirements.txt (line 4)) (0.1.2)\n",
            "Requirement already satisfied: linkify-it-py<3,>=1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py[linkify]>=2.0.0->gradio==3.35.2->-r requirements.txt (line 4)) (2.0.3)\n",
            "INFO: pip is looking at multiple versions of mdit-py-plugins to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting mdit-py-plugins<=0.3.3 (from gradio==3.35.2->-r requirements.txt (line 4))\n",
            "  Downloading mdit_py_plugins-0.3.2-py3-none-any.whl.metadata (2.8 kB)\n",
            "  Downloading mdit_py_plugins-0.3.1-py3-none-any.whl.metadata (2.8 kB)\n",
            "  Downloading mdit_py_plugins-0.3.0-py3-none-any.whl.metadata (2.8 kB)\n",
            "  Downloading mdit_py_plugins-0.2.8-py3-none-any.whl.metadata (2.8 kB)\n",
            "  Downloading mdit_py_plugins-0.2.7-py3-none-any.whl.metadata (2.8 kB)\n",
            "  Downloading mdit_py_plugins-0.2.6-py3-none-any.whl.metadata (2.6 kB)\n",
            "  Downloading mdit_py_plugins-0.2.5-py3-none-any.whl.metadata (2.6 kB)\n",
            "INFO: pip is still looking at multiple versions of mdit-py-plugins to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading mdit_py_plugins-0.2.4-py3-none-any.whl.metadata (2.6 kB)\n",
            "  Downloading mdit_py_plugins-0.2.3-py3-none-any.whl.metadata (2.6 kB)\n",
            "  Downloading mdit_py_plugins-0.2.2-py3-none-any.whl.metadata (2.6 kB)\n",
            "  Downloading mdit_py_plugins-0.2.1-py3-none-any.whl.metadata (2.6 kB)\n",
            "  Downloading mdit_py_plugins-0.2.0-py3-none-any.whl.metadata (2.6 kB)\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
            "  Downloading mdit_py_plugins-0.1.0-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting markdown-it-py[linkify]>=2.0.0 (from gradio==3.35.2->-r requirements.txt (line 4))\n",
            "  Using cached markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
            "  Downloading markdown_it_py-2.2.0-py3-none-any.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets==2.13.0->-r requirements.txt (line 2)) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets==2.13.0->-r requirements.txt (line 2)) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets==2.13.0->-r requirements.txt (line 2)) (2024.8.30)\n",
            "Requirement already satisfied: importlib-resources>=1.3 in /usr/local/lib/python3.10/dist-packages (from swagger-spec-validator>=2.7.4->neptune==1.2.0->-r requirements.txt (line 35)) (6.4.5)\n",
            "Collecting h11>=0.8 (from uvicorn>=0.14.0->gradio==3.35.2->-r requirements.txt (line 4))\n",
            "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Collecting starlette<0.39.0,>=0.37.2 (from fastapi->gradio==3.35.2->-r requirements.txt (line 4))\n",
            "  Downloading starlette-0.38.6-py3-none-any.whl.metadata (6.0 kB)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx->gradio==3.35.2->-r requirements.txt (line 4)) (3.7.1)\n",
            "Collecting httpcore==1.* (from httpx->gradio==3.35.2->-r requirements.txt (line 4))\n",
            "  Downloading httpcore-1.0.6-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->gradio==3.35.2->-r requirements.txt (line 4)) (1.3.1)\n",
            "Requirement already satisfied: sortedcontainers<3.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from intervaltree->bioc==2.0->-r requirements.txt (line 52)) (2.4.0)\n",
            "INFO: pip is looking at multiple versions of multiprocess to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting multiprocess (from datasets==2.13.0->-r requirements.txt (line 2))\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
            "  Downloading multiprocess-0.70.15-py310-none-any.whl.metadata (7.2 kB)\n",
            "  Downloading multiprocess-0.70.14-py310-none-any.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.0.1->-r requirements.txt (line 9)) (1.3.0)\n",
            "Collecting jsonref (from bravado-core>=5.16.1->bravado<12.0.0,>=11.0.0->neptune==1.2.0->-r requirements.txt (line 35))\n",
            "  Downloading jsonref-1.1.0-py3-none-any.whl.metadata (2.7 kB)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->GitPython>=2.0.8->neptune==1.2.0->-r requirements.txt (line 35))\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl.metadata (4.3 kB)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair>=4.2.0->gradio==3.35.2->-r requirements.txt (line 4)) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair>=4.2.0->gradio==3.35.2->-r requirements.txt (line 4)) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair>=4.2.0->gradio==3.35.2->-r requirements.txt (line 4)) (0.20.0)\n",
            "Requirement already satisfied: uc-micro-py in /usr/local/lib/python3.10/dist-packages (from linkify-it-py<3,>=1->markdown-it-py[linkify]>=2.0.0->gradio==3.35.2->-r requirements.txt (line 4)) (1.0.3)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard==2.13.0->-r requirements.txt (line 34)) (0.6.1)\n",
            "Collecting fqdn (from jsonschema[format-nongpl]>=2.5.1->bravado-core>=5.16.1->bravado<12.0.0,>=11.0.0->neptune==1.2.0->-r requirements.txt (line 35))\n",
            "  Downloading fqdn-1.5.1-py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting isoduration (from jsonschema[format-nongpl]>=2.5.1->bravado-core>=5.16.1->bravado<12.0.0,>=11.0.0->neptune==1.2.0->-r requirements.txt (line 35))\n",
            "  Downloading isoduration-20.11.0-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting jsonpointer>1.13 (from jsonschema[format-nongpl]>=2.5.1->bravado-core>=5.16.1->bravado<12.0.0,>=11.0.0->neptune==1.2.0->-r requirements.txt (line 35))\n",
            "  Downloading jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting rfc3339-validator (from jsonschema[format-nongpl]>=2.5.1->bravado-core>=5.16.1->bravado<12.0.0,>=11.0.0->neptune==1.2.0->-r requirements.txt (line 35))\n",
            "  Downloading rfc3339_validator-0.1.4-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting rfc3986-validator>0.1.0 (from jsonschema[format-nongpl]>=2.5.1->bravado-core>=5.16.1->bravado<12.0.0,>=11.0.0->neptune==1.2.0->-r requirements.txt (line 35))\n",
            "  Downloading rfc3986_validator-0.1.1-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting uri-template (from jsonschema[format-nongpl]>=2.5.1->bravado-core>=5.16.1->bravado<12.0.0,>=11.0.0->neptune==1.2.0->-r requirements.txt (line 35))\n",
            "  Downloading uri_template-1.3.0-py3-none-any.whl.metadata (8.8 kB)\n",
            "Requirement already satisfied: webcolors>=24.6.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema[format-nongpl]>=2.5.1->bravado-core>=5.16.1->bravado<12.0.0,>=11.0.0->neptune==1.2.0->-r requirements.txt (line 35)) (24.8.0)\n",
            "Collecting arrow>=0.15.0 (from isoduration->jsonschema[format-nongpl]>=2.5.1->bravado-core>=5.16.1->bravado<12.0.0,>=11.0.0->neptune==1.2.0->-r requirements.txt (line 35))\n",
            "  Downloading arrow-1.3.0-py3-none-any.whl.metadata (7.5 kB)\n",
            "Collecting types-python-dateutil>=2.8.10 (from arrow>=0.15.0->isoduration->jsonschema[format-nongpl]>=2.5.1->bravado-core>=5.16.1->bravado<12.0.0,>=11.0.0->neptune==1.2.0->-r requirements.txt (line 35))\n",
            "  Downloading types_python_dateutil-2.9.0.20240906-py3-none-any.whl.metadata (1.9 kB)\n",
            "Downloading datasets-2.13.0-py3-none-any.whl (485 kB)\n",
            "Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m50.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio-3.35.2-py3-none-any.whl (19.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.7/19.7 MB\u001b[0m \u001b[31m93.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading huggingface_hub-0.15.1-py3-none-any.whl (236 kB)\n",
            "Downloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
            "Downloading docutils-0.20.1-py3-none-any.whl (572 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m572.7/572.7 kB\u001b[0m \u001b[31m27.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torch-2.0.1-cp310-cp310-manylinux1_x86_64.whl (619.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m619.9/619.9 MB\u001b[0m \u001b[31m46.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading evaluate-0.4.0-py3-none-any.whl (81 kB)\n",
            "Downloading sacrebleu-2.3.1-py3-none-any.whl (118 kB)\n",
            "Downloading scikit_learn-1.2.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.6/9.6 MB\u001b[0m \u001b[31m88.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading better_profanity-0.7.0-py3-none-any.whl (46 kB)\n",
            "Downloading numpy-1.24.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m81.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pandas-2.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m83.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading loralib-0.1.1-py3-none-any.whl (8.8 kB)\n",
            "Downloading bitsandbytes-0.39.0-py3-none-any.whl (92.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.2/92.2 MB\u001b[0m \u001b[31m42.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading accelerate-0.20.3-py3-none-any.whl (227 kB)\n",
            "Downloading transformers-4.30.2-py3-none-any.whl (7.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m110.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m109.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading APScheduler-3.10.1-py3-none-any.whl (59 kB)\n",
            "Downloading pynvml-11.5.0-py3-none-any.whl (53 kB)\n",
            "Downloading boto3-1.26.101-py3-none-any.whl (135 kB)\n",
            "Downloading botocore-1.29.101-py3-none-any.whl (10.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.6/10.6 MB\u001b[0m \u001b[31m28.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboard-2.13.0-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m122.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading neptune-1.2.0-py3-none-any.whl (448 kB)\n",
            "Downloading gradio_client-0.2.7-py3-none-any.whl (288 kB)\n",
            "Downloading beautifulsoup4-4.12.2-py3-none-any.whl (142 kB)\n",
            "Downloading Markdown-3.4.3-py3-none-any.whl (93 kB)\n",
            "Downloading pytest-7.2.2-py3-none-any.whl (317 kB)\n",
            "Downloading pytest_xdist-3.2.1-py3-none-any.whl (41 kB)\n",
            "Downloading textstat-0.7.3-py3-none-any.whl (105 kB)\n",
            "Downloading pypandoc_binary-1.11-py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.1/17.1 MB\u001b[0m \u001b[31m84.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading openpyxl-3.1.2-py2.py3-none-any.whl (249 kB)\n",
            "Downloading lm_dataformat-0.0.20-py3-none-any.whl (5.8 kB)\n",
            "Downloading bioc-2.0-py3-none-any.whl (4.0 kB)\n",
            "Downloading einops-0.6.1-py3-none-any.whl (42 kB)\n",
            "Downloading InstructorEmbedding-1.0.1-py2.py3-none-any.whl (19 kB)\n",
            "Downloading python_dotenv-1.0.0-py3-none-any.whl (19 kB)\n",
            "Downloading text_generation-0.6.0-py3-none-any.whl (10 kB)\n",
            "Downloading tiktoken-0.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m76.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading openai-0.27.8-py3-none-any.whl (73 kB)\n",
            "Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m48.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl (11.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m99.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m103.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m40.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m39.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux2014_x86_64.whl (168.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m61.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl (54.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 MB\u001b[0m \u001b[31m50.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl (102.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.6/102.6 MB\u001b[0m \u001b[31m55.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl (173.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.2/173.2 MB\u001b[0m \u001b[31m68.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl (177.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.1/177.1 MB\u001b[0m \u001b[31m67.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl (98 kB)\n",
            "Downloading triton-2.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 MB\u001b[0m \u001b[31m52.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bravado-11.0.3-py2.py3-none-any.whl (38 kB)\n",
            "Downloading dill-0.3.6-py3-none-any.whl (110 kB)\n",
            "Downloading execnet-2.1.1-py3-none-any.whl (40 kB)\n",
            "Downloading GitPython-3.1.43-py3-none-any.whl (207 kB)\n",
            "Downloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl (18 kB)\n",
            "Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Downloading jsonlines-4.0.0-py3-none-any.whl (8.7 kB)\n",
            "Downloading markdown_it_py-2.2.0-py3-none-any.whl (84 kB)\n",
            "Downloading mdit_py_plugins-0.3.3-py3-none-any.whl (50 kB)\n",
            "Downloading pydantic-1.10.18-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m110.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Downloading s3transfer-0.6.2-py3-none-any.whl (79 kB)\n",
            "Downloading swagger_spec_validator-3.0.4-py2.py3-none-any.whl (28 kB)\n",
            "Downloading urllib3-1.26.20-py2.py3-none-any.whl (144 kB)\n",
            "Downloading uvicorn-0.31.0-py3-none-any.whl (63 kB)\n",
            "Downloading websockets-13.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (164 kB)\n",
            "Downloading aiofiles-24.1.0-py3-none-any.whl (15 kB)\n",
            "Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Downloading fastapi-0.115.0-py3-none-any.whl (94 kB)\n",
            "Downloading ffmpy-0.4.0-py3-none-any.whl (5.8 kB)\n",
            "Downloading httpx-0.27.2-py3-none-any.whl (76 kB)\n",
            "Downloading httpcore-1.0.6-py3-none-any.whl (78 kB)\n",
            "Downloading multiprocess-0.70.14-py310-none-any.whl (134 kB)\n",
            "Downloading orjson-3.10.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (141 kB)\n",
            "Downloading portalocker-2.10.1-py3-none-any.whl (18 kB)\n",
            "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Downloading pyphen-0.16.0-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m94.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_multipart-0.0.12-py3-none-any.whl (23 kB)\n",
            "Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Downloading ujson-5.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (53 kB)\n",
            "Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "Downloading zstandard-0.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m123.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "Downloading starlette-0.38.6-py3-none-any.whl (71 kB)\n",
            "Downloading lit-18.1.8-py3-none-any.whl (96 kB)\n",
            "Downloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
            "Downloading simplejson-3.19.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (137 kB)\n",
            "Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Downloading jsonref-1.1.0-py3-none-any.whl (9.4 kB)\n",
            "Downloading jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
            "Downloading rfc3986_validator-0.1.1-py2.py3-none-any.whl (4.2 kB)\n",
            "Downloading fqdn-1.5.1-py3-none-any.whl (9.1 kB)\n",
            "Downloading isoduration-20.11.0-py3-none-any.whl (11 kB)\n",
            "Downloading rfc3339_validator-0.1.4-py2.py3-none-any.whl (3.5 kB)\n",
            "Downloading uri_template-1.3.0-py3-none-any.whl (11 kB)\n",
            "Downloading arrow-1.3.0-py3-none-any.whl (66 kB)\n",
            "Downloading types_python_dateutil-2.9.0.20240906-py3-none-any.whl (9.7 kB)\n",
            "Building wheels for collected packages: fire, rouge_score, alt-profanity-check, peft, intervaltree, bravado-core\n",
            "  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fire: filename=fire-0.5.0-py2.py3-none-any.whl size=116931 sha256=fe0ceb7af6a5837e9aa97841b8616ae4c0b8a2456b3681c0c5fcc33d9bed184a\n",
            "  Stored in directory: /root/.cache/pip/wheels/90/d4/f7/9404e5db0116bd4d43e5666eaa3e70ab53723e1e3ea40c9a95\n",
            "  Building wheel for rouge_score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24935 sha256=358340ab3b3bb108b887b16078b7739b1de34214c3ccc8c7c9e64429659ea04f\n",
            "  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\n",
            "  Building wheel for alt-profanity-check (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for alt-profanity-check: filename=alt_profanity_check-1.2.2-py3-none-any.whl size=1866160 sha256=28f1c9992353b263305231ea83b96cfc323d6c4576f4367307dd2024c15a59b2\n",
            "  Stored in directory: /root/.cache/pip/wheels/5b/98/77/c2903d8f2862ecf6ac3f51007e82f12d456f1ac7f6a147e7ab\n",
            "  Building wheel for peft (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for peft: filename=peft-0.4.0.dev0-py3-none-any.whl size=61636 sha256=13cb3577333684ef1d16f3c13a870743060a41db3e72677f3f6fb3270f39abea\n",
            "  Stored in directory: /root/.cache/pip/wheels/92/96/bb/e86c6b13090bcad7aa0a598c188f16519472dcc8d8320c0dbe\n",
            "  Building wheel for intervaltree (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for intervaltree: filename=intervaltree-3.1.0-py2.py3-none-any.whl size=26096 sha256=1a9166129154793b35f96a8d3c37d8e32c045d8127d988d0ecbf1a49655710bc\n",
            "  Stored in directory: /root/.cache/pip/wheels/fa/80/8c/43488a924a046b733b64de3fac99252674c892a4c3801c0a61\n",
            "  Building wheel for bravado-core (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for bravado-core: filename=bravado_core-6.1.1-py2.py3-none-any.whl size=67675 sha256=61edd72c0f6a035e6878e51fd5e96dd4a55e05e30df5da21a2a74a612926fa1c\n",
            "  Stored in directory: /root/.cache/pip/wheels/42/35/4a/44ec4c358db21a5d63ed4e40f0f0012a438106f220bce4ccba\n",
            "Successfully built fire rouge_score alt-profanity-check peft intervaltree bravado-core\n",
            "Installing collected packages: tokenizers, sentencepiece, pydub, monotonic, lit, instructorembedding, bitsandbytes, appdirs, zstandard, xxhash, websockets, urllib3, uri-template, ujson, types-python-dateutil, smmap, simplejson, semantic-version, rfc3986-validator, rfc3339-validator, python-multipart, python-dotenv, pytest, pyphen, pypandoc_binary, pynvml, pydantic, portalocker, orjson, openpyxl, nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, numpy, markdown-it-py, markdown, loralib, jsonref, jsonpointer, jsonlines, jmespath, intervaltree, h11, fqdn, fire, ffmpy, execnet, einops, docutils, dill, colorama, better-profanity, beautifulsoup4, APScheduler, aiofiles, uvicorn, textstat, starlette, sacrebleu, rouge_score, pytest-xdist, pandas, nvidia-cusolver-cu11, nvidia-cudnn-cu11, multiprocess, mdit-py-plugins, lm_dataformat, httpcore, gitdb, botocore, bioc, arrow, tiktoken, scikit-learn, s3transfer, responses, isoduration, huggingface_hub, httpx, GitPython, fastapi, transformers, text-generation, swagger-spec-validator, openai, gradio_client, google-auth-oauthlib, boto3, alt-profanity-check, tensorboard, gradio, datasets, bravado-core, evaluate, bravado, neptune, triton, torch, accelerate, peft\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.19.1\n",
            "    Uninstalling tokenizers-0.19.1:\n",
            "      Successfully uninstalled tokenizers-0.19.1\n",
            "  Attempting uninstall: sentencepiece\n",
            "    Found existing installation: sentencepiece 0.2.0\n",
            "    Uninstalling sentencepiece-0.2.0:\n",
            "      Successfully uninstalled sentencepiece-0.2.0\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 2.2.3\n",
            "    Uninstalling urllib3-2.2.3:\n",
            "      Successfully uninstalled urllib3-2.2.3\n",
            "  Attempting uninstall: pytest\n",
            "    Found existing installation: pytest 7.4.4\n",
            "    Uninstalling pytest-7.4.4:\n",
            "      Successfully uninstalled pytest-7.4.4\n",
            "  Attempting uninstall: pydantic\n",
            "    Found existing installation: pydantic 2.9.2\n",
            "    Uninstalling pydantic-2.9.2:\n",
            "      Successfully uninstalled pydantic-2.9.2\n",
            "  Attempting uninstall: openpyxl\n",
            "    Found existing installation: openpyxl 3.1.5\n",
            "    Uninstalling openpyxl-3.1.5:\n",
            "      Successfully uninstalled openpyxl-3.1.5\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.26.4\n",
            "    Uninstalling numpy-1.26.4:\n",
            "      Successfully uninstalled numpy-1.26.4\n",
            "  Attempting uninstall: markdown-it-py\n",
            "    Found existing installation: markdown-it-py 3.0.0\n",
            "    Uninstalling markdown-it-py-3.0.0:\n",
            "      Successfully uninstalled markdown-it-py-3.0.0\n",
            "  Attempting uninstall: markdown\n",
            "    Found existing installation: Markdown 3.7\n",
            "    Uninstalling Markdown-3.7:\n",
            "      Successfully uninstalled Markdown-3.7\n",
            "  Attempting uninstall: einops\n",
            "    Found existing installation: einops 0.8.0\n",
            "    Uninstalling einops-0.8.0:\n",
            "      Successfully uninstalled einops-0.8.0\n",
            "  Attempting uninstall: docutils\n",
            "    Found existing installation: docutils 0.18.1\n",
            "    Uninstalling docutils-0.18.1:\n",
            "      Successfully uninstalled docutils-0.18.1\n",
            "  Attempting uninstall: beautifulsoup4\n",
            "    Found existing installation: beautifulsoup4 4.12.3\n",
            "    Uninstalling beautifulsoup4-4.12.3:\n",
            "      Successfully uninstalled beautifulsoup4-4.12.3\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 2.2.2\n",
            "    Uninstalling pandas-2.2.2:\n",
            "      Successfully uninstalled pandas-2.2.2\n",
            "  Attempting uninstall: mdit-py-plugins\n",
            "    Found existing installation: mdit-py-plugins 0.4.2\n",
            "    Uninstalling mdit-py-plugins-0.4.2:\n",
            "      Successfully uninstalled mdit-py-plugins-0.4.2\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.5.2\n",
            "    Uninstalling scikit-learn-1.5.2:\n",
            "      Successfully uninstalled scikit-learn-1.5.2\n",
            "  Attempting uninstall: huggingface_hub\n",
            "    Found existing installation: huggingface-hub 0.24.7\n",
            "    Uninstalling huggingface-hub-0.24.7:\n",
            "      Successfully uninstalled huggingface-hub-0.24.7\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.44.2\n",
            "    Uninstalling transformers-4.44.2:\n",
            "      Successfully uninstalled transformers-4.44.2\n",
            "  Attempting uninstall: google-auth-oauthlib\n",
            "    Found existing installation: google-auth-oauthlib 1.2.1\n",
            "    Uninstalling google-auth-oauthlib-1.2.1:\n",
            "      Successfully uninstalled google-auth-oauthlib-1.2.1\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.17.0\n",
            "    Uninstalling tensorboard-2.17.0:\n",
            "      Successfully uninstalled tensorboard-2.17.0\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.4.1+cu121\n",
            "    Uninstalling torch-2.4.1+cu121:\n",
            "      Successfully uninstalled torch-2.4.1+cu121\n",
            "  Attempting uninstall: accelerate\n",
            "    Found existing installation: accelerate 0.34.2\n",
            "    Uninstalling accelerate-0.34.2:\n",
            "      Successfully uninstalled accelerate-0.34.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "sphinx 5.0.2 requires docutils<0.19,>=0.14, but you have docutils 0.20.1 which is incompatible.\n",
            "albumentations 1.4.15 requires numpy>=1.24.4, but you have numpy 1.24.3 which is incompatible.\n",
            "albumentations 1.4.15 requires pydantic>=2.7.0, but you have pydantic 1.10.18 which is incompatible.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.0.2 which is incompatible.\n",
            "mizani 0.11.4 requires pandas>=2.1.0, but you have pandas 2.0.2 which is incompatible.\n",
            "plotnine 0.13.6 requires pandas<3.0.0,>=2.1.0, but you have pandas 2.0.2 which is incompatible.\n",
            "tensorflow 2.17.0 requires tensorboard<2.18,>=2.17, but you have tensorboard 2.13.0 which is incompatible.\n",
            "torchaudio 2.4.1+cu121 requires torch==2.4.1, but you have torch 2.0.1 which is incompatible.\n",
            "torchvision 0.19.1+cu121 requires torch==2.4.1, but you have torch 2.0.1 which is incompatible.\n",
            "xarray 2024.9.0 requires pandas>=2.1, but you have pandas 2.0.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed APScheduler-3.10.1 GitPython-3.1.43 accelerate-0.20.3 aiofiles-24.1.0 alt-profanity-check-1.2.2 appdirs-1.4.4 arrow-1.3.0 beautifulsoup4-4.12.2 better-profanity-0.7.0 bioc-2.0 bitsandbytes-0.39.0 boto3-1.26.101 botocore-1.29.101 bravado-11.0.3 bravado-core-6.1.1 colorama-0.4.6 datasets-2.13.0 dill-0.3.6 docutils-0.20.1 einops-0.6.1 evaluate-0.4.0 execnet-2.1.1 fastapi-0.115.0 ffmpy-0.4.0 fire-0.5.0 fqdn-1.5.1 gitdb-4.0.11 google-auth-oauthlib-1.0.0 gradio-3.35.2 gradio_client-0.2.7 h11-0.14.0 httpcore-1.0.6 httpx-0.27.2 huggingface_hub-0.15.1 instructorembedding-1.0.1 intervaltree-3.1.0 isoduration-20.11.0 jmespath-1.0.1 jsonlines-4.0.0 jsonpointer-3.0.0 jsonref-1.1.0 lit-18.1.8 lm_dataformat-0.0.20 loralib-0.1.1 markdown-3.4.3 markdown-it-py-2.2.0 mdit-py-plugins-0.3.3 monotonic-1.6 multiprocess-0.70.14 neptune-1.2.0 numpy-1.24.3 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-cupti-cu11-11.7.101 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.2.10.91 nvidia-cusolver-cu11-11.4.0.1 nvidia-cusparse-cu11-11.7.4.91 nvidia-nccl-cu11-2.14.3 nvidia-nvtx-cu11-11.7.91 openai-0.27.8 openpyxl-3.1.2 orjson-3.10.7 pandas-2.0.2 peft-0.4.0.dev0 portalocker-2.10.1 pydantic-1.10.18 pydub-0.25.1 pynvml-11.5.0 pypandoc_binary-1.11 pyphen-0.16.0 pytest-7.2.2 pytest-xdist-3.2.1 python-dotenv-1.0.0 python-multipart-0.0.12 responses-0.18.0 rfc3339-validator-0.1.4 rfc3986-validator-0.1.1 rouge_score-0.1.2 s3transfer-0.6.2 sacrebleu-2.3.1 scikit-learn-1.2.2 semantic-version-2.10.0 sentencepiece-0.1.99 simplejson-3.19.3 smmap-5.0.1 starlette-0.38.6 swagger-spec-validator-3.0.4 tensorboard-2.13.0 text-generation-0.6.0 textstat-0.7.3 tiktoken-0.4.0 tokenizers-0.13.3 torch-2.0.1 transformers-4.30.2 triton-2.0.0 types-python-dateutil-2.9.0.20240906 ujson-5.10.0 uri-template-1.3.0 urllib3-1.26.20 uvicorn-0.31.0 websockets-13.1 xxhash-3.5.0 zstandard-0.23.0\n",
            "Collecting langchain==0.0.202 (from -r reqs_optional/requirements_optional_langchain.txt (line 2))\n",
            "  Downloading langchain-0.0.202-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting pypdf==3.9.1 (from -r reqs_optional/requirements_optional_langchain.txt (line 3))\n",
            "  Downloading pypdf-3.9.1-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting sentence_transformers==2.2.2 (from -r reqs_optional/requirements_optional_langchain.txt (line 8))\n",
            "  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting chromadb==0.3.25 (from -r reqs_optional/requirements_optional_langchain.txt (line 11))\n",
            "  Downloading chromadb-0.3.25-py3-none-any.whl.metadata (6.7 kB)\n",
            "Collecting unstructured==0.7.4 (from unstructured[local-inference]==0.7.4->-r reqs_optional/requirements_optional_langchain.txt (line 20))\n",
            "  Downloading unstructured-0.7.4-py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from -r reqs_optional/requirements_optional_langchain.txt (line 23)) (10.4.0)\n",
            "Collecting pdfminer.six==20221105 (from -r reqs_optional/requirements_optional_langchain.txt (line 25))\n",
            "  Downloading pdfminer.six-20221105-py3-none-any.whl.metadata (4.0 kB)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from -r reqs_optional/requirements_optional_langchain.txt (line 26)) (1.26.20)\n",
            "Collecting requests_file (from -r reqs_optional/requirements_optional_langchain.txt (line 27))\n",
            "  Downloading requests_file-2.1.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: tabulate==0.9.0 in /usr/local/lib/python3.10/dist-packages (from -r reqs_optional/requirements_optional_langchain.txt (line 31)) (0.9.0)\n",
            "Collecting pip-licenses==4.3.0 (from -r reqs_optional/requirements_optional_langchain.txt (line 39))\n",
            "  Downloading pip_licenses-4.3.0-py3-none-any.whl.metadata (31 kB)\n",
            "Collecting weaviate-client==3.20.0 (from -r reqs_optional/requirements_optional_langchain.txt (line 42))\n",
            "  Downloading weaviate_client-3.20.0-py3-none-any.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: PyYAML>=5.4.1 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.202->-r reqs_optional/requirements_optional_langchain.txt (line 2)) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.202->-r reqs_optional/requirements_optional_langchain.txt (line 2)) (2.0.35)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.202->-r reqs_optional/requirements_optional_langchain.txt (line 2)) (3.10.6)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.202->-r reqs_optional/requirements_optional_langchain.txt (line 2)) (4.0.3)\n",
            "Collecting dataclasses-json<0.6.0,>=0.5.7 (from langchain==0.0.202->-r reqs_optional/requirements_optional_langchain.txt (line 2))\n",
            "  Downloading dataclasses_json-0.5.14-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting langchainplus-sdk>=0.0.9 (from langchain==0.0.202->-r reqs_optional/requirements_optional_langchain.txt (line 2))\n",
            "  Downloading langchainplus_sdk-0.0.20-py3-none-any.whl.metadata (8.7 kB)\n",
            "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.202->-r reqs_optional/requirements_optional_langchain.txt (line 2)) (2.10.1)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.202->-r reqs_optional/requirements_optional_langchain.txt (line 2)) (1.24.3)\n",
            "Collecting openapi-schema-pydantic<2.0,>=1.2 (from langchain==0.0.202->-r reqs_optional/requirements_optional_langchain.txt (line 2))\n",
            "  Downloading openapi_schema_pydantic-1.2.4-py3-none-any.whl.metadata (8.5 kB)\n",
            "Requirement already satisfied: pydantic<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.202->-r reqs_optional/requirements_optional_langchain.txt (line 2)) (1.10.18)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.202->-r reqs_optional/requirements_optional_langchain.txt (line 2)) (2.32.3)\n",
            "Collecting tenacity<9.0.0,>=8.1.0 (from langchain==0.0.202->-r reqs_optional/requirements_optional_langchain.txt (line 2))\n",
            "  Downloading tenacity-8.5.0-py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers==2.2.2->-r reqs_optional/requirements_optional_langchain.txt (line 8)) (4.30.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence_transformers==2.2.2->-r reqs_optional/requirements_optional_langchain.txt (line 8)) (4.66.5)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers==2.2.2->-r reqs_optional/requirements_optional_langchain.txt (line 8)) (2.0.1)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from sentence_transformers==2.2.2->-r reqs_optional/requirements_optional_langchain.txt (line 8)) (0.19.1+cu121)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence_transformers==2.2.2->-r reqs_optional/requirements_optional_langchain.txt (line 8)) (1.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence_transformers==2.2.2->-r reqs_optional/requirements_optional_langchain.txt (line 8)) (1.13.1)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from sentence_transformers==2.2.2->-r reqs_optional/requirements_optional_langchain.txt (line 8)) (3.8.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from sentence_transformers==2.2.2->-r reqs_optional/requirements_optional_langchain.txt (line 8)) (0.1.99)\n",
            "Requirement already satisfied: huggingface-hub>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers==2.2.2->-r reqs_optional/requirements_optional_langchain.txt (line 8)) (0.15.1)\n",
            "Requirement already satisfied: pandas>=1.3 in /usr/local/lib/python3.10/dist-packages (from chromadb==0.3.25->-r reqs_optional/requirements_optional_langchain.txt (line 11)) (2.0.2)\n",
            "Collecting hnswlib>=0.7 (from chromadb==0.3.25->-r reqs_optional/requirements_optional_langchain.txt (line 11))\n",
            "  Downloading hnswlib-0.8.0.tar.gz (36 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting clickhouse-connect>=0.5.7 (from chromadb==0.3.25->-r reqs_optional/requirements_optional_langchain.txt (line 11))\n",
            "  Downloading clickhouse_connect-0.8.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.1 kB)\n",
            "Requirement already satisfied: duckdb>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from chromadb==0.3.25->-r reqs_optional/requirements_optional_langchain.txt (line 11)) (1.1.1)\n",
            "Requirement already satisfied: fastapi>=0.85.1 in /usr/local/lib/python3.10/dist-packages (from chromadb==0.3.25->-r reqs_optional/requirements_optional_langchain.txt (line 11)) (0.115.0)\n",
            "Requirement already satisfied: uvicorn>=0.18.3 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb==0.3.25->-r reqs_optional/requirements_optional_langchain.txt (line 11)) (0.31.0)\n",
            "Collecting posthog>=2.4.0 (from chromadb==0.3.25->-r reqs_optional/requirements_optional_langchain.txt (line 11))\n",
            "  Downloading posthog-3.6.6-py2.py3-none-any.whl.metadata (2.0 kB)\n",
            "Collecting onnxruntime>=1.14.1 (from chromadb==0.3.25->-r reqs_optional/requirements_optional_langchain.txt (line 11))\n",
            "  Downloading onnxruntime-1.19.2-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.5 kB)\n",
            "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.10/dist-packages (from chromadb==0.3.25->-r reqs_optional/requirements_optional_langchain.txt (line 11)) (0.13.3)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from chromadb==0.3.25->-r reqs_optional/requirements_optional_langchain.txt (line 11)) (4.12.2)\n",
            "Collecting overrides>=7.3.1 (from chromadb==0.3.25->-r reqs_optional/requirements_optional_langchain.txt (line 11))\n",
            "  Downloading overrides-7.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Collecting argilla (from unstructured==0.7.4->unstructured[local-inference]==0.7.4->-r reqs_optional/requirements_optional_langchain.txt (line 20))\n",
            "  Downloading argilla-2.2.2-py3-none-any.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: chardet in /usr/local/lib/python3.10/dist-packages (from unstructured==0.7.4->unstructured[local-inference]==0.7.4->-r reqs_optional/requirements_optional_langchain.txt (line 20)) (5.2.0)\n",
            "Collecting filetype (from unstructured==0.7.4->unstructured[local-inference]==0.7.4->-r reqs_optional/requirements_optional_langchain.txt (line 20))\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from unstructured==0.7.4->unstructured[local-inference]==0.7.4->-r reqs_optional/requirements_optional_langchain.txt (line 20)) (4.9.4)\n",
            "Collecting msg-parser (from unstructured==0.7.4->unstructured[local-inference]==0.7.4->-r reqs_optional/requirements_optional_langchain.txt (line 20))\n",
            "  Downloading msg_parser-1.2.0-py2.py3-none-any.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.10/dist-packages (from unstructured==0.7.4->unstructured[local-inference]==0.7.4->-r reqs_optional/requirements_optional_langchain.txt (line 20)) (3.1.2)\n",
            "Collecting pypandoc (from unstructured==0.7.4->unstructured[local-inference]==0.7.4->-r reqs_optional/requirements_optional_langchain.txt (line 20))\n",
            "  Downloading pypandoc-1.13-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting python-docx (from unstructured==0.7.4->unstructured[local-inference]==0.7.4->-r reqs_optional/requirements_optional_langchain.txt (line 20))\n",
            "  Downloading python_docx-1.1.2-py3-none-any.whl.metadata (2.0 kB)\n",
            "Collecting python-pptx (from unstructured==0.7.4->unstructured[local-inference]==0.7.4->-r reqs_optional/requirements_optional_langchain.txt (line 20))\n",
            "  Downloading python_pptx-1.0.2-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting python-magic (from unstructured==0.7.4->unstructured[local-inference]==0.7.4->-r reqs_optional/requirements_optional_langchain.txt (line 20))\n",
            "  Downloading python_magic-0.4.27-py2.py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: markdown in /usr/local/lib/python3.10/dist-packages (from unstructured==0.7.4->unstructured[local-inference]==0.7.4->-r reqs_optional/requirements_optional_langchain.txt (line 20)) (3.4.3)\n",
            "Requirement already satisfied: xlrd in /usr/local/lib/python3.10/dist-packages (from unstructured==0.7.4->unstructured[local-inference]==0.7.4->-r reqs_optional/requirements_optional_langchain.txt (line 20)) (2.0.1)\n",
            "Requirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six==20221105->-r reqs_optional/requirements_optional_langchain.txt (line 25)) (3.3.2)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six==20221105->-r reqs_optional/requirements_optional_langchain.txt (line 25)) (43.0.1)\n",
            "Requirement already satisfied: prettytable>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from pip-licenses==4.3.0->-r reqs_optional/requirements_optional_langchain.txt (line 39)) (3.11.0)\n",
            "Collecting requests<3,>=2 (from langchain==0.0.202->-r reqs_optional/requirements_optional_langchain.txt (line 2))\n",
            "  Downloading requests-2.31.0-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting validators<=0.21.0,>=0.18.2 (from weaviate-client==3.20.0->-r reqs_optional/requirements_optional_langchain.txt (line 42))\n",
            "  Downloading validators-0.21.0-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting authlib>=1.1.0 (from weaviate-client==3.20.0->-r reqs_optional/requirements_optional_langchain.txt (line 42))\n",
            "  Downloading Authlib-1.3.2-py2.py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting unstructured-inference==0.5.1 (from unstructured[local-inference]==0.7.4->-r reqs_optional/requirements_optional_langchain.txt (line 20))\n",
            "  Downloading unstructured_inference-0.5.1-py3-none-any.whl.metadata (6.4 kB)\n",
            "Collecting layoutparser[layoutmodels,tesseract] (from unstructured-inference==0.5.1->unstructured[local-inference]==0.7.4->-r reqs_optional/requirements_optional_langchain.txt (line 20))\n",
            "  Downloading layoutparser-0.3.4-py3-none-any.whl.metadata (7.7 kB)\n",
            "Requirement already satisfied: python-multipart in /usr/local/lib/python3.10/dist-packages (from unstructured-inference==0.5.1->unstructured[local-inference]==0.7.4->-r reqs_optional/requirements_optional_langchain.txt (line 20)) (0.0.12)\n",
            "Requirement already satisfied: opencv-python!=4.7.0.68 in /usr/local/lib/python3.10/dist-packages (from unstructured-inference==0.5.1->unstructured[local-inference]==0.7.4->-r reqs_optional/requirements_optional_langchain.txt (line 20)) (4.10.0.84)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.202->-r reqs_optional/requirements_optional_langchain.txt (line 2)) (2.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.202->-r reqs_optional/requirements_optional_langchain.txt (line 2)) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.202->-r reqs_optional/requirements_optional_langchain.txt (line 2)) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.202->-r reqs_optional/requirements_optional_langchain.txt (line 2)) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.202->-r reqs_optional/requirements_optional_langchain.txt (line 2)) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.202->-r reqs_optional/requirements_optional_langchain.txt (line 2)) (1.12.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from clickhouse-connect>=0.5.7->chromadb==0.3.25->-r reqs_optional/requirements_optional_langchain.txt (line 11)) (2024.8.30)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.10/dist-packages (from clickhouse-connect>=0.5.7->chromadb==0.3.25->-r reqs_optional/requirements_optional_langchain.txt (line 11)) (2024.2)\n",
            "Requirement already satisfied: zstandard in /usr/local/lib/python3.10/dist-packages (from clickhouse-connect>=0.5.7->chromadb==0.3.25->-r reqs_optional/requirements_optional_langchain.txt (line 11)) (0.23.0)\n",
            "Collecting lz4 (from clickhouse-connect>=0.5.7->chromadb==0.3.25->-r reqs_optional/requirements_optional_langchain.txt (line 11))\n",
            "  Downloading lz4-4.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=36.0.0->pdfminer.six==20221105->-r reqs_optional/requirements_optional_langchain.txt (line 25)) (1.17.1)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.6.0,>=0.5.7->langchain==0.0.202->-r reqs_optional/requirements_optional_langchain.txt (line 2))\n",
            "  Downloading marshmallow-3.22.0-py3-none-any.whl.metadata (7.2 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.6.0,>=0.5.7->langchain==0.0.202->-r reqs_optional/requirements_optional_langchain.txt (line 2))\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: starlette<0.39.0,>=0.37.2 in /usr/local/lib/python3.10/dist-packages (from fastapi>=0.85.1->chromadb==0.3.25->-r reqs_optional/requirements_optional_langchain.txt (line 11)) (0.38.6)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers==2.2.2->-r reqs_optional/requirements_optional_langchain.txt (line 8)) (3.16.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers==2.2.2->-r reqs_optional/requirements_optional_langchain.txt (line 8)) (2024.6.1)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers==2.2.2->-r reqs_optional/requirements_optional_langchain.txt (line 8)) (24.1)\n",
            "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb==0.3.25->-r reqs_optional/requirements_optional_langchain.txt (line 11))\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb==0.3.25->-r reqs_optional/requirements_optional_langchain.txt (line 11)) (24.3.25)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb==0.3.25->-r reqs_optional/requirements_optional_langchain.txt (line 11)) (3.20.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb==0.3.25->-r reqs_optional/requirements_optional_langchain.txt (line 11)) (1.13.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.3->chromadb==0.3.25->-r reqs_optional/requirements_optional_langchain.txt (line 11)) (2.8.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.3->chromadb==0.3.25->-r reqs_optional/requirements_optional_langchain.txt (line 11)) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from posthog>=2.4.0->chromadb==0.3.25->-r reqs_optional/requirements_optional_langchain.txt (line 11)) (1.16.0)\n",
            "Requirement already satisfied: monotonic>=1.5 in /usr/local/lib/python3.10/dist-packages (from posthog>=2.4.0->chromadb==0.3.25->-r reqs_optional/requirements_optional_langchain.txt (line 11)) (1.6)\n",
            "Collecting backoff>=1.10.0 (from posthog>=2.4.0->chromadb==0.3.25->-r reqs_optional/requirements_optional_langchain.txt (line 11))\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prettytable>=2.3.0->pip-licenses==4.3.0->-r reqs_optional/requirements_optional_langchain.txt (line 39)) (0.2.13)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.0.202->-r reqs_optional/requirements_optional_langchain.txt (line 2)) (3.10)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain==0.0.202->-r reqs_optional/requirements_optional_langchain.txt (line 2)) (3.1.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence_transformers==2.2.2->-r reqs_optional/requirements_optional_langchain.txt (line 8)) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence_transformers==2.2.2->-r reqs_optional/requirements_optional_langchain.txt (line 8)) (3.1.4)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence_transformers==2.2.2->-r reqs_optional/requirements_optional_langchain.txt (line 8)) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence_transformers==2.2.2->-r reqs_optional/requirements_optional_langchain.txt (line 8)) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence_transformers==2.2.2->-r reqs_optional/requirements_optional_langchain.txt (line 8)) (11.7.101)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence_transformers==2.2.2->-r reqs_optional/requirements_optional_langchain.txt (line 8)) (8.5.0.96)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence_transformers==2.2.2->-r reqs_optional/requirements_optional_langchain.txt (line 8)) (11.10.3.66)\n",
            "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence_transformers==2.2.2->-r reqs_optional/requirements_optional_langchain.txt (line 8)) (10.9.0.58)\n",
            "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence_transformers==2.2.2->-r reqs_optional/requirements_optional_langchain.txt (line 8)) (10.2.10.91)\n",
            "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence_transformers==2.2.2->-r reqs_optional/requirements_optional_langchain.txt (line 8)) (11.4.0.1)\n",
            "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence_transformers==2.2.2->-r reqs_optional/requirements_optional_langchain.txt (line 8)) (11.7.4.91)\n",
            "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence_transformers==2.2.2->-r reqs_optional/requirements_optional_langchain.txt (line 8)) (2.14.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence_transformers==2.2.2->-r reqs_optional/requirements_optional_langchain.txt (line 8)) (11.7.91)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence_transformers==2.2.2->-r reqs_optional/requirements_optional_langchain.txt (line 8)) (2.0.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.6.0->sentence_transformers==2.2.2->-r reqs_optional/requirements_optional_langchain.txt (line 8)) (71.0.4)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.6.0->sentence_transformers==2.2.2->-r reqs_optional/requirements_optional_langchain.txt (line 8)) (0.44.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->sentence_transformers==2.2.2->-r reqs_optional/requirements_optional_langchain.txt (line 8)) (3.30.3)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->sentence_transformers==2.2.2->-r reqs_optional/requirements_optional_langchain.txt (line 8)) (18.1.8)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers==2.2.2->-r reqs_optional/requirements_optional_langchain.txt (line 8)) (2024.9.11)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers==2.2.2->-r reqs_optional/requirements_optional_langchain.txt (line 8)) (0.4.5)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn>=0.18.3->uvicorn[standard]>=0.18.3->chromadb==0.3.25->-r reqs_optional/requirements_optional_langchain.txt (line 11)) (8.1.7)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.10/dist-packages (from uvicorn>=0.18.3->uvicorn[standard]>=0.18.3->chromadb==0.3.25->-r reqs_optional/requirements_optional_langchain.txt (line 11)) (0.14.0)\n",
            "Collecting httptools>=0.5.0 (from uvicorn[standard]>=0.18.3->chromadb==0.3.25->-r reqs_optional/requirements_optional_langchain.txt (line 11))\n",
            "  Downloading httptools-0.6.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb==0.3.25->-r reqs_optional/requirements_optional_langchain.txt (line 11)) (1.0.0)\n",
            "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]>=0.18.3->chromadb==0.3.25->-r reqs_optional/requirements_optional_langchain.txt (line 11))\n",
            "  Downloading uvloop-0.20.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb==0.3.25->-r reqs_optional/requirements_optional_langchain.txt (line 11))\n",
            "  Downloading watchfiles-0.24.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb==0.3.25->-r reqs_optional/requirements_optional_langchain.txt (line 11)) (13.1)\n",
            "Requirement already satisfied: httpx>=0.26.0 in /usr/local/lib/python3.10/dist-packages (from argilla->unstructured==0.7.4->unstructured[local-inference]==0.7.4->-r reqs_optional/requirements_optional_langchain.txt (line 20)) (0.27.2)\n",
            "INFO: pip is looking at multiple versions of argilla to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting argilla (from unstructured==0.7.4->unstructured[local-inference]==0.7.4->-r reqs_optional/requirements_optional_langchain.txt (line 20))\n",
            "  Downloading argilla-2.2.1-py3-none-any.whl.metadata (9.0 kB)\n",
            "  Downloading argilla-2.2.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "  Downloading argilla-2.1.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "  Downloading argilla-2.0.1-py3-none-any.whl.metadata (9.0 kB)\n",
            "  Downloading argilla-2.0.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "  Downloading argilla-1.29.1-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting httpx<=0.26,>=0.15 (from argilla->unstructured==0.7.4->unstructured[local-inference]==0.7.4->-r reqs_optional/requirements_optional_langchain.txt (line 20))\n",
            "  Downloading httpx-0.26.0-py3-none-any.whl.metadata (7.6 kB)\n",
            "Collecting deprecated~=1.2.0 (from argilla->unstructured==0.7.4->unstructured[local-inference]==0.7.4->-r reqs_optional/requirements_optional_langchain.txt (line 20))\n",
            "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting wrapt<1.15,>=1.14 (from argilla->unstructured==0.7.4->unstructured[local-inference]==0.7.4->-r reqs_optional/requirements_optional_langchain.txt (line 20))\n",
            "  Downloading wrapt-1.14.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: rich!=13.1.0 in /usr/local/lib/python3.10/dist-packages (from argilla->unstructured==0.7.4->unstructured[local-inference]==0.7.4->-r reqs_optional/requirements_optional_langchain.txt (line 20)) (13.8.1)\n",
            "Collecting typer<0.10.0,>=0.6.0 (from argilla->unstructured==0.7.4->unstructured[local-inference]==0.7.4->-r reqs_optional/requirements_optional_langchain.txt (line 20))\n",
            "  Downloading typer-0.9.4-py3-none-any.whl.metadata (14 kB)\n",
            "Collecting olefile>=0.46 (from msg-parser->unstructured==0.7.4->unstructured[local-inference]==0.7.4->-r reqs_optional/requirements_optional_langchain.txt (line 20))\n",
            "  Downloading olefile-0.47-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->sentence_transformers==2.2.2->-r reqs_optional/requirements_optional_langchain.txt (line 8)) (1.4.2)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.10/dist-packages (from openpyxl->unstructured==0.7.4->unstructured[local-inference]==0.7.4->-r reqs_optional/requirements_optional_langchain.txt (line 20)) (1.1.0)\n",
            "Collecting XlsxWriter>=0.5.7 (from python-pptx->unstructured==0.7.4->unstructured[local-inference]==0.7.4->-r reqs_optional/requirements_optional_langchain.txt (line 20))\n",
            "  Downloading XlsxWriter-3.2.0-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence_transformers==2.2.2->-r reqs_optional/requirements_optional_langchain.txt (line 8)) (3.5.0)\n",
            "Collecting torch>=1.6.0 (from sentence_transformers==2.2.2->-r reqs_optional/requirements_optional_langchain.txt (line 8))\n",
            "  Downloading torch-2.4.1-cp310-cp310-manylinux1_x86_64.whl.metadata (26 kB)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.6.0->sentence_transformers==2.2.2->-r reqs_optional/requirements_optional_langchain.txt (line 8))\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.6.0->sentence_transformers==2.2.2->-r reqs_optional/requirements_optional_langchain.txt (line 8))\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.6.0->sentence_transformers==2.2.2->-r reqs_optional/requirements_optional_langchain.txt (line 8))\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.6.0->sentence_transformers==2.2.2->-r reqs_optional/requirements_optional_langchain.txt (line 8))\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.6.0->sentence_transformers==2.2.2->-r reqs_optional/requirements_optional_langchain.txt (line 8))\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.6.0->sentence_transformers==2.2.2->-r reqs_optional/requirements_optional_langchain.txt (line 8))\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.6.0->sentence_transformers==2.2.2->-r reqs_optional/requirements_optional_langchain.txt (line 8))\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.6.0->sentence_transformers==2.2.2->-r reqs_optional/requirements_optional_langchain.txt (line 8))\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.6.0->sentence_transformers==2.2.2->-r reqs_optional/requirements_optional_langchain.txt (line 8))\n",
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch>=1.6.0->sentence_transformers==2.2.2->-r reqs_optional/requirements_optional_langchain.txt (line 8))\n",
            "  Downloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.6.0->sentence_transformers==2.2.2->-r reqs_optional/requirements_optional_langchain.txt (line 8))\n",
            "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting triton==3.0.0 (from torch>=1.6.0->sentence_transformers==2.2.2->-r reqs_optional/requirements_optional_langchain.txt (line 8))\n",
            "  Downloading triton-3.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.6.0->sentence_transformers==2.2.2->-r reqs_optional/requirements_optional_langchain.txt (line 8)) (12.6.68)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20221105->-r reqs_optional/requirements_optional_langchain.txt (line 25)) (2.22)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<=0.26,>=0.15->argilla->unstructured==0.7.4->unstructured[local-inference]==0.7.4->-r reqs_optional/requirements_optional_langchain.txt (line 20)) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<=0.26,>=0.15->argilla->unstructured==0.7.4->unstructured[local-inference]==0.7.4->-r reqs_optional/requirements_optional_langchain.txt (line 20)) (1.0.6)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<=0.26,>=0.15->argilla->unstructured==0.7.4->unstructured[local-inference]==0.7.4->-r reqs_optional/requirements_optional_langchain.txt (line 20)) (1.3.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich!=13.1.0->argilla->unstructured==0.7.4->unstructured[local-inference]==0.7.4->-r reqs_optional/requirements_optional_langchain.txt (line 20)) (2.2.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich!=13.1.0->argilla->unstructured==0.7.4->unstructured[local-inference]==0.7.4->-r reqs_optional/requirements_optional_langchain.txt (line 20)) (2.18.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain==0.0.202->-r reqs_optional/requirements_optional_langchain.txt (line 2))\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb==0.3.25->-r reqs_optional/requirements_optional_langchain.txt (line 11))\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6.0->sentence_transformers==2.2.2->-r reqs_optional/requirements_optional_langchain.txt (line 8)) (2.1.5)\n",
            "Collecting iopath (from layoutparser[layoutmodels,tesseract]->unstructured-inference==0.5.1->unstructured[local-inference]==0.7.4->-r reqs_optional/requirements_optional_langchain.txt (line 20))\n",
            "  Downloading iopath-0.1.10.tar.gz (42 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pdfplumber (from layoutparser[layoutmodels,tesseract]->unstructured-inference==0.5.1->unstructured[local-inference]==0.7.4->-r reqs_optional/requirements_optional_langchain.txt (line 20))\n",
            "  Downloading pdfplumber-0.11.4-py3-none-any.whl.metadata (41 kB)\n",
            "Collecting pdf2image (from layoutparser[layoutmodels,tesseract]->unstructured-inference==0.5.1->unstructured[local-inference]==0.7.4->-r reqs_optional/requirements_optional_langchain.txt (line 20))\n",
            "  Downloading pdf2image-1.17.0-py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting pytesseract (from layoutparser[layoutmodels,tesseract]->unstructured-inference==0.5.1->unstructured[local-inference]==0.7.4->-r reqs_optional/requirements_optional_langchain.txt (line 20))\n",
            "  Downloading pytesseract-0.3.13-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting effdet (from layoutparser[layoutmodels,tesseract]->unstructured-inference==0.5.1->unstructured[local-inference]==0.7.4->-r reqs_optional/requirements_optional_langchain.txt (line 20))\n",
            "  Downloading effdet-0.4.1-py3-none-any.whl.metadata (33 kB)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb==0.3.25->-r reqs_optional/requirements_optional_langchain.txt (line 11)) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<=0.26,>=0.15->argilla->unstructured==0.7.4->unstructured[local-inference]==0.7.4->-r reqs_optional/requirements_optional_langchain.txt (line 20)) (1.2.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich!=13.1.0->argilla->unstructured==0.7.4->unstructured[local-inference]==0.7.4->-r reqs_optional/requirements_optional_langchain.txt (line 20)) (0.1.2)\n",
            "Collecting timm>=0.9.2 (from effdet->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.5.1->unstructured[local-inference]==0.7.4->-r reqs_optional/requirements_optional_langchain.txt (line 20))\n",
            "  Downloading timm-1.0.9-py3-none-any.whl.metadata (42 kB)\n",
            "Requirement already satisfied: pycocotools>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from effdet->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.5.1->unstructured[local-inference]==0.7.4->-r reqs_optional/requirements_optional_langchain.txt (line 20)) (2.0.8)\n",
            "Collecting omegaconf>=2.0 (from effdet->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.5.1->unstructured[local-inference]==0.7.4->-r reqs_optional/requirements_optional_langchain.txt (line 20))\n",
            "  Downloading omegaconf-2.3.0-py3-none-any.whl.metadata (3.9 kB)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.10/dist-packages (from iopath->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.5.1->unstructured[local-inference]==0.7.4->-r reqs_optional/requirements_optional_langchain.txt (line 20)) (2.10.1)\n",
            "INFO: pip is looking at multiple versions of pdfplumber to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting pdfplumber (from layoutparser[layoutmodels,tesseract]->unstructured-inference==0.5.1->unstructured[local-inference]==0.7.4->-r reqs_optional/requirements_optional_langchain.txt (line 20))\n",
            "  Downloading pdfplumber-0.11.3-py3-none-any.whl.metadata (41 kB)\n",
            "  Downloading pdfplumber-0.11.2-py3-none-any.whl.metadata (40 kB)\n",
            "  Downloading pdfplumber-0.11.1-py3-none-any.whl.metadata (39 kB)\n",
            "  Downloading pdfplumber-0.11.0-py3-none-any.whl.metadata (39 kB)\n",
            "  Downloading pdfplumber-0.10.4-py3-none-any.whl.metadata (39 kB)\n",
            "Collecting pypdfium2>=4.18.0 (from pdfplumber->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.5.1->unstructured[local-inference]==0.7.4->-r reqs_optional/requirements_optional_langchain.txt (line 20))\n",
            "  Downloading pypdfium2-4.30.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (48 kB)\n",
            "Collecting antlr4-python3-runtime==4.9.* (from omegaconf>=2.0->effdet->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.5.1->unstructured[local-inference]==0.7.4->-r reqs_optional/requirements_optional_langchain.txt (line 20))\n",
            "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: matplotlib>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from pycocotools>=2.0.2->effdet->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.5.1->unstructured[local-inference]==0.7.4->-r reqs_optional/requirements_optional_langchain.txt (line 20)) (3.7.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0.2->effdet->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.5.1->unstructured[local-inference]==0.7.4->-r reqs_optional/requirements_optional_langchain.txt (line 20)) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0.2->effdet->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.5.1->unstructured[local-inference]==0.7.4->-r reqs_optional/requirements_optional_langchain.txt (line 20)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0.2->effdet->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.5.1->unstructured[local-inference]==0.7.4->-r reqs_optional/requirements_optional_langchain.txt (line 20)) (4.54.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0.2->effdet->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.5.1->unstructured[local-inference]==0.7.4->-r reqs_optional/requirements_optional_langchain.txt (line 20)) (1.4.7)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0.2->effdet->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.5.1->unstructured[local-inference]==0.7.4->-r reqs_optional/requirements_optional_langchain.txt (line 20)) (3.1.4)\n",
            "Downloading langchain-0.0.202-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m26.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pypdf-3.9.1-py3-none-any.whl (249 kB)\n",
            "Downloading chromadb-0.3.25-py3-none-any.whl (86 kB)\n",
            "Downloading unstructured-0.7.4-py3-none-any.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m45.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pdfminer.six-20221105-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m133.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pip_licenses-4.3.0-py3-none-any.whl (19 kB)\n",
            "Downloading weaviate_client-3.20.0-py3-none-any.whl (99 kB)\n",
            "Downloading unstructured_inference-0.5.1-py3-none-any.whl (39 kB)\n",
            "Downloading requests_file-2.1.0-py2.py3-none-any.whl (4.2 kB)\n",
            "Downloading Authlib-1.3.2-py2.py3-none-any.whl (225 kB)\n",
            "Downloading clickhouse_connect-0.8.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (977 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m977.5/977.5 kB\u001b[0m \u001b[31m57.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.5.14-py3-none-any.whl (26 kB)\n",
            "Downloading langchainplus_sdk-0.0.20-py3-none-any.whl (25 kB)\n",
            "Downloading onnxruntime-1.19.2-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (13.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.2/13.2 MB\u001b[0m \u001b[31m116.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading openapi_schema_pydantic-1.2.4-py3-none-any.whl (90 kB)\n",
            "Downloading overrides-7.7.0-py3-none-any.whl (17 kB)\n",
            "Downloading posthog-3.6.6-py2.py3-none-any.whl (54 kB)\n",
            "Downloading requests-2.31.0-py3-none-any.whl (62 kB)\n",
            "Downloading tenacity-8.5.0-py3-none-any.whl (28 kB)\n",
            "Downloading validators-0.21.0-py3-none-any.whl (27 kB)\n",
            "Downloading argilla-1.29.1-py3-none-any.whl (417 kB)\n",
            "Downloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Downloading msg_parser-1.2.0-py2.py3-none-any.whl (101 kB)\n",
            "Downloading pypandoc-1.13-py3-none-any.whl (21 kB)\n",
            "Downloading python_docx-1.1.2-py3-none-any.whl (244 kB)\n",
            "Downloading python_magic-0.4.27-py2.py3-none-any.whl (13 kB)\n",
            "Downloading python_pptx-1.0.2-py3-none-any.whl (472 kB)\n",
            "Downloading torch-2.4.1-cp310-cp310-manylinux1_x86_64.whl (797.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m797.1/797.1 MB\u001b[0m \u001b[31m34.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m53.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m124.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m115.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m46.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m35.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m56.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m59.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m64.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m70.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.2/176.2 MB\u001b[0m \u001b[31m70.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Downloading triton-3.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (209.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.4/209.4 MB\u001b[0m \u001b[31m69.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
            "Downloading httptools-0.6.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (341 kB)\n",
            "Downloading httpx-0.26.0-py3-none-any.whl (75 kB)\n",
            "Downloading marshmallow-3.22.0-py3-none-any.whl (49 kB)\n",
            "Downloading olefile-0.47-py2.py3-none-any.whl (114 kB)\n",
            "Downloading typer-0.9.4-py3-none-any.whl (45 kB)\n",
            "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading uvloop-0.20.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m113.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchfiles-0.24.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (425 kB)\n",
            "Downloading wrapt-1.14.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (77 kB)\n",
            "Downloading XlsxWriter-3.2.0-py3-none-any.whl (159 kB)\n",
            "Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "Downloading lz4-4.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m69.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Downloading effdet-0.4.1-py3-none-any.whl (112 kB)\n",
            "Downloading layoutparser-0.3.4-py3-none-any.whl (19.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.2/19.2 MB\u001b[0m \u001b[31m102.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pdf2image-1.17.0-py3-none-any.whl (11 kB)\n",
            "Downloading pdfplumber-0.10.4-py3-none-any.whl (54 kB)\n",
            "Downloading pytesseract-0.3.13-py3-none-any.whl (14 kB)\n",
            "Downloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
            "Downloading pypdfium2-4.30.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m106.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading timm-1.0.9-py3-none-any.whl (2.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m96.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: sentence_transformers, hnswlib, iopath, antlr4-python3-runtime\n",
            "  Building wheel for sentence_transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sentence_transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125924 sha256=398744820a681d008e327dd4494573bbff1a9d148e5e1e44b895233ea701792d\n",
            "  Stored in directory: /root/.cache/pip/wheels/62/f2/10/1e606fd5f02395388f74e7462910fe851042f97238cbbd902f\n",
            "  Building wheel for hnswlib (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for hnswlib: filename=hnswlib-0.8.0-cp310-cp310-linux_x86_64.whl size=2360795 sha256=55569645a4ed1668b8ea34d732d3ecd34861e146ad68f4d1d93b6093779fe0c2\n",
            "  Stored in directory: /root/.cache/pip/wheels/af/a9/3e/3e5d59ee41664eb31a4e6de67d1846f86d16d93c45f277c4e7\n",
            "  Building wheel for iopath (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for iopath: filename=iopath-0.1.10-py3-none-any.whl size=31529 sha256=b77199f5a97e54eb7a8dfb36549a620825d92269293255065719a5df709b65c3\n",
            "  Stored in directory: /root/.cache/pip/wheels/9a/a3/b6/ac0fcd1b4ed5cfeb3db92e6a0e476cfd48ed0df92b91080c1d\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144554 sha256=b026eed8f65652144ce363140b454231f690976ece26ccf110fe7cd729c14ce1\n",
            "  Stored in directory: /root/.cache/pip/wheels/12/93/dd/1f6a127edc45659556564c5730f6d4e300888f4bca2d4c5a88\n",
            "Successfully built sentence_transformers hnswlib iopath antlr4-python3-runtime\n",
            "Installing collected packages: filetype, antlr4-python3-runtime, XlsxWriter, wrapt, validators, uvloop, typer, triton, tenacity, requests, python-magic, python-docx, pytesseract, pypdfium2, pypdf, pypandoc, pdf2image, overrides, omegaconf, olefile, nvidia-nvtx-cu12, nvidia-nccl-cu12, nvidia-cusparse-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, mypy-extensions, marshmallow, lz4, iopath, humanfriendly, httptools, hnswlib, backoff, watchfiles, typing-inspect, requests_file, python-pptx, posthog, pip-licenses, openapi-schema-pydantic, nvidia-cusolver-cu12, nvidia-cudnn-cu12, msg-parser, langchainplus-sdk, httpx, deprecated, coloredlogs, clickhouse-connect, torch, pdfminer.six, onnxruntime, dataclasses-json, authlib, argilla, weaviate-client, unstructured, pdfplumber, langchain, chromadb, timm, sentence_transformers, layoutparser, effdet, unstructured-inference\n",
            "  Attempting uninstall: wrapt\n",
            "    Found existing installation: wrapt 1.16.0\n",
            "    Uninstalling wrapt-1.16.0:\n",
            "      Successfully uninstalled wrapt-1.16.0\n",
            "  Attempting uninstall: typer\n",
            "    Found existing installation: typer 0.12.5\n",
            "    Uninstalling typer-0.12.5:\n",
            "      Successfully uninstalled typer-0.12.5\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 2.0.0\n",
            "    Uninstalling triton-2.0.0:\n",
            "      Successfully uninstalled triton-2.0.0\n",
            "  Attempting uninstall: tenacity\n",
            "    Found existing installation: tenacity 9.0.0\n",
            "    Uninstalling tenacity-9.0.0:\n",
            "      Successfully uninstalled tenacity-9.0.0\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.32.3\n",
            "    Uninstalling requests-2.32.3:\n",
            "      Successfully uninstalled requests-2.32.3\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.23.4\n",
            "    Uninstalling nvidia-nccl-cu12-2.23.4:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.23.4\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.3.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.3.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.3.3\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.6.59\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.6.59:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.6.59\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.6.68\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.6.68:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.6.68\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.6.68\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.6.68:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.6.68\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.6.1.4\n",
            "    Uninstalling nvidia-cublas-cu12-12.6.1.4:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.6.1.4\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.4.69\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.4.69:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.4.69\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.4.0.58\n",
            "    Uninstalling nvidia-cudnn-cu12-9.4.0.58:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.4.0.58\n",
            "  Attempting uninstall: httpx\n",
            "    Found existing installation: httpx 0.27.2\n",
            "    Uninstalling httpx-0.27.2:\n",
            "      Successfully uninstalled httpx-0.27.2\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.0.1\n",
            "    Uninstalling torch-2.0.1:\n",
            "      Successfully uninstalled torch-2.0.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "sphinx 5.0.2 requires docutils<0.19,>=0.14, but you have docutils 0.20.1 which is incompatible.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.0.2 which is incompatible.\n",
            "google-colab 1.0.0 requires requests==2.32.3, but you have requests 2.31.0 which is incompatible.\n",
            "tensorflow 2.17.0 requires tensorboard<2.18,>=2.17, but you have tensorboard 2.13.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed XlsxWriter-3.2.0 antlr4-python3-runtime-4.9.3 argilla-1.29.1 authlib-1.3.2 backoff-2.2.1 chromadb-0.3.25 clickhouse-connect-0.8.1 coloredlogs-15.0.1 dataclasses-json-0.5.14 deprecated-1.2.14 effdet-0.4.1 filetype-1.2.0 hnswlib-0.8.0 httptools-0.6.1 httpx-0.26.0 humanfriendly-10.0 iopath-0.1.10 langchain-0.0.202 langchainplus-sdk-0.0.20 layoutparser-0.3.4 lz4-4.3.3 marshmallow-3.22.0 msg-parser-1.2.0 mypy-extensions-1.0.0 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvtx-cu12-12.1.105 olefile-0.47 omegaconf-2.3.0 onnxruntime-1.19.2 openapi-schema-pydantic-1.2.4 overrides-7.7.0 pdf2image-1.17.0 pdfminer.six-20221105 pdfplumber-0.10.4 pip-licenses-4.3.0 posthog-3.6.6 pypandoc-1.13 pypdf-3.9.1 pypdfium2-4.30.0 pytesseract-0.3.13 python-docx-1.1.2 python-magic-0.4.27 python-pptx-1.0.2 requests-2.31.0 requests_file-2.1.0 sentence_transformers-2.2.2 tenacity-8.5.0 timm-1.0.9 torch-2.4.1 triton-3.0.0 typer-0.9.4 typing-inspect-0.9.0 unstructured-0.7.4 unstructured-inference-0.5.1 uvloop-0.20.0 validators-0.21.0 watchfiles-0.24.0 weaviate-client-3.20.0 wrapt-1.14.1\n",
            "Collecting gpt4all==0.3.3 (from -r reqs_optional/requirements_optional_gpt4all.txt (line 1))\n",
            "  Downloading gpt4all-0.3.3-py3-none-manylinux1_x86_64.whl.metadata (836 bytes)\n",
            "Collecting llama-cpp-python==0.1.68 (from -r reqs_optional/requirements_optional_gpt4all.txt (line 2))\n",
            "  Downloading llama_cpp_python-0.1.68.tar.gz (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from gpt4all==0.3.3->-r reqs_optional/requirements_optional_gpt4all.txt (line 1)) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gpt4all==0.3.3->-r reqs_optional/requirements_optional_gpt4all.txt (line 1)) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-cpp-python==0.1.68->-r reqs_optional/requirements_optional_gpt4all.txt (line 2)) (4.12.2)\n",
            "Requirement already satisfied: numpy>=1.20.0 in /usr/local/lib/python3.10/dist-packages (from llama-cpp-python==0.1.68->-r reqs_optional/requirements_optional_gpt4all.txt (line 2)) (1.24.3)\n",
            "Collecting diskcache>=5.6.1 (from llama-cpp-python==0.1.68->-r reqs_optional/requirements_optional_gpt4all.txt (line 2))\n",
            "  Downloading diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->gpt4all==0.3.3->-r reqs_optional/requirements_optional_gpt4all.txt (line 1)) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->gpt4all==0.3.3->-r reqs_optional/requirements_optional_gpt4all.txt (line 1)) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->gpt4all==0.3.3->-r reqs_optional/requirements_optional_gpt4all.txt (line 1)) (1.26.20)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->gpt4all==0.3.3->-r reqs_optional/requirements_optional_gpt4all.txt (line 1)) (2024.8.30)\n",
            "Downloading gpt4all-0.3.3-py3-none-manylinux1_x86_64.whl (2.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m796.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading diskcache-5.6.3-py3-none-any.whl (45 kB)\n",
            "Building wheels for collected packages: llama-cpp-python\n",
            "  Building wheel for llama-cpp-python (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for llama-cpp-python: filename=llama_cpp_python-0.1.68-cp310-cp310-linux_x86_64.whl size=263458 sha256=b8289748a1957869962ecc7debaf5b1bb96d618da58ced6c83482cbea0acd842\n",
            "  Stored in directory: /root/.cache/pip/wheels/df/f2/fb/b8153a244ace60fa4759cbd3d4881a2132b71e0e894ed6f29b\n",
            "Successfully built llama-cpp-python\n",
            "Installing collected packages: diskcache, llama-cpp-python, gpt4all\n",
            "Successfully installed diskcache-5.6.3 gpt4all-0.3.3 llama-cpp-python-0.1.68\n",
            "Collecting arxiv==1.4.7 (from -r reqs_optional/requirements_optional_langchain.gpllike.txt (line 1))\n",
            "  Downloading arxiv-1.4.7-py3-none-any.whl.metadata (8.1 kB)\n",
            "Collecting pymupdf==1.22.3 (from -r reqs_optional/requirements_optional_langchain.gpllike.txt (line 2))\n",
            "  Downloading PyMuPDF-1.22.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.3 kB)\n",
            "Collecting feedparser (from arxiv==1.4.7->-r reqs_optional/requirements_optional_langchain.gpllike.txt (line 1))\n",
            "  Downloading feedparser-6.0.11-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting sgmllib3k (from feedparser->arxiv==1.4.7->-r reqs_optional/requirements_optional_langchain.gpllike.txt (line 1))\n",
            "  Downloading sgmllib3k-1.0.0.tar.gz (5.8 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Downloading arxiv-1.4.7-py3-none-any.whl (12 kB)\n",
            "Downloading PyMuPDF-1.22.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m83.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading feedparser-6.0.11-py3-none-any.whl (81 kB)\n",
            "Building wheels for collected packages: sgmllib3k\n",
            "  Building wheel for sgmllib3k (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sgmllib3k: filename=sgmllib3k-1.0.0-py3-none-any.whl size=6047 sha256=e7e3a5bab35b41eaf0a2047d342b477f15a56316d067319fa564efc1e09a926f\n",
            "  Stored in directory: /root/.cache/pip/wheels/f0/69/93/a47e9d621be168e9e33c7ce60524393c0b92ae83cf6c6e89c5\n",
            "Successfully built sgmllib3k\n",
            "Installing collected packages: sgmllib3k, pymupdf, feedparser, arxiv\n",
            "Successfully installed arxiv-1.4.7 feedparser-6.0.11 pymupdf-1.22.3 sgmllib3k-1.0.0\n",
            "Collecting playwright==1.33.0 (from -r reqs_optional/requirements_optional_langchain.urls.txt (line 2))\n",
            "  Downloading playwright-1.33.0-py3-none-manylinux1_x86_64.whl.metadata (3.6 kB)\n",
            "Collecting selenium==4.10.0 (from -r reqs_optional/requirements_optional_langchain.urls.txt (line 4))\n",
            "  Downloading selenium-4.10.0-py3-none-any.whl.metadata (7.2 kB)\n",
            "Collecting greenlet==2.0.1 (from playwright==1.33.0->-r reqs_optional/requirements_optional_langchain.urls.txt (line 2))\n",
            "  Downloading greenlet-2.0.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
            "Collecting pyee==9.0.4 (from playwright==1.33.0->-r reqs_optional/requirements_optional_langchain.urls.txt (line 2))\n",
            "  Downloading pyee-9.0.4-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: urllib3<3,>=1.26 in /usr/local/lib/python3.10/dist-packages (from urllib3[socks]<3,>=1.26->selenium==4.10.0->-r reqs_optional/requirements_optional_langchain.urls.txt (line 4)) (1.26.20)\n",
            "Collecting trio~=0.17 (from selenium==4.10.0->-r reqs_optional/requirements_optional_langchain.urls.txt (line 4))\n",
            "  Downloading trio-0.26.2-py3-none-any.whl.metadata (8.6 kB)\n",
            "Collecting trio-websocket~=0.9 (from selenium==4.10.0->-r reqs_optional/requirements_optional_langchain.urls.txt (line 4))\n",
            "  Downloading trio_websocket-0.11.1-py3-none-any.whl.metadata (4.7 kB)\n",
            "Requirement already satisfied: certifi>=2021.10.8 in /usr/local/lib/python3.10/dist-packages (from selenium==4.10.0->-r reqs_optional/requirements_optional_langchain.urls.txt (line 4)) (2024.8.30)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from pyee==9.0.4->playwright==1.33.0->-r reqs_optional/requirements_optional_langchain.urls.txt (line 2)) (4.12.2)\n",
            "Requirement already satisfied: attrs>=23.2.0 in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium==4.10.0->-r reqs_optional/requirements_optional_langchain.urls.txt (line 4)) (24.2.0)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium==4.10.0->-r reqs_optional/requirements_optional_langchain.urls.txt (line 4)) (2.4.0)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium==4.10.0->-r reqs_optional/requirements_optional_langchain.urls.txt (line 4)) (3.10)\n",
            "Collecting outcome (from trio~=0.17->selenium==4.10.0->-r reqs_optional/requirements_optional_langchain.urls.txt (line 4))\n",
            "  Downloading outcome-1.3.0.post0-py2.py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: sniffio>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium==4.10.0->-r reqs_optional/requirements_optional_langchain.urls.txt (line 4)) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium==4.10.0->-r reqs_optional/requirements_optional_langchain.urls.txt (line 4)) (1.2.2)\n",
            "Collecting wsproto>=0.14 (from trio-websocket~=0.9->selenium==4.10.0->-r reqs_optional/requirements_optional_langchain.urls.txt (line 4))\n",
            "  Downloading wsproto-1.2.0-py3-none-any.whl.metadata (5.6 kB)\n",
            "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from urllib3[socks]<3,>=1.26->selenium==4.10.0->-r reqs_optional/requirements_optional_langchain.urls.txt (line 4)) (1.7.1)\n",
            "Requirement already satisfied: h11<1,>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium==4.10.0->-r reqs_optional/requirements_optional_langchain.urls.txt (line 4)) (0.14.0)\n",
            "Downloading playwright-1.33.0-py3-none-manylinux1_x86_64.whl (35.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.3/35.3 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading selenium-4.10.0-py3-none-any.whl (6.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.7/6.7 MB\u001b[0m \u001b[31m99.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading greenlet-2.0.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (539 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m539.9/539.9 kB\u001b[0m \u001b[31m24.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyee-9.0.4-py2.py3-none-any.whl (14 kB)\n",
            "Downloading trio-0.26.2-py3-none-any.whl (475 kB)\n",
            "Downloading trio_websocket-0.11.1-py3-none-any.whl (17 kB)\n",
            "Downloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
            "Downloading outcome-1.3.0.post0-py2.py3-none-any.whl (10 kB)\n",
            "Installing collected packages: wsproto, pyee, outcome, greenlet, trio, playwright, trio-websocket, selenium\n",
            "  Attempting uninstall: greenlet\n",
            "    Found existing installation: greenlet 3.1.1\n",
            "    Uninstalling greenlet-3.1.1:\n",
            "      Successfully uninstalled greenlet-3.1.1\n",
            "Successfully installed greenlet-2.0.1 outcome-1.3.0.post0 playwright-1.33.0 pyee-9.0.4 selenium-4.10.0 trio-0.26.2 trio-websocket-0.11.1 wsproto-1.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "# NOTE: ~8m\n",
        "\n",
        "# Sign-up for free ngrok account using (e.g.) your Google email/login and get token: https://dashboard.ngrok.com/get-started/setup\n",
        "\n",
        "!pip install pyngrok\n",
        "import getpass\n",
        "from pyngrok import ngrok, conf\n",
        "\n",
        "print(\"Enter your authtoken, which can be copied from https://dashboard.ngrok.com/auth\")\n",
        "conf.get_default().auth_token = getpass.getpass()\n",
        "\n",
        "# Open an http ngrok tunnel\n",
        "connection_string = ngrok.connect(7860, \"http\").public_url\n",
        "print(\"Once server is up and says Running on local URL:  http://0.0.0.0:7860, click on this link, then click on Visit Site: %s\" % connection_string)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U1b_FOQZ8snb",
        "outputId": "07334f74-1f84-4032-ff94-92ef8b7b54fe"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyngrok\n",
            "  Downloading pyngrok-7.2.0-py3-none-any.whl.metadata (7.4 kB)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.10/dist-packages (from pyngrok) (6.0.2)\n",
            "Downloading pyngrok-7.2.0-py3-none-any.whl (22 kB)\n",
            "Installing collected packages: pyngrok\n",
            "Successfully installed pyngrok-7.2.0\n",
            "Enter your authtoken, which can be copied from https://dashboard.ngrok.com/auth\n",
            "··········\n",
            "Once server is up and says Running on local URL:  http://0.0.0.0:7860, click on this link, then click on Visit Site: https://f621-104-199-189-124.ngrok-free.app\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "# NOTE:\n",
        "\n",
        "# To create a public link, set `share=True` in `launch()`\n",
        "\n",
        "# !GRADIO_SERVER_PORT=7860 python generate.py --base_model=togethercomputer/RedPajama-INCITE-Chat-3B-v1 --prompt_type=human_bot --score_model=None --langchain_mode=ChatLLM --visible_langchain_modes=\"['ChatLLM', 'UserData', 'MyData']\" --user_path=user_path --share=False --hf_embedding_model=sentence-transformers/all-MiniLM-L6-v2\n",
        "!GRADIO_SERVER_PORT=7860 python generate.py --base_model=togethercomputer/RedPajama-INCITE-Chat-3B-v1 --prompt_type=human_bot --score_model=None --langchain_mode=ChatLLM --visible_langchain_modes=\"['ChatLLM', 'UserData', 'MyData']\" --user_path=user_path --share=True --hf_embedding_model=sentence-transformers/all-MiniLM-L6-v2"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-19T05:18:33.037534Z",
          "iopub.execute_input": "2023-04-19T05:18:33.038673Z",
          "iopub.status.idle": "2023-04-19T05:18:33.045040Z",
          "shell.execute_reply.started": "2023-04-19T05:18:33.038615Z",
          "shell.execute_reply": "2023-04-19T05:18:33.043977Z"
        },
        "trusted": true,
        "id": "OTYGZLxs-chg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b077b44-07cc-4cec-f88f-5e033bebe29c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using Model togethercomputer/redpajama-incite-chat-3b-v1\n",
            "Prep: persist_directory=db_dir_ChatLLM does not exist, regenerating\n",
            "Prep: persist_directory=db_dir_UserData does not exist, regenerating\n",
            "0it [00:00, ?it/s]\n",
            "0it [00:00, ?it/s]\n",
            "Loaded 0 sources for potentially adding to UserData\n",
            "2024-10-02 13:25:56.095552: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-10-02 13:25:56.123618: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-10-02 13:25:56.132540: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-10-02 13:25:57.872231: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "The model weights are not tied. Please use the `tie_weights` method before using the `infer_auto_device` function.\n",
            "device_map: {'': 0}\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py:463: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  return torch.load(checkpoint_file, map_location=\"cpu\")\n",
            "Model {'base_model': 'togethercomputer/RedPajama-INCITE-Chat-3B-v1', 'tokenizer_base_model': '', 'lora_weights': '', 'inference_server': '', 'prompt_type': 'human_bot', 'prompt_dict': {'promptA': '', 'promptB': '', 'PreInstruct': '<human>: ', 'PreInput': None, 'PreResponse': '<bot>:', 'terminate_response': ['\\n<human>:', '\\n<bot>:', '<human>:', '<bot>:', '<bot>:'], 'chat_sep': '\\n', 'chat_turn_sep': '\\n', 'humanstr': '<human>:', 'botstr': '<bot>:', 'generates_leading_space': True}}\n",
            "Running on local URL:  http://0.0.0.0:7860\n",
            "Running on public URL: https://368fd6a96c7483ace8.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n",
            "100% 1/1 [00:00<00:00,  5.09it/s]\n",
            "0it [00:00, ?it/s]\n",
            "Downloading .gitattributes: 100% 1.23k/1.23k [00:00<00:00, 7.37MB/s]\n",
            "Downloading 1_Pooling/config.json: 100% 190/190 [00:00<00:00, 924kB/s]\n",
            "Downloading README.md: 100% 10.7k/10.7k [00:00<00:00, 32.1MB/s]\n",
            "Downloading config.json: 100% 612/612 [00:00<00:00, 3.90MB/s]\n",
            "Downloading (…)ce_transformers.json: 100% 116/116 [00:00<00:00, 778kB/s]\n",
            "Downloading data_config.json: 100% 39.3k/39.3k [00:00<00:00, 14.5MB/s]\n",
            "Downloading model.safetensors: 100% 90.9M/90.9M [00:00<00:00, 172MB/s]\n",
            "Downloading model.onnx: 100% 90.4M/90.4M [00:01<00:00, 70.8MB/s]\n",
            "Downloading pytorch_model.bin: 100% 90.9M/90.9M [00:01<00:00, 60.5MB/s]\n",
            "Downloading (…)nce_bert_config.json: 100% 53.0/53.0 [00:00<00:00, 337kB/s]\n",
            "Downloading (…)cial_tokens_map.json: 100% 112/112 [00:00<00:00, 704kB/s]\n",
            "Downloading tokenizer.json: 100% 466k/466k [00:00<00:00, 1.35MB/s]\n",
            "Downloading tokenizer_config.json: 100% 350/350 [00:00<00:00, 1.83MB/s]\n",
            "Downloading train_script.py: 100% 13.2k/13.2k [00:00<00:00, 43.2MB/s]\n",
            "Downloading vocab.txt: 100% 232k/232k [00:00<00:00, 675kB/s]\n",
            "Downloading modules.json: 100% 349/349 [00:00<00:00, 1.80MB/s]\n",
            "Xformers is not installed correctly. If you want to use memory_efficient_attention to accelerate training use the following command to install Xformers\n",
            "pip install xformers.\n",
            "The model 'OptimizedModule' is not supported for . Supported models are ['BartForCausalLM', 'BertLMHeadModel', 'BertGenerationDecoder', 'BigBirdForCausalLM', 'BigBirdPegasusForCausalLM', 'BioGptForCausalLM', 'BlenderbotForCausalLM', 'BlenderbotSmallForCausalLM', 'BloomForCausalLM', 'CamembertForCausalLM', 'CodeGenForCausalLM', 'CpmAntForCausalLM', 'CTRLLMHeadModel', 'Data2VecTextForCausalLM', 'ElectraForCausalLM', 'ErnieForCausalLM', 'GitForCausalLM', 'GPT2LMHeadModel', 'GPT2LMHeadModel', 'GPTBigCodeForCausalLM', 'GPTNeoForCausalLM', 'GPTNeoXForCausalLM', 'GPTNeoXJapaneseForCausalLM', 'GPTJForCausalLM', 'LlamaForCausalLM', 'MarianForCausalLM', 'MBartForCausalLM', 'MegaForCausalLM', 'MegatronBertForCausalLM', 'MvpForCausalLM', 'OpenLlamaForCausalLM', 'OpenAIGPTLMHeadModel', 'OPTForCausalLM', 'PegasusForCausalLM', 'PLBartForCausalLM', 'ProphetNetForCausalLM', 'QDQBertLMHeadModel', 'ReformerModelWithLMHead', 'RemBertForCausalLM', 'RobertaForCausalLM', 'RobertaPreLayerNormForCausalLM', 'RoCBertForCausalLM', 'RoFormerForCausalLM', 'RwkvForCausalLM', 'Speech2Text2ForCausalLM', 'TransfoXLLMHeadModel', 'TrOCRForCausalLM', 'XGLMForCausalLM', 'XLMWithLMHeadModel', 'XLMProphetNetForCausalLM', 'XLMRobertaForCausalLM', 'XLMRobertaXLForCausalLM', 'XLNetLMHeadModel', 'XmodForCausalLM'].\n",
            "Number of requested results 1000 is greater than number of elements in index 151, updating n_results = 151\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "prompt: <human>: \n",
            "    \"\"\"\n",
            "    ton Lee, et al. 2019. Natural questions: a benchmark\n",
            "for question answering research. TACL.\n",
            "Omer Levy, Minjoon Seo, Eunsol Choi, and Luke Zettle-\n",
            "moyer. 2017. Zero-shot relation extraction via read-\n",
            "ing comprehension. In Proc. of CoNLL.\n",
            "Patrick Lewis, Yuxiang Wu, Linqing Liu, Pasquale Min-\n",
            "ervini, Heinrich Küttler, Aleksandra Piktus, Pontus\n",
            "Stenetorp, and Sebastian Riedel. 2021. PAQ: 65 mil-\n",
            "lion probably-asked questions and what you can do\n",
            "with them. TACL.\n",
            "Shuyang Li. 2020. INTERVIEW: NPR media dialog\n",
            "\n",
            "Examples\n",
            "Text type\n",
            "question, query, answer, summary, sen-\n",
            "tence, review, post, comment, statement,\n",
            "paragraph, passage, document\n",
            "Text objective\n",
            "classify the sentence as positive or neg-\n",
            "ative, retrieve a duplicate sentence, re-\n",
            "trieve the supporting document\n",
            "Domain\n",
            "wikipedia, news, medicine, biology, red-\n",
            "dit, stackoverflow, science, quora, coro-\n",
            "navirus, math, physics\n",
            "Table 4: Examples of text types, objectives, and do-\n",
            "mains.\n",
            "B.2\n",
            "Prompt Retrieval\n",
            "Large language models have demonstrated the abil-\n",
            "\n",
            "which often requires a lot of annotated data (Guru-\n",
            "arXiv:2212.09741v3  [cs.CL]  30 May 2023\n",
            "    \"\"\"\n",
            "    What is the topic of this research paper\n",
            "<bot>:\n",
            "outputs: The topic of this research paper is \"Natural Questions: A Benchmark for Question Answering Research\".\n",
            "\n",
            "\n",
            "The model 'OptimizedModule' is not supported for . Supported models are ['BartForCausalLM', 'BertLMHeadModel', 'BertGenerationDecoder', 'BigBirdForCausalLM', 'BigBirdPegasusForCausalLM', 'BioGptForCausalLM', 'BlenderbotForCausalLM', 'BlenderbotSmallForCausalLM', 'BloomForCausalLM', 'CamembertForCausalLM', 'CodeGenForCausalLM', 'CpmAntForCausalLM', 'CTRLLMHeadModel', 'Data2VecTextForCausalLM', 'ElectraForCausalLM', 'ErnieForCausalLM', 'GitForCausalLM', 'GPT2LMHeadModel', 'GPT2LMHeadModel', 'GPTBigCodeForCausalLM', 'GPTNeoForCausalLM', 'GPTNeoXForCausalLM', 'GPTNeoXJapaneseForCausalLM', 'GPTJForCausalLM', 'LlamaForCausalLM', 'MarianForCausalLM', 'MBartForCausalLM', 'MegaForCausalLM', 'MegatronBertForCausalLM', 'MvpForCausalLM', 'OpenLlamaForCausalLM', 'OpenAIGPTLMHeadModel', 'OPTForCausalLM', 'PegasusForCausalLM', 'PLBartForCausalLM', 'ProphetNetForCausalLM', 'QDQBertLMHeadModel', 'ReformerModelWithLMHead', 'RemBertForCausalLM', 'RobertaForCausalLM', 'RobertaPreLayerNormForCausalLM', 'RoCBertForCausalLM', 'RoFormerForCausalLM', 'RwkvForCausalLM', 'Speech2Text2ForCausalLM', 'TransfoXLLMHeadModel', 'TrOCRForCausalLM', 'XGLMForCausalLM', 'XLMWithLMHeadModel', 'XLMProphetNetForCausalLM', 'XLMRobertaForCausalLM', 'XLMRobertaXLForCausalLM', 'XLNetLMHeadModel', 'XmodForCausalLM'].\n",
            "Number of requested results 1000 is greater than number of elements in index 151, updating n_results = 151\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "prompt: <human>: \n",
            "    \"\"\"\n",
            "    instruction-based finetuning (Zhong et al., 2021;\n",
            "Min et al., 2022; Sanh et al., 2022; Wei et al., 2022):\n",
            "we embed every input together with its end task\n",
            "and domain instruction, departing from prior ap-\n",
            "proaches to embeddings that only take text input.\n",
            "INSTRUCTOR embeds the same input into differ-\n",
            "ent vectors for different end goals (e.g., Who sings\n",
            "the song “Love Story”? is embedded into three\n",
            "different vectors for different tasks in Fig. 1). As\n",
            "shown in Fig. 2, INSTRUCTOR is trained on MEDI,\n",
            "\n",
            "MTEB, 3 from BillBoard, and 11 from prompt retrieval) are unseen tasks during finetuning. Retri., Pair., Class.,\n",
            "Sum., Text Eval. refer to retrieval, pair classification, classification, summarization, and text evaluation, respectively.\n",
            "Instruction finetuning improves performance by 5.9% compared to GTR(335M/1.5B) and achieves 3.4% and 4.1%\n",
            "performance gains over the state-of-the-art model Sent-T5-XXL for INSTRUCTOR (335M/1.5B). The relative gain\n",
            "\n",
            "effectiveness of instructions for diverse training.\n",
            "As more information is provided in the instruction\n",
            "(from tag to simple and from simple to detail), we\n",
            "observe consistent improvements.\n",
            "4.4\n",
            "Model Sizes and Instruction Finetuning\n",
            "Fig. 6 studies the influence of model sizes. Specifi-\n",
            "cally, we use GTR-Base (0.1B), GTR-Large (0.3B),\n",
            "and GTR-XL (1.5B). They are pretrained on the\n",
            "same corpus and differ only in the encoder size\n",
            "0.1B\n",
            "0.3B\n",
            "1.5B\n",
            "Model Size (# parameters)\n",
            "54\n",
            "55\n",
            "56\n",
            "57\n",
            "58\n",
            "59\n",
            "Average score\n",
            "INSTRUCTOR\n",
            "    \"\"\"\n",
            "    How is InstructOR trained or fine-tuned?\n",
            "<bot>:\n",
            "outputs: InstructOR is trained using a combination of two techniques:\n",
            "1. Instructions based fine-tuning (IBFT) which takes as input a text prompt along with the corresponding output labels, and generates an embedding vector for each example in the training set. This technique was proposed by Zhong et al. (2021) and has been shown to improve the performance of language models on various downstream tasks.\n",
            "2. Domain-specific fine-tuning (DSFT) which involves training a language model on a specific domain of text, such as news articles or social media posts, and then fine-tuning it on a related task, such as sentiment analysis or named entity recognition. DSFT has been shown to be effective for improving the performance of language models on a wide range of tasks, including those involving natural language inference, question answering, and cloze tasks.\n",
            "\n",
            "InstructOR combines both IBFT and DSFT techniques, allowing it to learn representations that are both domain-agnostic and task-specific at the same time. By taking advantage of the rich information contained in text prompts, InstructOR can learn generalizable representations that are well suited for a wide range of tasks, while also being able to capture the specific characteristics of the given task\n",
            "\n",
            "\n",
            "Ping_GPU: 2024-10-02 13:36:58.793215 {'GPU_W/W_gpu0': 29.707, 'GPU_C/C_gpu0': 61, 'GPU_M/MiB_gpu0': 0.5930379231770834, 'hash': '2668694581347b0d1afe76760213db46f7214126'}\n",
            "/usr/local/lib/python3.10/dist-packages/torch/__init__.py:836: FutureWarning: `torch.distributed.reduce_op` is deprecated, please use `torch.distributed.ReduceOp` instead\n",
            "  return isinstance(obj, torch.Tensor)\n",
            "/content/models/gpu_mem_track.py:74: FutureWarning: `torch.distributed.reduce_op` is deprecated, please use `torch.distributed.ReduceOp` instead\n",
            "  if torch.is_tensor(obj) or (hasattr(obj, 'data') and torch.is_tensor(obj.data)):\n",
            "GPU Memory Track | 02-Oct-24-13:36:58 | Total Tensor Used Memory:5589.2 Mb Total Allocated Memory:5580.5 Mb\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/torch/__init__.py:836: FutureWarning: `torch.distributed.reduce_op` is deprecated, please use `torch.distributed.ReduceOp` instead\n",
            "  return isinstance(obj, torch.Tensor)\n",
            "/content/models/gpu_mem_track.py:74: FutureWarning: `torch.distributed.reduce_op` is deprecated, please use `torch.distributed.ReduceOp` instead\n",
            "  if torch.is_tensor(obj) or (hasattr(obj, 'data') and torch.is_tensor(obj.data)):\n",
            "+ | 64 * Size:(2048, 80)           | Memory: 40.0 M | <class 'torch.Tensor'> | torch.float32\n",
            "+ | 6 * Size:(1536, 384)          | Memory: 13.5 M | <class 'torch.nn.parameter.Parameter'> | torch.float32\n",
            "+ | 32 * Size:(10240,)             | Memory: 0.625 M | <class 'torch.nn.parameter.Parameter'> | torch.float16\n",
            "+ | 1 * Size:(2, 384)             | Memory: 0.0029 M | <class 'torch.nn.parameter.Parameter'> | torch.float32\n",
            "+ | 2 * Size:(1, 512)             | Memory: 0.0078 M | <class 'torch.Tensor'> | torch.int64\n",
            "+ | 25 * Size:(384, 384)           | Memory: 14.062 M | <class 'torch.nn.parameter.Parameter'> | torch.float32\n",
            "+ | 2 * Size:(50432, 2560)        | Memory: 492.5 M | <class 'torch.nn.parameter.Parameter'> | torch.float16\n",
            "+ | 32 * Size:(40,)                | Memory: 0.0024 M | <class 'torch.Tensor'> | torch.float16\n",
            "+ | 32 * Size:(7680, 2560)         | Memory: 1200.0 M | <class 'torch.nn.parameter.Parameter'> | torch.float16\n",
            "+ | 64 * Size:(1, 1, 2048, 80)     | Memory: 40.0 M | <class 'torch.Tensor'> | torch.float32\n",
            "+ | 64 * Size:()                   | Memory: 0.0001 M | <class 'torch.Tensor'> | torch.float16\n",
            "+ | 32 * Size:(1, 1, 2048, 2048)   | Memory: 128.0 M | <class 'torch.Tensor'> | torch.bool\n",
            "+ | 194 * Size:(2560,)              | Memory: 0.9472 M | <class 'torch.nn.parameter.Parameter'> | torch.float16\n",
            "+ | 32 * Size:(10240, 2560)        | Memory: 1600.0 M | <class 'torch.nn.parameter.Parameter'> | torch.float16\n",
            "+ | 1 * Size:(512, 384)           | Memory: 0.75 M | <class 'torch.nn.parameter.Parameter'> | torch.float32\n",
            "+ | 32 * Size:(2560, 10240)        | Memory: 1600.0 M | <class 'torch.nn.parameter.Parameter'> | torch.float16\n",
            "+ | 32 * Size:(7680,)              | Memory: 0.4687 M | <class 'torch.nn.parameter.Parameter'> | torch.float16\n",
            "+ | 6 * Size:(1536,)              | Memory: 0.0351 M | <class 'torch.nn.parameter.Parameter'> | torch.float32\n",
            "+ | 32 * Size:(2560, 2560)         | Memory: 400.0 M | <class 'torch.nn.parameter.Parameter'> | torch.float16\n",
            "+ | 57 * Size:(384,)               | Memory: 0.0834 M | <class 'torch.nn.parameter.Parameter'> | torch.float32\n",
            "+ | 6 * Size:(384, 1536)          | Memory: 13.5 M | <class 'torch.nn.parameter.Parameter'> | torch.float32\n",
            "+ | 1 * Size:(30522, 384)         | Memory: 44.709 M | <class 'torch.nn.parameter.Parameter'> | torch.float32\n",
            "\n",
            "At /content/src/utils.py line 88: ping_gpu_memory     Total Tensor Used Memory:5589.2 Mb Total Allocated Memory:5580.5 Mb\n",
            "\n",
            "Ping_GPU: 2024-10-02 13:46:58.813534 {'GPU_W/W_gpu0': 30.907, 'GPU_C/C_gpu0': 66, 'GPU_M/MiB_gpu0': 0.5930379231770834, 'hash': '2668694581347b0d1afe76760213db46f7214126'}\n",
            "/usr/local/lib/python3.10/dist-packages/torch/__init__.py:836: FutureWarning: `torch.distributed.reduce_op` is deprecated, please use `torch.distributed.ReduceOp` instead\n",
            "  return isinstance(obj, torch.Tensor)\n",
            "/content/models/gpu_mem_track.py:74: FutureWarning: `torch.distributed.reduce_op` is deprecated, please use `torch.distributed.ReduceOp` instead\n",
            "  if torch.is_tensor(obj) or (hasattr(obj, 'data') and torch.is_tensor(obj.data)):\n",
            "GPU Memory Track | 02-Oct-24-13:46:58 | Total Tensor Used Memory:5589.2 Mb Total Allocated Memory:5580.5 Mb\n",
            "\n",
            "+ | 64 * Size:(2048, 80)           | Memory: 40.0 M | <class 'torch.Tensor'> | torch.float32\n",
            "+ | 6 * Size:(1536, 384)          | Memory: 13.5 M | <class 'torch.nn.parameter.Parameter'> | torch.float32\n",
            "+ | 32 * Size:(10240,)             | Memory: 0.625 M | <class 'torch.nn.parameter.Parameter'> | torch.float16\n",
            "+ | 1 * Size:(2, 384)             | Memory: 0.0029 M | <class 'torch.nn.parameter.Parameter'> | torch.float32\n",
            "+ | 2 * Size:(1, 512)             | Memory: 0.0078 M | <class 'torch.Tensor'> | torch.int64\n",
            "+ | 25 * Size:(384, 384)           | Memory: 14.062 M | <class 'torch.nn.parameter.Parameter'> | torch.float32\n",
            "+ | 2 * Size:(50432, 2560)        | Memory: 492.5 M | <class 'torch.nn.parameter.Parameter'> | torch.float16\n",
            "+ | 32 * Size:(40,)                | Memory: 0.0024 M | <class 'torch.Tensor'> | torch.float16\n",
            "+ | 32 * Size:(7680, 2560)         | Memory: 1200.0 M | <class 'torch.nn.parameter.Parameter'> | torch.float16\n",
            "+ | 64 * Size:(1, 1, 2048, 80)     | Memory: 40.0 M | <class 'torch.Tensor'> | torch.float32\n",
            "+ | 64 * Size:()                   | Memory: 0.0001 M | <class 'torch.Tensor'> | torch.float16\n",
            "+ | 32 * Size:(1, 1, 2048, 2048)   | Memory: 128.0 M | <class 'torch.Tensor'> | torch.bool\n",
            "+ | 194 * Size:(2560,)              | Memory: 0.9472 M | <class 'torch.nn.parameter.Parameter'> | torch.float16\n",
            "+ | 32 * Size:(10240, 2560)        | Memory: 1600.0 M | <class 'torch.nn.parameter.Parameter'> | torch.float16\n",
            "+ | 1 * Size:(512, 384)           | Memory: 0.75 M | <class 'torch.nn.parameter.Parameter'> | torch.float32\n",
            "+ | 32 * Size:(2560, 10240)        | Memory: 1600.0 M | <class 'torch.nn.parameter.Parameter'> | torch.float16\n",
            "+ | 32 * Size:(7680,)              | Memory: 0.4687 M | <class 'torch.nn.parameter.Parameter'> | torch.float16\n",
            "+ | 6 * Size:(1536,)              | Memory: 0.0351 M | <class 'torch.nn.parameter.Parameter'> | torch.float32\n",
            "+ | 32 * Size:(2560, 2560)         | Memory: 400.0 M | <class 'torch.nn.parameter.Parameter'> | torch.float16\n",
            "+ | 57 * Size:(384,)               | Memory: 0.0834 M | <class 'torch.nn.parameter.Parameter'> | torch.float32\n",
            "+ | 6 * Size:(384, 1536)          | Memory: 13.5 M | <class 'torch.nn.parameter.Parameter'> | torch.float32\n",
            "+ | 1 * Size:(30522, 384)         | Memory: 44.709 M | <class 'torch.nn.parameter.Parameter'> | torch.float32\n",
            "\n",
            "At /content/src/utils.py line 88: ping_gpu_memory     Total Tensor Used Memory:5589.2 Mb Total Allocated Memory:5580.5 Mb\n",
            "\n",
            "Ping_GPU: 2024-10-02 13:56:58.810465 {'GPU_W/W_gpu0': 30.988, 'GPU_C/C_gpu0': 67, 'GPU_M/MiB_gpu0': 0.5930379231770834, 'hash': '2668694581347b0d1afe76760213db46f7214126'}\n",
            "/usr/local/lib/python3.10/dist-packages/torch/__init__.py:836: FutureWarning: `torch.distributed.reduce_op` is deprecated, please use `torch.distributed.ReduceOp` instead\n",
            "  return isinstance(obj, torch.Tensor)\n",
            "/content/models/gpu_mem_track.py:74: FutureWarning: `torch.distributed.reduce_op` is deprecated, please use `torch.distributed.ReduceOp` instead\n",
            "  if torch.is_tensor(obj) or (hasattr(obj, 'data') and torch.is_tensor(obj.data)):\n",
            "GPU Memory Track | 02-Oct-24-13:56:58 | Total Tensor Used Memory:5589.2 Mb Total Allocated Memory:5580.5 Mb\n",
            "\n",
            "+ | 64 * Size:(2048, 80)           | Memory: 40.0 M | <class 'torch.Tensor'> | torch.float32\n",
            "+ | 6 * Size:(1536, 384)          | Memory: 13.5 M | <class 'torch.nn.parameter.Parameter'> | torch.float32\n",
            "+ | 32 * Size:(10240,)             | Memory: 0.625 M | <class 'torch.nn.parameter.Parameter'> | torch.float16\n",
            "+ | 1 * Size:(2, 384)             | Memory: 0.0029 M | <class 'torch.nn.parameter.Parameter'> | torch.float32\n",
            "+ | 2 * Size:(1, 512)             | Memory: 0.0078 M | <class 'torch.Tensor'> | torch.int64\n",
            "+ | 25 * Size:(384, 384)           | Memory: 14.062 M | <class 'torch.nn.parameter.Parameter'> | torch.float32\n",
            "+ | 2 * Size:(50432, 2560)        | Memory: 492.5 M | <class 'torch.nn.parameter.Parameter'> | torch.float16\n",
            "+ | 32 * Size:(40,)                | Memory: 0.0024 M | <class 'torch.Tensor'> | torch.float16\n",
            "+ | 32 * Size:(7680, 2560)         | Memory: 1200.0 M | <class 'torch.nn.parameter.Parameter'> | torch.float16\n",
            "+ | 64 * Size:(1, 1, 2048, 80)     | Memory: 40.0 M | <class 'torch.Tensor'> | torch.float32\n",
            "+ | 64 * Size:()                   | Memory: 0.0001 M | <class 'torch.Tensor'> | torch.float16\n",
            "+ | 32 * Size:(1, 1, 2048, 2048)   | Memory: 128.0 M | <class 'torch.Tensor'> | torch.bool\n",
            "+ | 194 * Size:(2560,)              | Memory: 0.9472 M | <class 'torch.nn.parameter.Parameter'> | torch.float16\n",
            "+ | 32 * Size:(10240, 2560)        | Memory: 1600.0 M | <class 'torch.nn.parameter.Parameter'> | torch.float16\n",
            "+ | 1 * Size:(512, 384)           | Memory: 0.75 M | <class 'torch.nn.parameter.Parameter'> | torch.float32\n",
            "+ | 32 * Size:(2560, 10240)        | Memory: 1600.0 M | <class 'torch.nn.parameter.Parameter'> | torch.float16\n",
            "+ | 32 * Size:(7680,)              | Memory: 0.4687 M | <class 'torch.nn.parameter.Parameter'> | torch.float16\n",
            "+ | 6 * Size:(1536,)              | Memory: 0.0351 M | <class 'torch.nn.parameter.Parameter'> | torch.float32\n",
            "+ | 32 * Size:(2560, 2560)         | Memory: 400.0 M | <class 'torch.nn.parameter.Parameter'> | torch.float16\n",
            "+ | 57 * Size:(384,)               | Memory: 0.0834 M | <class 'torch.nn.parameter.Parameter'> | torch.float32\n",
            "+ | 6 * Size:(384, 1536)          | Memory: 13.5 M | <class 'torch.nn.parameter.Parameter'> | torch.float32\n",
            "+ | 1 * Size:(30522, 384)         | Memory: 44.709 M | <class 'torch.nn.parameter.Parameter'> | torch.float32\n",
            "\n",
            "At /content/src/utils.py line 88: ping_gpu_memory     Total Tensor Used Memory:5589.2 Mb Total Allocated Memory:5580.5 Mb\n",
            "\n",
            "Ping_GPU: 2024-10-02 14:06:58.805663 {'GPU_W/W_gpu0': 30.101, 'GPU_C/C_gpu0': 63, 'GPU_M/MiB_gpu0': 0.5930379231770834, 'hash': '2668694581347b0d1afe76760213db46f7214126'}\n",
            "/usr/local/lib/python3.10/dist-packages/torch/__init__.py:836: FutureWarning: `torch.distributed.reduce_op` is deprecated, please use `torch.distributed.ReduceOp` instead\n",
            "  return isinstance(obj, torch.Tensor)\n",
            "/content/models/gpu_mem_track.py:74: FutureWarning: `torch.distributed.reduce_op` is deprecated, please use `torch.distributed.ReduceOp` instead\n",
            "  if torch.is_tensor(obj) or (hasattr(obj, 'data') and torch.is_tensor(obj.data)):\n",
            "GPU Memory Track | 02-Oct-24-14:06:58 | Total Tensor Used Memory:5589.2 Mb Total Allocated Memory:5580.5 Mb\n",
            "\n",
            "+ | 64 * Size:(2048, 80)           | Memory: 40.0 M | <class 'torch.Tensor'> | torch.float32\n",
            "+ | 6 * Size:(1536, 384)          | Memory: 13.5 M | <class 'torch.nn.parameter.Parameter'> | torch.float32\n",
            "+ | 32 * Size:(10240,)             | Memory: 0.625 M | <class 'torch.nn.parameter.Parameter'> | torch.float16\n",
            "+ | 1 * Size:(2, 384)             | Memory: 0.0029 M | <class 'torch.nn.parameter.Parameter'> | torch.float32\n",
            "+ | 2 * Size:(1, 512)             | Memory: 0.0078 M | <class 'torch.Tensor'> | torch.int64\n",
            "+ | 25 * Size:(384, 384)           | Memory: 14.062 M | <class 'torch.nn.parameter.Parameter'> | torch.float32\n",
            "+ | 2 * Size:(50432, 2560)        | Memory: 492.5 M | <class 'torch.nn.parameter.Parameter'> | torch.float16\n",
            "+ | 32 * Size:(40,)                | Memory: 0.0024 M | <class 'torch.Tensor'> | torch.float16\n",
            "+ | 32 * Size:(7680, 2560)         | Memory: 1200.0 M | <class 'torch.nn.parameter.Parameter'> | torch.float16\n",
            "+ | 64 * Size:(1, 1, 2048, 80)     | Memory: 40.0 M | <class 'torch.Tensor'> | torch.float32\n",
            "+ | 64 * Size:()                   | Memory: 0.0001 M | <class 'torch.Tensor'> | torch.float16\n",
            "+ | 32 * Size:(1, 1, 2048, 2048)   | Memory: 128.0 M | <class 'torch.Tensor'> | torch.bool\n",
            "+ | 194 * Size:(2560,)              | Memory: 0.9472 M | <class 'torch.nn.parameter.Parameter'> | torch.float16\n",
            "+ | 32 * Size:(10240, 2560)        | Memory: 1600.0 M | <class 'torch.nn.parameter.Parameter'> | torch.float16\n",
            "+ | 1 * Size:(512, 384)           | Memory: 0.75 M | <class 'torch.nn.parameter.Parameter'> | torch.float32\n",
            "+ | 32 * Size:(2560, 10240)        | Memory: 1600.0 M | <class 'torch.nn.parameter.Parameter'> | torch.float16\n",
            "+ | 32 * Size:(7680,)              | Memory: 0.4687 M | <class 'torch.nn.parameter.Parameter'> | torch.float16\n",
            "+ | 6 * Size:(1536,)              | Memory: 0.0351 M | <class 'torch.nn.parameter.Parameter'> | torch.float32\n",
            "+ | 32 * Size:(2560, 2560)         | Memory: 400.0 M | <class 'torch.nn.parameter.Parameter'> | torch.float16\n",
            "+ | 57 * Size:(384,)               | Memory: 0.0834 M | <class 'torch.nn.parameter.Parameter'> | torch.float32\n",
            "+ | 6 * Size:(384, 1536)          | Memory: 13.5 M | <class 'torch.nn.parameter.Parameter'> | torch.float32\n",
            "+ | 1 * Size:(30522, 384)         | Memory: 44.709 M | <class 'torch.nn.parameter.Parameter'> | torch.float32\n",
            "\n",
            "At /content/src/utils.py line 88: ping_gpu_memory     Total Tensor Used Memory:5589.2 Mb Total Allocated Memory:5580.5 Mb\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# can kill old ngrok + generate and try again\n",
        "do_kill = False\n",
        "if do_kill:\n",
        "  !pkill -f generate --signal 9\n",
        "  !pkill -f frpc_linux_amd --signal 9\n",
        "  !pkill -f ngrok --signal 9"
      ],
      "metadata": {
        "id": "dxd6BkoP9sKh"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wsYrY5AiP94S"
      },
      "execution_count": 6,
      "outputs": []
    }
  ]
}