{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "How-to: Return structured output from LLMs | Langchain | Strategies & Code Implementation (22:43) (17 Aug 2024)\n",
        "\n",
        "* https://www.youtube.com/watch?v=eLL5Akg-UL8"
      ],
      "metadata": {
        "id": "5iXZPpOjT8QP"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o5uyYO9nTzZX"
      },
      "source": [
        "### High Level Strategies:\n",
        "1. Prompting\n",
        "2. Function calling\n",
        "3. Tool Calling\n",
        "4. Json Mode"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain_openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0yKy-8OEVMFl",
        "outputId": "5ee095e6-ae01-4a3b-a8a0-0b6734259c20"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain_openai\n",
            "  Downloading langchain_openai-0.1.23-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting langchain-core<0.3.0,>=0.2.35 (from langchain_openai)\n",
            "  Downloading langchain_core-0.2.39-py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting openai<2.0.0,>=1.40.0 (from langchain_openai)\n",
            "  Downloading openai-1.44.1-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting tiktoken<1,>=0.7 (from langchain_openai)\n",
            "  Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.35->langchain_openai) (6.0.2)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<0.3.0,>=0.2.35->langchain_openai)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting langsmith<0.2.0,>=0.1.112 (from langchain-core<0.3.0,>=0.2.35->langchain_openai)\n",
            "  Downloading langsmith-0.1.118-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.35->langchain_openai) (24.1)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.35->langchain_openai) (2.9.1)\n",
            "Collecting tenacity!=8.4.0,<9.0.0,>=8.1.0 (from langchain-core<0.3.0,>=0.2.35->langchain_openai)\n",
            "  Downloading tenacity-8.5.0-py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.35->langchain_openai) (4.12.2)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.40.0->langchain_openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai<2.0.0,>=1.40.0->langchain_openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai<2.0.0,>=1.40.0->langchain_openai)\n",
            "  Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting jiter<1,>=0.4.0 (from openai<2.0.0,>=1.40.0->langchain_openai)\n",
            "  Downloading jiter-0.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.40.0->langchain_openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.40.0->langchain_openai) (4.66.5)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.7->langchain_openai) (2024.5.15)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.7->langchain_openai) (2.32.3)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.40.0->langchain_openai) (3.8)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.40.0->langchain_openai) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.40.0->langchain_openai) (2024.8.30)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai<2.0.0,>=1.40.0->langchain_openai)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.40.0->langchain_openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.35->langchain_openai)\n",
            "  Downloading jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.112->langchain-core<0.3.0,>=0.2.35->langchain_openai)\n",
            "  Downloading orjson-3.10.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.3.0,>=0.2.35->langchain_openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.3.0,>=0.2.35->langchain_openai) (2.23.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain_openai) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain_openai) (2.0.7)\n",
            "Downloading langchain_openai-0.1.23-py3-none-any.whl (51 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.0/52.0 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_core-0.2.39-py3-none-any.whl (396 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m396.6/396.6 kB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading openai-1.44.1-py3-none-any.whl (373 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m373.5/373.5 kB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m36.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx-0.27.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jiter-0.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (318 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.9/318.9 kB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Downloading langsmith-0.1.118-py3-none-any.whl (289 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m289.3/289.3 kB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tenacity-8.5.0-py3-none-any.whl (28 kB)\n",
            "Downloading jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
            "Downloading orjson-3.10.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (141 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.9/141.9 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tenacity, orjson, jsonpointer, jiter, h11, tiktoken, jsonpatch, httpcore, httpx, openai, langsmith, langchain-core, langchain_openai\n",
            "  Attempting uninstall: tenacity\n",
            "    Found existing installation: tenacity 9.0.0\n",
            "    Uninstalling tenacity-9.0.0:\n",
            "      Successfully uninstalled tenacity-9.0.0\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.5 httpx-0.27.2 jiter-0.5.0 jsonpatch-1.33 jsonpointer-3.0.0 langchain-core-0.2.39 langchain_openai-0.1.23 langsmith-0.1.118 openai-1.44.1 orjson-3.10.7 tenacity-8.5.0 tiktoken-0.7.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain_community"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qlx7WybkV4j3",
        "outputId": "9cf1de73-5e50-4b89-9e00-5986bda06f2d"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain_community\n",
            "  Downloading langchain_community-0.2.16-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (2.0.34)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (3.10.5)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain_community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting langchain<0.3.0,>=0.2.16 (from langchain_community)\n",
            "  Downloading langchain-0.2.16-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: langchain-core<0.3.0,>=0.2.38 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.2.39)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.1.118)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (1.26.4)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (8.5.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.11.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (4.0.3)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading marshmallow-3.22.0-py3-none-any.whl.metadata (7.2 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting langchain-text-splitters<0.3.0,>=0.2.0 (from langchain<0.3.0,>=0.2.16->langchain_community)\n",
            "  Downloading langchain_text_splitters-0.2.4-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain<0.3.0,>=0.2.16->langchain_community) (2.9.1)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.38->langchain_community) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.38->langchain_community) (24.1)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.38->langchain_community) (4.12.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.0->langchain_community) (0.27.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.0->langchain_community) (3.10.7)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (2024.8.30)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.0.3)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain_community) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain_community) (1.0.5)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain_community) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain_community) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.38->langchain_community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.16->langchain_community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.16->langchain_community) (2.23.3)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain_community) (1.2.2)\n",
            "Downloading langchain_community-0.2.16-py3-none-any.whl (2.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m31.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading langchain-0.2.16-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m39.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_text_splitters-0.2.4-py3-none-any.whl (25 kB)\n",
            "Downloading marshmallow-3.22.0-py3-none-any.whl (49 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: mypy-extensions, marshmallow, typing-inspect, dataclasses-json, langchain-text-splitters, langchain, langchain_community\n",
            "Successfully installed dataclasses-json-0.6.7 langchain-0.2.16 langchain-text-splitters-0.2.4 langchain_community-0.2.16 marshmallow-3.22.0 mypy-extensions-1.0.0 typing-inspect-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "epRELsFXTzZa"
      },
      "source": [
        "Import LLM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "VXP_ny16TzZb"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import getpass\n",
        "from langchain_openai import ChatOpenAI"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "OPENAI_API_KEY = getpass.getpass(\"OpenAI API Key: \")\n",
        "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "slYybZErVlNg",
        "outputId": "e4001732-1afd-412d-edbb-a6a11d57cd22"
      },
      "execution_count": 6,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "OpenAI API Key: ··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "xA-uMIL7TzZd"
      },
      "outputs": [],
      "source": [
        "llm = ChatOpenAI(model = \"gpt-4o-mini\", api_key=os.environ.get(\"OPENAI_API_KEY\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "cC8jpU1YTzZe",
        "outputId": "3a40fe48-e89a-4502-859d-19c5f1c6c222",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='8.9 is greater than 8.11.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 11, 'prompt_tokens': 20, 'total_tokens': 31}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_483d39d857', 'finish_reason': 'stop', 'logprobs': None}, id='run-4b6ce6f8-2435-4c32-8a46-da538a8decaf-0', usage_metadata={'input_tokens': 20, 'output_tokens': 11, 'total_tokens': 31})"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "llm.invoke(\"which one is greater 8.11 or 8.9\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "z6qBFfriTzZf"
      },
      "outputs": [],
      "source": [
        "conversation = \t'''\n",
        "Alice: Hi, I bought a laptop from your store recently, but it's really slow and gets hot quickly. Can you help?\n",
        "John: Hi Alice, I'm sorry to hear that. I'm here to assist. Can you tell me the model and when you purchased it?\n",
        "Alice: It's the XYZ UltraBook 15, and I bought it two weeks ago.\n",
        "John: Thanks, Alice. The slowness could be due to background processes or memory issues. Does it happen with specific apps?\n",
        "Alice: Yes, mostly when I’m using video editing software or have many browser tabs open.\n",
        "John: That makes sense. Let’s check the Task Manager. Press Ctrl + Shift + Esc to see which processes are using a lot of resources.\n",
        "Alice: I see the video software and something called “svchost.exe” using a lot of memory.\n",
        "John: The video software is expected to use a lot, but svchost.exe might just need a restart to clear it up. How about the overheating?\n",
        "Alice: Yes, it gets really hot after a short time.\n",
        "John: Overheating can be due to blocked vents or high CPU usage. Try cleaning the vents and placing the laptop on a hard surface. If it continues, check for updates or bring it in for a diagnostic.\n",
        "Alice: Okay, I'll try that. Thanks for your help, John.\n",
        "John: You’re welcome, Alice! Let me know if you need anything else. Have a great day!\n",
        "Alice: Thanks, you too!\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kIGqqAuDTzZg"
      },
      "source": [
        "Prompting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "4yV901_hTzZh"
      },
      "outputs": [],
      "source": [
        "prompt = f'''You are provided with a conversation between customer and agent.\n",
        "        Your task is to extract key information like Topic of conversation, name of customer and agent, sentiment of the call between 1 to 5.\n",
        "        Always provide results in json format nothing else.\n",
        "        Conversation: {conversation}'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "L-TjJc9ETzZi"
      },
      "outputs": [],
      "source": [
        "from langchain_community.callbacks import get_openai_callback"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "xXswBYaZTzZj",
        "outputId": "6f590159-9411-45fb-fc35-f20c6904304e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "```json\n",
            "{\n",
            "  \"Topic\": \"Laptop Performance Issues\",\n",
            "  \"CustomerName\": \"Alice\",\n",
            "  \"AgentName\": \"John\",\n",
            "  \"Sentiment\": 4\n",
            "}\n",
            "```\n",
            "Tokens Used: 404\n",
            "\tPrompt Tokens: 365\n",
            "\tCompletion Tokens: 39\n",
            "Successful Requests: 1\n",
            "Total Cost (USD): $7.815e-05\n"
          ]
        }
      ],
      "source": [
        "with get_openai_callback() as cb:\n",
        "    out = llm.invoke(prompt)\n",
        "print(out.content)\n",
        "print(cb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "MjhreyaDTzZk",
        "outputId": "8893abc6-4124-45bf-dad3-f959e26a3594",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "str"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "type(out.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ayli9Cj9TzZl"
      },
      "source": [
        "Function Calling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "3NIZfmRITzZl"
      },
      "outputs": [],
      "source": [
        "from langchain_core.pydantic_v1 import BaseModel, Field\n",
        "\n",
        "class Summarization(BaseModel):\n",
        "    \"\"\"Extract key information from the conversation.\"\"\"\n",
        "\n",
        "    Topic: str = Field(description=\"What was the topic of discussion in the call.\")\n",
        "    Customer: str = Field(description=\"Name of the customer\")\n",
        "    Agent: str = Field(description=\"Name of the Agent\")\n",
        "    Sentiment: int = Field(description=\"What was the sentiment of the customer, from 1 to 5, 1 as most negative and 5 as most positive\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "8UDc3423TzZl",
        "outputId": "87475b35-02e2-4f6a-98e2-4e2483647eae",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class '__main__.Summarization'> \n",
            " Topic='Laptop performance issues and troubleshooting' Customer='Alice' Agent='John' Sentiment=4\n",
            "Tokens Used: 442\n",
            "\tPrompt Tokens: 420\n",
            "\tCompletion Tokens: 22\n",
            "Successful Requests: 1\n",
            "Total Cost (USD): $7.619999999999998e-05\n"
          ]
        }
      ],
      "source": [
        "structured_llm = llm.with_structured_output(Summarization)\n",
        "\n",
        "with get_openai_callback() as cb:\n",
        "    out = structured_llm.invoke(f\"{conversation}\")\n",
        "\n",
        "print(type(out), \"\\n\", out)\n",
        "print(cb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "h7oSl-FPTzZm",
        "outputId": "599d5dea-f175-4b3b-98b3-8405a44db239",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Laptop performance issues and troubleshooting'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "out.Topic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "AZgiSC9NTzZn",
        "outputId": "f156f64b-b78d-4d63-e60c-3dff05b322f0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'lc': 1,\n",
              " 'type': 'constructor',\n",
              " 'id': ['langchain', 'schema', 'runnable', 'RunnableSequence'],\n",
              " 'kwargs': {'first': RunnableBinding(bound=ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x7e42c8a22a40>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x7e42c8a487f0>, root_client=<openai.OpenAI object at 0x7e42c8a22d70>, root_async_client=<openai.AsyncOpenAI object at 0x7e42c8a22620>, model_name='gpt-4o-mini', openai_api_key=SecretStr('**********'), openai_proxy=''), kwargs={'tools': [{'type': 'function', 'function': {'name': 'Summarization', 'description': 'Extract key information from the conversation.', 'parameters': {'type': 'object', 'properties': {'Topic': {'description': 'What was the topic of discussion in the call.', 'type': 'string'}, 'Customer': {'description': 'Name of the customer', 'type': 'string'}, 'Agent': {'description': 'Name of the Agent', 'type': 'string'}, 'Sentiment': {'description': 'What was the sentiment of the customer, from 1 to 5, 1 as most negative and 5 as most positive', 'type': 'integer'}}, 'required': ['Topic', 'Customer', 'Agent', 'Sentiment']}}}], 'parallel_tool_calls': False, 'tool_choice': {'type': 'function', 'function': {'name': 'Summarization'}}}),\n",
              "  'last': PydanticToolsParser(first_tool_only=True, tools=[<class '__main__.Summarization'>])},\n",
              " 'name': 'RunnableSequence'}"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "structured_llm.to_json()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "DhEhxkk4TzZn",
        "outputId": "a8f21ed8-76a7-4eca-acc3-401ac0fbea91",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'dict'> \n",
            " {'Topic': 'Laptop Performance Issues', 'Customer': 'Alice', 'Agent': 'John', 'Sentiment': 2}\n",
            "Tokens Used: 392\n",
            "\tPrompt Tokens: 372\n",
            "\tCompletion Tokens: 20\n",
            "Successful Requests: 1\n",
            "Total Cost (USD): $6.78e-05\n"
          ]
        }
      ],
      "source": [
        "from typing_extensions import TypedDict\n",
        "\n",
        "class Summarization(TypedDict):\n",
        "    \"\"\"Extract key information from the conversation.\"\"\"\n",
        "\n",
        "    Topic: str = Field(description=\"What was the topic of discussion in the call.\")\n",
        "    Customer: str = Field(description=\"Name of the customer\")\n",
        "    Agent: str = Field(description=\"Name of the Agent\")\n",
        "    Sentiment: int = Field(description=\"What was the sentiment of the customer, from 1 to 5, 1 as most negative and 5 as most positive\")\n",
        "\n",
        "\n",
        "structured_llm = llm.with_structured_output(Summarization)\n",
        "\n",
        "with get_openai_callback() as cb:\n",
        "    out = structured_llm.invoke(f\"{conversation}\")\n",
        "\n",
        "print(type(out), \"\\n\", out)\n",
        "print(cb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uESl_dpbTzZo"
      },
      "source": [
        "Tool Calling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "6RObsTIETzZo"
      },
      "outputs": [],
      "source": [
        "from typing import Union\n",
        "\n",
        "\n",
        "class ConversationalResponse(BaseModel):\n",
        "    \"\"\"Respond in a conversational manner. Be kind and helpful.\"\"\"\n",
        "\n",
        "    response: str = Field(description=\"A conversational response to the user's query\")\n",
        "\n",
        "\n",
        "class Response(BaseModel):\n",
        "    output: Union[Summarization, ConversationalResponse]\n",
        "\n",
        "structured_llm = llm.with_structured_output(Response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "OLBSMtfMTzZp",
        "outputId": "13fe164f-6f5e-4828-8253-622dd6fff2a1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class '__main__.Response'> \n",
            " output=ConversationalResponse(response='As of October 2023, the President of India is Droupadi Murmu. She took office on July 25, 2022, and is the first tribal woman to hold the position.')\n",
            "Tokens Used: 164\n",
            "\tPrompt Tokens: 117\n",
            "\tCompletion Tokens: 47\n",
            "Successful Requests: 1\n",
            "Total Cost (USD): $4.575e-05\n"
          ]
        }
      ],
      "source": [
        "with get_openai_callback() as cb:\n",
        "    out = structured_llm.invoke(\"Who is president of India?\")\n",
        "\n",
        "print(type(out), \"\\n\", out)\n",
        "print(cb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "dR71LCRvTzZp",
        "outputId": "acb20ace-e760-48fa-c991-63ef1f739096",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class '__main__.Response'> \n",
            " output={'Topic': 'Customer Support for Laptop Issues', 'Customer': 'Alice', 'Agent': 'John', 'Sentiment': 3}\n",
            "Tokens Used: 439\n",
            "\tPrompt Tokens: 415\n",
            "\tCompletion Tokens: 24\n",
            "Successful Requests: 1\n",
            "Total Cost (USD): $7.664999999999999e-05\n"
          ]
        }
      ],
      "source": [
        "with get_openai_callback() as cb:\n",
        "    out = structured_llm.invoke(f\"{conversation}\")\n",
        "\n",
        "print(type(out), \"\\n\", out)\n",
        "print(cb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xfdt6dEDTzZq"
      },
      "source": [
        "Json Mode"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "2Uy5gdIwTzZq"
      },
      "outputs": [],
      "source": [
        "from langchain_core.output_parsers import JsonOutputParser\n",
        "from langchain_core.prompts import PromptTemplate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "QOINvNq7TzZq"
      },
      "outputs": [],
      "source": [
        "class Summarization(BaseModel):\n",
        "    \"\"\"Extract key information from the conversation.\"\"\"\n",
        "\n",
        "    Topic: str = Field(description=\"What was the topic of discussion in the call.\")\n",
        "    Customer: str = Field(description=\"Name of the customer\")\n",
        "    Agent: str = Field(description=\"Name of the Agent\")\n",
        "    Sentiment: int = Field(description=\"What was the sentiment of the customer, from 1 to 5, 1 as most negative and 5 as most positive\")\n",
        "\n",
        "\n",
        "parser = JsonOutputParser(pydantic_object=Summarization)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "3SO8dcbfTzZq",
        "outputId": "b67842bc-658a-4b18-ab21-574f6f9ad7f1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The output should be formatted as a JSON instance that conforms to the JSON schema below.\n",
            "\n",
            "As an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\n",
            "the object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\n",
            "\n",
            "Here is the output schema:\n",
            "```\n",
            "{\"description\": \"Extract key information from the conversation.\", \"properties\": {\"Topic\": {\"title\": \"Topic\", \"description\": \"What was the topic of discussion in the call.\", \"type\": \"string\"}, \"Customer\": {\"title\": \"Customer\", \"description\": \"Name of the customer\", \"type\": \"string\"}, \"Agent\": {\"title\": \"Agent\", \"description\": \"Name of the Agent\", \"type\": \"string\"}, \"Sentiment\": {\"title\": \"Sentiment\", \"description\": \"What was the sentiment of the customer, from 1 to 5, 1 as most negative and 5 as most positive\", \"type\": \"integer\"}}, \"required\": [\"Topic\", \"Customer\", \"Agent\", \"Sentiment\"]}\n",
            "```\n"
          ]
        }
      ],
      "source": [
        "print(parser.get_format_instructions())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "1sreQtbjTzZr"
      },
      "outputs": [],
      "source": [
        "prompt = PromptTemplate(\n",
        "    template=\"Answer the user query.\\n{format_instructions}\\n{query}\\n\",\n",
        "    input_variables=[\"query\"],\n",
        "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "vyng5p1WTzZr",
        "outputId": "6886fa55-5a43-4525-f7b1-cd6f4065ea57",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input_variables=['query'] partial_variables={'format_instructions': 'The output should be formatted as a JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output schema:\\n```\\n{\"description\": \"Extract key information from the conversation.\", \"properties\": {\"Topic\": {\"title\": \"Topic\", \"description\": \"What was the topic of discussion in the call.\", \"type\": \"string\"}, \"Customer\": {\"title\": \"Customer\", \"description\": \"Name of the customer\", \"type\": \"string\"}, \"Agent\": {\"title\": \"Agent\", \"description\": \"Name of the Agent\", \"type\": \"string\"}, \"Sentiment\": {\"title\": \"Sentiment\", \"description\": \"What was the sentiment of the customer, from 1 to 5, 1 as most negative and 5 as most positive\", \"type\": \"integer\"}}, \"required\": [\"Topic\", \"Customer\", \"Agent\", \"Sentiment\"]}\\n```'} template='Answer the user query.\\n{format_instructions}\\n{query}\\n'\n"
          ]
        }
      ],
      "source": [
        "print(prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "4KL1g_imTzZr"
      },
      "outputs": [],
      "source": [
        "chain = prompt | llm | parser"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "aVFialmDTzZs",
        "outputId": "c2c12032-0dd6-492e-944e-81b66ee681dd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Topic': 'Laptop performance issues', 'Customer': 'Alice', 'Agent': 'John', 'Sentiment': 3}\n",
            "Tokens Used: 628\n",
            "\tPrompt Tokens: 591\n",
            "\tCompletion Tokens: 37\n",
            "Successful Requests: 1\n",
            "Total Cost (USD): $0.00011084999999999998\n"
          ]
        }
      ],
      "source": [
        "with get_openai_callback() as cb:\n",
        "    out = chain.invoke(f\"{conversation}\")\n",
        "\n",
        "print(out)\n",
        "print(cb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "bLTGv-cqTzZs",
        "outputId": "047f166e-0693-4727-db68-89545d07a9b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'{\"Topic\": \"Laptop performance issues\", \"Customer\": \"Alice\", \"Agent\": \"John\", \"Sentiment\": 3}'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "import json\n",
        "json.dumps(out)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "epeNKjPdTzZs"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}