{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Ollama in Google Colab\n",
        "\n",
        "* https://www.youtube.com/watch?v=rV0yqqQeeLw\n",
        "\n",
        "IPHS 391: Frontiers in AI - Agents\n",
        "Jon Chun\n",
        "Kenyon College\n",
        "Fall 2024"
      ],
      "metadata": {
        "id": "ZdjbGTd1FOK0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt-get install -y pciutils"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jo6ot9cvEOST",
        "outputId": "ae1cafe0-9283-4ce7-c91f-b776a82cb585"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  libpci3 pci.ids\n",
            "The following NEW packages will be installed:\n",
            "  libpci3 pci.ids pciutils\n",
            "0 upgraded, 3 newly installed, 0 to remove and 49 not upgraded.\n",
            "Need to get 343 kB of archives.\n",
            "After this operation, 1,581 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/main amd64 pci.ids all 0.0~2022.01.22-1 [251 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 libpci3 amd64 1:3.7.0-6 [28.9 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/main amd64 pciutils amd64 1:3.7.0-6 [63.6 kB]\n",
            "Fetched 343 kB in 1s (255 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 3.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package pci.ids.\n",
            "(Reading database ... 123597 files and directories currently installed.)\n",
            "Preparing to unpack .../pci.ids_0.0~2022.01.22-1_all.deb ...\n",
            "Unpacking pci.ids (0.0~2022.01.22-1) ...\n",
            "Selecting previously unselected package libpci3:amd64.\n",
            "Preparing to unpack .../libpci3_1%3a3.7.0-6_amd64.deb ...\n",
            "Unpacking libpci3:amd64 (1:3.7.0-6) ...\n",
            "Selecting previously unselected package pciutils.\n",
            "Preparing to unpack .../pciutils_1%3a3.7.0-6_amd64.deb ...\n",
            "Unpacking pciutils (1:3.7.0-6) ...\n",
            "Setting up pci.ids (0.0~2022.01.22-1) ...\n",
            "Setting up libpci3:amd64 (1:3.7.0-6) ...\n",
            "Setting up pciutils (1:3.7.0-6) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.4) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!curl -fsSL https://ollama.com/install.sh | sh # download ollama api"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1A2VUb7bEOO6",
        "outputId": "07129d78-1885-4e72-83a0-f8a7806a6c3f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">>> Installing ollama to /usr/local\n",
            ">>> Downloading Linux amd64 bundle\n",
            "############################################################################################# 100.0%\n",
            ">>> Creating ollama user...\n",
            ">>> Adding ollama user to video group...\n",
            ">>> Adding current user to ollama group...\n",
            ">>> Creating ollama systemd service...\n",
            ">>> NVIDIA GPU installed.\n",
            ">>> The Ollama API is now available at 127.0.0.1:11434.\n",
            ">>> Install complete. Run \"ollama\" from the command line.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import clear_output"
      ],
      "metadata": {
        "id": "VFujFA5mEVOB"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a Python script to start the Ollama API server in a separate thread\n",
        "\n",
        "import os\n",
        "import threading\n",
        "import subprocess\n",
        "import requests\n",
        "import json"
      ],
      "metadata": {
        "id": "8Hafi72KESTB"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ollama():\n",
        "    os.environ['OLLAMA_HOST'] = '0.0.0.0:11434'\n",
        "    os.environ['OLLAMA_ORIGINS'] = '*'\n",
        "    subprocess.Popen([\"ollama\", \"serve\"])\n",
        "\n",
        "ollama_thread = threading.Thread(target=ollama)\n",
        "ollama_thread.start()"
      ],
      "metadata": {
        "id": "aFbsdxQhEcKM"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "# NOTE:\n",
        "\n",
        "!ollama pull llama3.1:8b\n",
        "clear_output()"
      ],
      "metadata": {
        "id": "TbRx20F0Eep7"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U lightrag[ollama]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8aRhdX6oEf4a",
        "outputId": "a24b8993-cac6-42a7-e579-d5085f42b131"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting lightrag[ollama]\n",
            "  Downloading lightrag-0.1.0b6-py3-none-any.whl.metadata (14 kB)\n",
            "Collecting backoff<3.0.0,>=2.2.1 (from lightrag[ollama])\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: jinja2<4.0.0,>=3.1.3 in /usr/local/lib/python3.10/dist-packages (from lightrag[ollama]) (3.1.4)\n",
            "Collecting jsonlines<5.0.0,>=4.0.0 (from lightrag[ollama])\n",
            "  Downloading jsonlines-4.0.0-py3-none-any.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nest-asyncio<2.0.0,>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from lightrag[ollama]) (1.6.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.26.4 in /usr/local/lib/python3.10/dist-packages (from lightrag[ollama]) (1.26.4)\n",
            "Collecting python-dotenv<2.0.0,>=1.0.1 (from lightrag[ollama])\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: pyyaml<7.0.0,>=6.0.1 in /usr/local/lib/python3.10/dist-packages (from lightrag[ollama]) (6.0.2)\n",
            "Collecting tiktoken<0.8.0,>=0.7.0 (from lightrag[ollama])\n",
            "  Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.66.4 in /usr/local/lib/python3.10/dist-packages (from lightrag[ollama]) (4.66.5)\n",
            "Collecting ollama<0.3.0,>=0.2.1 (from lightrag[ollama])\n",
            "  Downloading ollama-0.2.1-py3-none-any.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2<4.0.0,>=3.1.3->lightrag[ollama]) (2.1.5)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonlines<5.0.0,>=4.0.0->lightrag[ollama]) (24.2.0)\n",
            "Collecting httpx<0.28.0,>=0.27.0 (from ollama<0.3.0,>=0.2.1->lightrag[ollama])\n",
            "  Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken<0.8.0,>=0.7.0->lightrag[ollama]) (2024.5.15)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken<0.8.0,>=0.7.0->lightrag[ollama]) (2.32.3)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<0.28.0,>=0.27.0->ollama<0.3.0,>=0.2.1->lightrag[ollama]) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<0.28.0,>=0.27.0->ollama<0.3.0,>=0.2.1->lightrag[ollama]) (2024.8.30)\n",
            "Collecting httpcore==1.* (from httpx<0.28.0,>=0.27.0->ollama<0.3.0,>=0.2.1->lightrag[ollama])\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx<0.28.0,>=0.27.0->ollama<0.3.0,>=0.2.1->lightrag[ollama]) (3.8)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<0.28.0,>=0.27.0->ollama<0.3.0,>=0.2.1->lightrag[ollama]) (1.3.1)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<0.28.0,>=0.27.0->ollama<0.3.0,>=0.2.1->lightrag[ollama])\n",
            "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken<0.8.0,>=0.7.0->lightrag[ollama]) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken<0.8.0,>=0.7.0->lightrag[ollama]) (2.0.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<0.28.0,>=0.27.0->ollama<0.3.0,>=0.2.1->lightrag[ollama]) (1.2.2)\n",
            "Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading jsonlines-4.0.0-py3-none-any.whl (8.7 kB)\n",
            "Downloading ollama-0.2.1-py3-none-any.whl (9.7 kB)\n",
            "Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m52.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightrag-0.1.0b6-py3-none-any.whl (159 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m159.1/159.1 kB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx-0.27.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: python-dotenv, jsonlines, h11, backoff, tiktoken, httpcore, lightrag, httpx, ollama\n",
            "Successfully installed backoff-2.2.1 h11-0.14.0 httpcore-1.0.5 httpx-0.27.2 jsonlines-4.0.0 lightrag-0.1.0b6 ollama-0.2.1 python-dotenv-1.0.1 tiktoken-0.7.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from lightrag.core.generator import Generator\n",
        "from lightrag.core.component import Component\n",
        "from lightrag.core.model_client import ModelClient\n",
        "from lightrag.components.model_client import OllamaClient, GroqAPIClient\n",
        "\n",
        "import time"
      ],
      "metadata": {
        "id": "OgBHtMM2Ei6C"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "qa_template = r\"\"\"<SYS>\n",
        "You are a helpful assistant.\n",
        "</SYS>\n",
        "User: {{input_str}}\n",
        "You:\"\"\""
      ],
      "metadata": {
        "id": "HsPoRFaXEmSJ"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "-hngn54zD_7j"
      },
      "outputs": [],
      "source": [
        "class SimpleQA(Component):\n",
        "    def __init__(self, model_client: ModelClient, model_kwargs: dict):\n",
        "        super().__init__()\n",
        "        self.generator = Generator(\n",
        "            model_client=model_client,\n",
        "            model_kwargs=model_kwargs,\n",
        "            template=qa_template,\n",
        "        )\n",
        "\n",
        "    def call(self, input: dict) -> str:\n",
        "        return self.generator.call({\"input_str\": str(input)})\n",
        "\n",
        "    async def acall(self, input: dict) -> str:\n",
        "        return await self.generator.acall({\"input_str\": str(input)})"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from lightrag.components.model_client import OllamaClient\n",
        "from IPython.display import Markdown, display\n"
      ],
      "metadata": {
        "id": "XGABKYtAEqDR"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = {\n",
        "    \"model_client\": OllamaClient(),\n",
        "    \"model_kwargs\": {\"model\": \"llama3.1:8b\"}\n",
        "}\n"
      ],
      "metadata": {
        "id": "zcVuE8-YEp9R"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "qa = SimpleQA(**model)\n",
        "output=qa(\"what is happiness\")\n",
        "display(Markdown(f\"**Answer:** {output.data}\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "i4OqtiqrEs9P",
        "outputId": "0cb9b751-3403-4dcb-f81e-2f3645efd2dc"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**Answer:** What a wonderful topic!\n\nHappiness can be defined as a positive emotional state characterized by feelings of joy, contentment, and fulfillment. It's the experience of living life to the fullest, feeling good about oneself and one's circumstances, and being in a state of well-being.\n\nAccording to various philosophers, psychologists, and researchers, happiness is often associated with:\n\n1. **Positive emotions**: Experiencing pleasure, delight, or joy from activities, relationships, or experiences.\n2. **Life satisfaction**: Feeling content with one's life, appreciating its goodness, and being grateful for what one has.\n3. **Subjective well-being**: Perceiving oneself as happy, satisfied, and fulfilled.\n\nSome common sources of happiness include:\n\n1. **Meaningful relationships**: Strong connections with loved ones, friends, or community.\n2. **Personal growth**: Pursuing passions, learning new skills, and developing oneself.\n3. **Good physical health**: Enjoying good physical well-being, mental clarity, and energy.\n4. **Gratitude**: Appreciating life's simple pleasures, being thankful for what one has.\n5. **Flow experiences**: Engaging in activities that challenge and engage oneself.\n\nOf course, happiness is a highly personal and subjective experience. What brings happiness to one person may not be the same for another.\n\nWould you like me to explore this topic further?"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "# NOTE:\n",
        "\n",
        "output=qa(\"Will AGI be realized? If yes, when and how? If no, why?\")\n",
        "display(Markdown(f\"**Answer:** {output.data}\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 715
        },
        "id": "L1vIO38KFDWJ",
        "outputId": "b688fa2e-044f-4f4e-b312-c02286a96a4f"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**Answer:** What a fascinating and complex topic!\n\nThe possibility of achieving Artificial General Intelligence (AGI) is a topic of ongoing debate among experts in the field. Some predict that AGI will be achieved within our lifetime, while others believe it's still far-fetched or even impossible.\n\n**Arguments for AGI being realized:**\n\n1. **Rapid progress**: The pace of AI research has accelerated significantly over the past few decades, with breakthroughs in areas like deep learning, natural language processing, and computer vision.\n2. **Increasing computational power**: Advances in computing hardware have enabled researchers to tackle more complex problems and simulate larger neural networks.\n3. **Improved understanding of human cognition**: Studies on human brain function and behavior are informing the development of more sophisticated AI models.\n\n**Predictions from experts:**\n\n1. **Ray Kurzweil**, a well-known futurist, predicts that AGI will be achieved by 2045 (Source: \"The Singularity Is Near\").\n2. **Nick Bostrom**, Director of the Future of Humanity Institute, suggests that AGI might emerge between 2050 and 2100 (Source: \"Superintelligence\").\n\n**Challenges and limitations:**\n\n1. **Scalability**: Currently, AI systems struggle to scale up to the complexity and generality required for true human-like intelligence.\n2. **Robustness and explainability**: AI models often lack transparency and are vulnerable to errors or biases.\n3. **Cognitive architectures**: The intricate relationships between cognitive modules in the human brain are still not well understood, making it challenging to replicate them in artificial systems.\n\n**Why AGI might not be realized:**\n\n1. **Complexity of human cognition**: Human intelligence is a complex and multifaceted phenomenon that may prove difficult to fully capture in an artificial system.\n2. **Limits of computational power**: The exponential growth of computing power may eventually plateau, hindering the development of more advanced AI models.\n3. **Societal and economic factors**: The pursuit of AGI could be hindered by societal concerns, budget constraints, or shifting research priorities.\n\n**The likely timeline:**\n\nWhile it's difficult to predict exactly when (or if) AGI will be achieved, I'd estimate the following rough timeline:\n\n* Short-term (2025-2035): We'll see significant advancements in narrow AI domains like language understanding, vision recognition, and decision-making.\n* Mid-term (2035-2050): Researchers will focus on developing more sophisticated cognitive architectures and improving the robustness of AI models.\n* Long-term (2050-2075): The emergence of true AGI is possible, but still uncertain. If achieved, it would likely be accompanied by significant societal changes.\n\nKeep in mind that this is a hypothetical timeline, and the actual path to AGI may differ significantly from these predictions.\n\nHow do you think AGI will evolve? Do you have any specific questions or concerns about AI development? I'm here to help!"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-FUMTev2FKBj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}