{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Summarize HN\n",
        "\n",
        "Jon Chun\n",
        "30 Sep 2024"
      ],
      "metadata": {
        "id": "rbtGBxMXAL9X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Installation"
      ],
      "metadata": {
        "id": "Eo8iAA-aAVZa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f38nVDf1ALTJ",
        "outputId": "a2bb128a-9e5e-419f-fb26-1346df70c1e4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.32.3)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (4.12.3)\n",
            "Collecting openai\n",
            "  Downloading openai-1.51.0-py3-none-any.whl.metadata (24 kB)\n",
            "Collecting python-dotenv\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (3.10.6)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (3.7.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2024.8.30)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4) (2.6)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting jiter<1,>=0.4.0 (from openai)\n",
            "  Downloading jiter-0.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.9.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp) (2.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp) (1.12.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp) (4.0.3)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.12.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy) (71.0.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (24.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.4.1)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.26.4)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.6-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.23.4)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (13.8.1)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.19.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.0.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy) (2.1.5)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.18.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.16.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n",
            "Downloading openai-1.51.0-py3-none-any.whl (383 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m383.5/383.5 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading httpx-0.27.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-1.0.6-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.0/78.0 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jiter-0.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (318 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.9/318.9 kB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: python-dotenv, jiter, h11, httpcore, httpx, openai\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.6 httpx-0.27.2 jiter-0.5.0 openai-1.51.0 python-dotenv-1.0.1\n",
            "Collecting en-core-web-sm==3.7.1\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m53.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.2 in /usr/local/lib/python3.10/dist-packages (from en-core-web-sm==3.7.1) (3.7.6)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.12.5)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.66.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.9.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (71.0.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (24.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.4.1)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.26.4)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.23.4)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2024.8.30)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (13.8.1)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.19.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (7.0.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.1.5)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.2.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.18.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.16.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.2)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ],
      "source": [
        "!pip install requests beautifulsoup4 openai python-dotenv aiohttp spacy\n",
        "!python -m spacy download en_core_web_sm\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **[RESTART RUNTIME]**"
      ],
      "metadata": {
        "id": "qFULL0mqGXX6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup"
      ],
      "metadata": {
        "id": "q138HI8iATmq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import getpass\n",
        "import re\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import openai\n",
        "from dotenv import load_dotenv\n",
        "import logging\n",
        "from typing import List, Dict, Tuple\n",
        "import asyncio\n",
        "import aiohttp\n",
        "import sys\n",
        "import spacy\n",
        "from collections import Counter\n",
        "from google.colab import files\n",
        "\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "\n",
        "load_dotenv()\n",
        "\n",
        "URL_TARGET = 'https://news.ycombinator.com/item?id=40515465'\n",
        "\n"
      ],
      "metadata": {
        "id": "I0wsCHVmAR41"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load spaCy model\n",
        "nlp = spacy.load(\"en_core_web_sm\")"
      ],
      "metadata": {
        "id": "nnNGkySYAgjE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Select the HN URL"
      ],
      "metadata": {
        "id": "vLklOyQmAkWr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "URL_TARGET = 'https://news.ycombinator.com/item?id=40515465'"
      ],
      "metadata": {
        "id": "28sihSSkAjN7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# OpenAI Key"
      ],
      "metadata": {
        "id": "KgOJx89DAm_S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import getpass"
      ],
      "metadata": {
        "id": "ntfAYcHDGhpo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "OPENAI_API_KEY = getpass.getpass(\"Enter OpenAI API Key: \")\n",
        "openai.api_key = OPENAI_API_KEY"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3HJN9hDPAgl_",
        "outputId": "e0f598f9-b1f8-4575-e0a6-a82318401026"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter OpenAI API Key: ··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Functions"
      ],
      "metadata": {
        "id": "CEBGPRfUAYW_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "async def fetch_web_page(url: str, session: aiohttp.ClientSession) -> str:\n",
        "    try:\n",
        "        async with session.get(url) as response:\n",
        "            response.raise_for_status()\n",
        "            return await response.text()\n",
        "    except aiohttp.ClientError as e:\n",
        "        logging.error(f\"Error fetching {url}: {e}\")\n",
        "        raise\n",
        "\n",
        "def parse_threads(html_content: str) -> List[Dict]:\n",
        "    soup = BeautifulSoup(html_content, 'html.parser')\n",
        "    threads = []\n",
        "\n",
        "    try:\n",
        "        comments = soup.find_all('tr', class_='athing comtr')\n",
        "        for comment in comments:\n",
        "            comment_id = comment.get('id')\n",
        "            indent = int(comment.find('td', class_='ind').find('img').get('width', 0)) // 40\n",
        "            content = comment.find('div', class_='comment')\n",
        "\n",
        "            if content:\n",
        "                threads.append({\n",
        "                    'id': comment_id,\n",
        "                    'indent': indent,\n",
        "                    'content': content.get_text(strip=True),\n",
        "                    'replies': []\n",
        "                })\n",
        "    except AttributeError as e:\n",
        "        logging.error(f\"Error parsing HTML: {e}\")\n",
        "        raise\n",
        "\n",
        "    return threads\n",
        "\n",
        "def build_thread_tree(threads: List[Dict]) -> List[Dict]:\n",
        "    thread_tree = []\n",
        "    stack = []\n",
        "\n",
        "    for thread in threads:\n",
        "        while stack and stack[-1]['indent'] >= thread['indent']:\n",
        "            stack.pop()\n",
        "\n",
        "        if stack:\n",
        "            stack[-1]['replies'].append(thread)\n",
        "        else:\n",
        "            thread_tree.append(thread)\n",
        "\n",
        "        stack.append(thread)\n",
        "\n",
        "    return thread_tree\n",
        "\n",
        "def is_common_word(word: str) -> bool:\n",
        "    common_words = set(['more', 'as', 'where', 'there', 'again', 'many', 'internet', 'edit', 'to'])\n",
        "    return word.lower() in common_words\n",
        "\n",
        "def extract_resources(text: str) -> List[Tuple[str, str, str]]:\n",
        "    resources = []\n",
        "\n",
        "    # Extract URLs\n",
        "    url_pattern = re.compile(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+')\n",
        "    urls = re.findall(url_pattern, text)\n",
        "    for url in urls:\n",
        "        resources.append((\"URL\", url, url))\n",
        "\n",
        "    # Extract named entities (this is a simplified version, you might want to use a more sophisticated NER)\n",
        "    entity_types = [\"PERSON\", \"ORG\", \"PRODUCT\", \"WORK_OF_ART\"]\n",
        "    for entity_type in entity_types:\n",
        "        entities = re.findall(r'\\b([A-Z][a-z]+(?:\\s+[A-Z][a-z]+)*)\\b', text)\n",
        "        for entity in entities:\n",
        "            if not is_common_word(entity):\n",
        "                resources.append((entity_type, entity, \"\"))\n",
        "\n",
        "    return resources\n",
        "\n",
        "async def format_resources(resources: Dict[int, Tuple[str, str, str]]) -> str:\n",
        "    formatted = \"# Combined and Deduplicated Resources List\\n\\n\"\n",
        "    resource_counter = Counter()\n",
        "\n",
        "    for _, (res_type, res_name, res_url) in resources.items():\n",
        "        resource_counter[(res_type, res_name)] += 1\n",
        "\n",
        "    sorted_resources = sorted(resource_counter.items(), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    async with aiohttp.ClientSession() as session:\n",
        "        for (res_type, res_name), count in sorted_resources:\n",
        "            formatted += f\"(count {count}) Type: {res_type}, Name: {res_name}\"\n",
        "            if res_type == \"URL\":\n",
        "                description = await get_url_description(res_name, session)\n",
        "                formatted += f\"\\n   URL: {res_name}\\n   {description}\"\n",
        "            formatted += \"\\n\\n\"\n",
        "\n",
        "    return formatted"
      ],
      "metadata": {
        "id": "gd_SWYNVAUth"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Summarize Threads"
      ],
      "metadata": {
        "id": "Rnlt5W78Avgm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "async def summarize_thread(thread: Dict, session: aiohttp.ClientSession) -> Tuple[str, List[Tuple[str, str, str]]]:\n",
        "    prompt = f\"Summarize the following discussion thread concisely:\\n\\n{thread['content']}\"\n",
        "\n",
        "    try:\n",
        "        async with session.post(\n",
        "            \"https://api.openai.com/v1/chat/completions\",\n",
        "            headers={\"Authorization\": f\"Bearer {OPENAI_API_KEY}\"},\n",
        "            json={\n",
        "                \"model\": \"gpt-3.5-turbo\",\n",
        "                \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n",
        "                \"max_tokens\": 150\n",
        "            }\n",
        "        ) as response:\n",
        "            response.raise_for_status()\n",
        "            result = await response.json()\n",
        "            summary = result['choices'][0]['message']['content'].strip()\n",
        "            resources = extract_resources(thread['content'])\n",
        "            return summary, resources\n",
        "    except aiohttp.ClientError as e:\n",
        "        logging.error(f\"Error calling OpenAI API: {e}\")\n",
        "        raise\n",
        "\n",
        "async def summarize_threads(threads: List[Dict]) -> Tuple[List[Dict], Dict[int, Tuple[str, str, str]]]:\n",
        "    async with aiohttp.ClientSession() as session:\n",
        "        tasks = [summarize_thread(thread, session) for thread in threads]\n",
        "        results = await asyncio.gather(*tasks, return_exceptions=True)\n",
        "\n",
        "    all_resources = {}\n",
        "    resource_counter = 1\n",
        "\n",
        "    for thread, result in zip(threads, results):\n",
        "        if isinstance(result, Exception):\n",
        "            logging.error(f\"Error summarizing thread {thread['id']}: {result}\")\n",
        "            thread['summary'] = \"Error in summarization\"\n",
        "            thread['resources'] = []\n",
        "        else:\n",
        "            summary, resources = result\n",
        "            thread['summary'] = summary\n",
        "            thread['resources'] = resources\n",
        "            for resource in resources:\n",
        "                all_resources[resource_counter] = resource\n",
        "                resource_counter += 1\n",
        "\n",
        "    return threads, all_resources\n",
        "\n",
        "def combine_summaries(threads: List[Dict]) -> str:\n",
        "    combined_summary = \"Individual Thread Summaries:\\n\\n\"\n",
        "\n",
        "    for thread in threads:\n",
        "        combined_summary += f\"Thread ID: {thread['id']}\\nSummary: {thread['summary']}\\n\\n\"\n",
        "\n",
        "    return combined_summary"
      ],
      "metadata": {
        "id": "1YQ0WvgpAsXc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Outline Synthesis and Formatting"
      ],
      "metadata": {
        "id": "Ig1GJQCpAzW_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "async def create_outline_synthesis(threads: List[Dict], session: aiohttp.ClientSession) -> str:\n",
        "    all_summaries = \"\\n\".join([thread['summary'] for thread in threads])\n",
        "    prompt = f\"\"\"Create an outline synthesizing all the topics from the following summaries.\n",
        "    Include supporting details like:\n",
        "    a. Concise description\n",
        "    b. Pros\n",
        "    c. Cons\n",
        "    d. Related resources (if any)\n",
        "\n",
        "    Summaries:\n",
        "    {all_summaries}\n",
        "    \"\"\"\n",
        "\n",
        "    try:\n",
        "        async with session.post(\n",
        "            \"https://api.openai.com/v1/chat/completions\",\n",
        "            headers={\"Authorization\": f\"Bearer {OPENAI_API_KEY}\"},\n",
        "            json={\n",
        "                \"model\": \"gpt-3.5-turbo\",\n",
        "                \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n",
        "                \"max_tokens\": 1000\n",
        "            }\n",
        "        ) as response:\n",
        "            response.raise_for_status()\n",
        "            result = await response.json()\n",
        "            return result['choices'][0]['message']['content'].strip()\n",
        "    except aiohttp.ClientError as e:\n",
        "        logging.error(f\"Error calling OpenAI API for synthesis: {e}\")\n",
        "        raise\n",
        "\n",
        "\n",
        "async def get_url_description(url: str, session: aiohttp.ClientSession) -> str:\n",
        "    prompt = f\"Provide a concise 1-3 word title and a brief 1 sentence description for this URL: {url}\"\n",
        "\n",
        "    try:\n",
        "        async with session.post(\n",
        "            \"https://api.openai.com/v1/chat/completions\",\n",
        "            headers={\"Authorization\": f\"Bearer {OPENAI_API_KEY}\"},\n",
        "            json={\n",
        "                \"model\": \"gpt-3.5-turbo\",\n",
        "                \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n",
        "                \"max_tokens\": 50\n",
        "            }\n",
        "        ) as response:\n",
        "            response.raise_for_status()\n",
        "            result = await response.json()\n",
        "            return result['choices'][0]['message']['content'].strip()\n",
        "    except aiohttp.ClientError as e:\n",
        "        logging.error(f\"Error calling OpenAI API for URL description: {e}\")\n",
        "        return \"Title: Unknown\\nDescription: Unable to fetch description.\"\n",
        "\n",
        "# The extract_resources function remains the same as in the previous version\n",
        "\n",
        "def get_hn_story_title(html_content: str) -> str:\n",
        "    soup = BeautifulSoup(html_content, 'html.parser')\n",
        "    title = soup.find('tr', class_='athing').find('span', class_='titleline').text.strip()\n",
        "    return re.sub(r'[^a-zA-Z0-9_]', '_', title.lower())"
      ],
      "metadata": {
        "id": "Q8-q0eXZAwkM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# File Saving and Main"
      ],
      "metadata": {
        "id": "v1keXKggA3kS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nest_asyncio\n",
        "nest_asyncio.apply()\n",
        "\n",
        "async def main():\n",
        "    try:\n",
        "        async with aiohttp.ClientSession() as session:\n",
        "            html_content = await fetch_web_page(URL_TARGET, session)\n",
        "\n",
        "        story_title = get_hn_story_title(html_content)\n",
        "        output_file = f\"ycombinatornews_{story_title}_40515465.txt\"\n",
        "\n",
        "        threads = parse_threads(html_content)\n",
        "        thread_tree = build_thread_tree(threads)\n",
        "\n",
        "        all_resources = {}\n",
        "        resource_counter = 1\n",
        "        for thread in thread_tree:\n",
        "            resources = extract_resources(thread['content'])\n",
        "            for resource in resources:\n",
        "                all_resources[resource_counter] = resource\n",
        "                resource_counter += 1\n",
        "\n",
        "        formatted_resources = await format_resources(all_resources)\n",
        "\n",
        "        # ... rest of the main function ...\n",
        "\n",
        "    except Exception as e:\n",
        "        logging.error(f\"An error occurred: {e}\")"
      ],
      "metadata": {
        "id": "IS-zuChwAyiS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "  async def save_summary_to_file(thread_summaries: str, outline_synthesis: str, resources: str, file_path: str):\n",
        "    try:\n",
        "        with open(file_path, 'w', encoding='utf-8') as file:\n",
        "            file.write(\"--- Thread Summaries ---\\n\\n\")\n",
        "            file.write(thread_summaries)\n",
        "            file.write(\"\\n--- Collected Resources ---\\n\\n\")\n",
        "            file.write(resources)\n",
        "            file.write(\"\\n--- Overall Outline Synthesis ---\\n\\n\")\n",
        "            file.write(outline_synthesis)\n",
        "        logging.info(f\"Summary saved to {file_path}\")\n",
        "        files.download(file_path)  # This will prompt a download in Colab\n",
        "    except IOError as e:\n",
        "        logging.error(f\"Error saving summary to file: {e}\")\n",
        "        raise"
      ],
      "metadata": {
        "id": "MIDaohsLA6Z9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "async def main():\n",
        "    try:\n",
        "        async with aiohttp.ClientSession() as session:\n",
        "            html_content = await fetch_web_page(URL_TARGET, session)\n",
        "\n",
        "        story_title = get_hn_story_title(html_content)\n",
        "        output_file = f\"ycombinatornews_{story_title}_40515465.txt\"\n",
        "\n",
        "        threads = parse_threads(html_content)\n",
        "        thread_tree = build_thread_tree(threads)\n",
        "\n",
        "        summarized_threads, all_resources = await summarize_threads(thread_tree)\n",
        "        thread_summaries = combine_summaries(summarized_threads)\n",
        "\n",
        "        formatted_resources = await format_resources(all_resources)\n",
        "\n",
        "        async with aiohttp.ClientSession() as session:\n",
        "            outline_synthesis = await create_outline_synthesis(summarized_threads, session)\n",
        "\n",
        "        await save_summary_to_file(thread_summaries, outline_synthesis, formatted_resources, output_file)\n",
        "\n",
        "        print(f\"Output has been saved to {output_file}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        logging.error(f\"An error occurred: {e}\")\n",
        "\n",
        "# Run the main function\n",
        "await main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "KEARN9n3DNhM",
        "outputId": "8f38a696-cb79-473a-bf99-cf69d8c81c37"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_d36c9a77-0246-4ddb-89ac-92cb85f6f0e3\", \"ycombinatornews_california_senate_passes_sb_1047__hyperdimensional_co__40515465.txt\", 15093)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output has been saved to ycombinatornews_california_senate_passes_sb_1047__hyperdimensional_co__40515465.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zeC52_9dGnEA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}