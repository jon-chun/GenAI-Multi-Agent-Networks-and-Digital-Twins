# MLOps

## Leaderboard

* [Huggingface Leaderboards](https://huggingface.co/open-llm-leaderboard)
* [ArtificialAnalysis.ai](https://artificialanalysis.ai/leaderboards/models)
* [Vellum Leaderboard](https://www.vellum.ai/llm-leaderboard)

## AI Libraries

* [9 Open Source Libraries to Supercharge Your Next Project (14 Nov 2024)](https://blog.gopenai.com/the-future-of-rag-will-be-with-vision-end-to-end-example-with-colpali-and-a-vision-language-model-fe133667d2f9)
Penpot
OpenAlternative
Listmonk
Supabase
Rallly
* [Pandas Is Dead. Machine Learning Teams Are Using These Tools Instead. (5 Nov 2024)](https://pub.towardsai.net/pandas-is-dead-machine-learning-teams-are-using-these-tools-instead-bc4124bb767c)
  * Polars is incredibly fast and well-suited for tasks that benefit from parallel processing.
  * DuckDB is ideal for SQL users who need a high-performance in-memory database for analytics.
  * Vaex works well with very large datasets, especially when memory is limited, although it lacks some advanced features.
  * Modin provides a user-friendly transition for those who need better performance than Pandas without altering much of their code.

## Utilities

* [can-it-run-llm](https://huggingface.co/spaces/Vokturz/can-it-run-llm)

## Virtual Environments

* [uv for Python](https://docs.astral.sh/uv/#tools)

## Software Engineering

* [Aurelio.ai's Semantic-Router](https://www.aurelio.ai/learn)
  * [Github](https://github.com/aurelio-labs/semantic-router)

## ACCELERATOR

* [MSI.com Afterburner](https://www.msi.com/Landing/afterburner/graphics-cards)

## JUPYTER

* [Jupyter](https://jupyter.org/install)
* [Voila](https://github.com/voila-dashboards/voila)

## VMs

* MLOps VMs
  * venv
  * Docker
  * [Huggingface Spaces](https://huggingface.co/spaces)
  * Colab
  * Kaggle
  * Github
    * [Github Discussions](https://github.com/orgs/community/discussions)
  * Replt
  
## Cloud Services

* MLOps Local/Cloud Private LLMs
  * [ollama](https://ollama.ai)
  * [groq Cloud](https://groq.com/)
  * [cerebras.ai](https://cerebras.ai/blog/cerebras-gpt-a-family-of-open-compute-efficient-large-language-models/)
  * [runpod.io](runpod.io)

## Ollama

* [Huggingface Models](https://huggingface.co/docs/hub/en/ollama)
* [ChatGPT Speedup](https://chatgpt.com/share/672b1ca6-57e0-800d-917c-1433383892ce)
* Ollama
  * [Ollama Python](https://github.com/ollama/ollama-python)
* Ollama in Colab
  * [Ollama on Google Colab: A Game-Changer! (15:07) (2 Jul 2024)](https://www.youtube.com/watch?v=9sPKTNGaPf8)
  * [Run Ollama Locally Using Google Colab’s Free GPU (28 Feb 2024)](https://medium.com/@neohob/run-ollama-locally-using-google-colabs-free-gpu-49543e0def31)
  * [Ollama in Colab](https://colab.research.google.com/github/jellyterra/ollama-colab/blob/master/OllamaColab.ipynb)
  * [ngrok API](https://dashboard.ngrok.com/)
  * [Ollama in Github Code Space](https://github.com/BlackTechX011/Ollama-in-GitHub-Codespaces)

## Ollama UI

* [LibreChat](https://github.com/danny-avila/LibreChat)
* [Ollama with Vision - Enabling Multimodal RAG (13:00) (7 Oct 2024)](https://www.youtube.com/watch?v=45LJT-bt500)
* [Find Your Perfect Ollama Build (13:30) (21 Nov 2024)](https://www.youtube.com/watch?v=RFaMiQ97EoE)
* [Ollama](ollama.ai)
* [MSTY](https://msty.app/)
* [Open WebUI](https://github.com/open-webui/open-webui)
* [Ollama UI](https://www.technovangelist.com/notes/annotated%20list%20of%20ollama%20web%20and%20desktop%20integrations/)
* [LocalAI](https://github.com/mudler/LocalAI)
  
## Local Alternatives

* [Run Any Local LLM Faster Than Ollama—Here's How (12:06) (5 Nov 2024)](https://www.youtube.com/watch?v=i1rvSiSpzSo)

## Docker

* [How to Make Your Python Docker Image 80% Smaller (18:46) (14 Mar 2025)](https://www.youtube.com/watch?v=tc713anE3UY&t=648s)
  * [Gihub](https://github.com/ArjanCodes/examples/tree/main/2025/efficient-python-dockerfile)
* [How to Install Ollama, Docker, and Open WebUI on Linux (Ubuntu) (5:14) (Dec 2025)](https://www.youtube.com/watch?v=TsTJVd9LciY)
* [How I deploy serverless containers for free (6:32) (Feb 2024)](https://www.youtube.com/watch?v=cw34KMPSt4k)

## Self-Hosted

* [Local AI Package Coleam00](https://github.com/coleam00/local-ai-packaged)
  * [YouTube](https://www.youtube.com/watch?v=hKrl5Gr7hM0)
* [Github: n8n Self-hosted AI starter kit](https://github.com/n8n-io/self-hosted-ai-starter-kit)
  * [Run All-in-One Local AI Infrastructure In MINUTES! (LLMs, RAG & More) (15:08) (10 Dec 2024)](https://www.youtube.com/watch?v=TIMOfVhnjQA)
  * [The ULTIMATE n8n Self-Hosting Guide (25:17) (11 Dec 2024)](https://www.youtube.com/watch?v=mhDeE5N_SWk)

## Infrastructure as Code

* [MetaFlow](https://github.com/Netflix/metaflow?tab=readme-ov-file)
* [Ansible in 100 Second (2:33) (2023)](https://www.youtube.com/watch?v=xRMPKQweySE)

## JavaScript

* [Install Node.js on Windows Subsystem for Linux (WSL2)](https://github.com/MicrosoftDocs/windows-dev-docs/blob/docs/hub/dev-environment/javascript/nodejs-on-wsl.md)

## Setup, Performance and Profiling Models

* [Gemma 3 Google AI Best Local Vision LLM Ever?! (47:41) (12 Mar 2025)](https://www.youtube.com/watch?v=rMSSuY4ppnY)
  * WebUI+Ollama, Quad RTX 3090s (see notes)
  * Enable Flash Attention: "LLAMA_FLASH_ATTENTION=1"
  * Set KV Cache Optimization Option: 'export OLLAMA_KV_CACHE_TYPE="q8_0"'
  * Start Ollama
  * Check logs to verify settings
  * NOTE: (Default?)
  * https://smcleod.net/2024/12/bringing-k/v-context-quantisation-to-ollama/
* [Modded-NanoGPT]()

## Multiple Models

* [AISuite Github](https://github.com/andrewyng/aisuite)

## AI Observability

* [LangFuse](https://github.com/langfuse/langfuse-docs/blob/main/cookbook/integration_pydantic_ai.ipynb)
* [Pydantic   logfire.dev](https://github.com/pydantic/logfire)
* [Opik](https://www.comet.com/site/products/opik/)
* [AgentBoard (24 Jan 2024)](https://github.com/hkust-nlp/AgentBoard)
  * [Paper](https://hkust-nlp.github.io/agentboard/)# MLOps

## Leaderboard

* [Huggingface Leaderboards](https://huggingface.co/open-llm-leaderboard)
* [ArtificialAnalysis.ai](https://artificialanalysis.ai/leaderboards/models)
* [Vellum Leaderboard](https://www.vellum.ai/llm-leaderboard)

## AI Libraries

* [9 Open Source Libraries to Supercharge Your Next Project (14 Nov 2024)](https://blog.gopenai.com/the-future-of-rag-will-be-with-vision-end-to-end-example-with-colpali-and-a-vision-language-model-fe133667d2f9)
Penpot
OpenAlternative
Listmonk
Supabase
Rallly
* [Pandas Is Dead. Machine Learning Teams Are Using These Tools Instead. (5 Nov 2024)](https://pub.towardsai.net/pandas-is-dead-machine-learning-teams-are-using-these-tools-instead-bc4124bb767c)
  * Polars is incredibly fast and well-suited for tasks that benefit from parallel processing.
  * DuckDB is ideal for SQL users who need a high-performance in-memory database for analytics.
  * Vaex works well with very large datasets, especially when memory is limited, although it lacks some advanced features.
  * Modin provides a user-friendly transition for those who need better performance than Pandas without altering much of their code.

## Software Engineering

* [Aurelio.ai's Semantic-Router](https://www.aurelio.ai/learn)
  * [Github](https://github.com/aurelio-labs/semantic-router)

## ACCELERATOR

* [MSI.com Afterburner](https://www.msi.com/Landing/afterburner/graphics-cards)

## JUPYTER

* [Jupyter](https://jupyter.org/install)
* [Voila](https://github.com/voila-dashboards/voila)

## VMs

* MLOps VMs
  * venv
  * Docker
  * [Huggingface Spaces](https://huggingface.co/spaces)
  * Colab
  * Kaggle
  * Github
  * Replt
  
## Cloud Services

* MLOps Local/Cloud Private LLMs
  * [ollama](https://ollama.ai)
  * [groq Cloud](https://groq.com/)
  * [cerebras.ai](https://cerebras.ai/blog/cerebras-gpt-a-family-of-open-compute-efficient-large-language-models/)
  * [runpod.io](runpod.io)

## Ollama

* [Ollama VIC UI](https://github.com/shokuninstudio/Ollama-VIC-20)
* [Ollama FAQ](https://github.com/ollama/ollama/blob/main/docs/faq.md)
* [Huggingface Models](https://huggingface.co/docs/hub/en/ollama)
* [ChatGPT Speedup](https://chatgpt.com/share/672b1ca6-57e0-800d-917c-1433383892ce)
* Ollama
  * [Ollama Python](https://github.com/ollama/ollama-python)
* Ollama in Colab
  * [Ollama on Google Colab: A Game-Changer! (15:07) (2 Jul 2024)](https://www.youtube.com/watch?v=9sPKTNGaPf8)
  * [Run Ollama Locally Using Google Colab’s Free GPU (28 Feb 2024)](https://medium.com/@neohob/run-ollama-locally-using-google-colabs-free-gpu-49543e0def31)
  * [Ollama in Colab](https://colab.research.google.com/github/jellyterra/ollama-colab/blob/master/OllamaColab.ipynb)
  * [ngrok API](https://dashboard.ngrok.com/)
  * [Ollama in Github Code Space](https://github.com/BlackTechX011/Ollama-in-GitHub-Codespaces)
* [Ollama with Vision - Enabling Multimodal RAG (13:00) (7 Oct 2024)](https://www.youtube.com/watch?v=45LJT-bt500)
* [Find Your Perfect Ollama Build (13:30) (21 Nov 2024)](https://www.youtube.com/watch?v=RFaMiQ97EoE)

## Local Alternatives

* [Run Any Local LLM Faster Than Ollama—Here's How (12:06) (5 Nov 2024)](https://www.youtube.com/watch?v=i1rvSiSpzSo)

## Docker

* [How I deploy serverless containers for free (6:32) (Feb 2024)](https://www.youtube.com/watch?v=cw34KMPSt4k)

## Self-Hosted

* [Github: n8n Self-hosted AI starter kit](https://github.com/n8n-io/self-hosted-ai-starter-kit)
  * [Run All-in-One Local AI Infrastructure In MINUTES! (LLMs, RAG & More) (15:08) (10 Dec 2024)](https://www.youtube.com/watch?v=TIMOfVhnjQA)
  * [The ULTIMATE n8n Self-Hosting Guide (25:17) (11 Dec 2024)](https://www.youtube.com/watch?v=mhDeE5N_SWk)

## Infrastructure as Code

* [Ansible in 100 Second (2:33) (2023)](https://www.youtube.com/watch?v=xRMPKQweySE)

## JavaScript

* [Install Node.js on Windows Subsystem for Linux (WSL2)](https://github.com/MicrosoftDocs/windows-dev-docs/blob/docs/hub/dev-environment/javascript/nodejs-on-wsl.md)

## Performance

* [Modded-NanoGPT]()

## Multiple Models

* [AISuite Github](https://github.com/andrewyng/aisuite)

## AI Observability

* [Pydantic logfire.dev](https://github.com/pydantic/logfire)
* [Opik](https://www.comet.com/site/products/opik/)
* [AgentBoard (24 Jan 2024)](https://github.com/hkust-nlp/AgentBoard)
  * [Paper](https://hkust-nlp.github.io/agentboard/)

## LLMOps

* [Agenta](https://github.com/Agenta-AI/agenta)