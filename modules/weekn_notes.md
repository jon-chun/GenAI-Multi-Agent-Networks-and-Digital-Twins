# Week N Notess

# Goals
* Agents
  - Knowledge
  - Tools
  - Memory
  - Guardrails
  - Metrics/Observability

* [12 Google AI Tools You Need to Know Now! (12:27) (26 Aug 2025)](https://www.youtube.com/watch?v=PO88FTIg9fE)

### Embeddings

* [Welcome EmbeddingGemma, Google's new efficient embedding model by Aarsen et al. (4 Sep 2024)](https://huggingface.co/blog/embeddinggemma)



## Key Questions to Consider

1. What are 5 levels on the way to AGI and how is each defined?
2. What are the ethical frameworks of LLMs and how can prompts explore surface them?
3. How can we ensure responsible use of AI APIs in application development?
4. How are LLM benchmarks designed and what are some key metrics?
5. How does prompt engineering affect the output of AI models accessed through APIs?
6. How might the widespread use of AI APIs impact job markets and skill requirements in tech?
7. How do benchmark performance translate to real-world performance?
8. What role does data privacy play when using AI APIs, and how can we protect user information?
9. How can we balance the benefits of AI APIs with the need for transparency and explainability?
10. What are the long-term implications of integrating AI APIs into critical systems and decision-making processes?

## Reading Assignments

* [BMAD Vibe Coding Workflow Is a Massive Level Up (24:57) (Aug 2025)](https://www.youtube.com/watch?v=Sosf8Z0T_M8)
  * [AI Dev Project Setup Prompts](https://notes.switchdimension.com/AI-Dev-Project-Setup-Prompts-18fb5b07a94380758bd6e92baa5e8c98)
  * [Gemini.google.com (new Gem)](https://gemini.google.com/gems/create)
  * [BMAD team full-stack](https://github.com/bmad-code-org/BMAD-METHOD/blob/main/dist/teams/team-fullstack.txt)

* SOTA Research (Only spend 15 min on each paper by selectiving focusing on mainpoints in Abstract, Introduction, Tables/Figures of Findings, Conclusions)
  * [Levels of AGI for Operationalizing Progress on the Path to AGI by Meredith Ringel Morris et al. (5 Jun 2024)](https://arxiv.org/pdf/2311.02462)
  * [Informed AI Regulation: Comparing the Ethical Frameworks of Leading LLM Chatbots Using an Ethics-Based Audit to Assess Moral Reasoning and Normative Values by Chun and Elkins (9 Jan 2024)](https://www.semanticscholar.org/paper/Informed-AI-Regulation%3A-Comparing-the-Ethical-of-an-Chun-Elkins/f55294c223752a7159c438951dbf6e6b66cd2e31)

* Chatbots:
  * [Prompt Engineering with Llama 2&3 (DeepLearning.ai) NOTE: Skip over ERRORS due to 70B model no longer available](https://learn.deeplearning.ai/courses/prompt-engineering-with-llama-2/lesson/1/introduction)
  * [Python Chatbot Tutorial | Using OpenAI API to Create a Smart Chatbot (5:36) Jul 2024](https://www.youtube.com/watch?v=w55C8cLWz74)  and [Github repo](https://github.com/debeshm/Python-ChatGPT/blob/main/chatbot.py)

* Benchmarks (Only spend 15 min on each paper by selectiving focusing on mainpoints in Abstract, Introduction, Tables/Figures of Findings, Conclusions)
  * Holistic Evaluation of Text-To-Image Models
    * [Website](https://crfm.stanford.edu/helm/lite/latest/)
    * [Github](https://github.com/stanford-crfm/helm)
    * [Paper (Click on the ArXxiv button)](https://www.semanticscholar.org/paper/Holistic-Evaluation-of-Language-Models-Liang-Bommasani/ce913026f693101e54d3ab9152e107034d81fce1) 
  * [BigBench-Hard](https://arxiv.org/pdf/2206.04615)

* Code Example for Miniproject #1: Voice Chatbot
  * [OpenAI ChatGPT API (NEW GPT 3.5) and Whisper API - Python and Gradio Tutorial (23:08) 2023](https://www.youtube.com/watch?v=Si0vFx_dJ5Y)

## In-Class

* Quiz: Week 3

* [Colab: llm_observability_integration_dspy_langfuse_20250909.ipynb](https://colab.research.google.com/drive/1VU6q_MpHwMZzCXA4vsN3ayYEpLezyUkD)

* Prompt Engineering
  * [Learning to Reason with LLMs (12 Sep 2024)](https://openai.com/index/learning-to-reason-with-llms/)
  * [OpenAI Reasoning Models](https://platform.openai.com/docs/guides/reasoning/advice-on-prompting?reasoning-prompt-examples=coding-planning)

* Leaderboards
  * Huggingface
    * [Huggingface Open LLM Leaderboard](https://huggingface.co/open-llm-leaderboard)
    * [Open LLM Leaderboard](https://huggingface.co/spaces/open-llm-leaderboard/open_llm_leaderboard)
  * [LMSys Chatbot Arena Leaderboard](https://huggingface.co/spaces/lmsys/chatbot-arena-leaderboard)

* Llama
  * [Llama Recipies](https://github.com/Meta-Llama/llama-recipes)

* Prompts for Chat Personas
  * [awesome-voice-prompts](https://github.com/langgptai/awesome-voice-prompts)


## Readings Humanistic

* [We must build AI for people; not to be a person Seemingly Conscious AI is Coming by Mustafa Suleyman (19 Aug 2025)](https://mustafa-suleyman.ai/seemingly-conscious-ai-is-coming)

## Readings Technical

* [The New Skill in AI is Not Prompting, It's Context Engineering by Phil Schmid (30 Jun 2025)](https://www.philschmid.de/context-engineering)
* [Breaking into AI Engineering in 2025: A roadmap that will help you up-skill or re-skill into an AI Engineer role. byAurimas Griciūnas (4 Jun 2025)](https://www.newsletter.swirlai.com/p/breaking-into-ai-engineering-in-2025?ref=dailydev)
* [12 MCP, RAG, and Agents Cheat Sheets for AI Engineers ...explained with visuals by Avi Chawla (12 Aug 2025)](https://blog.dailydoseofds.com/p/12-mcp-rag-and-agents-cheat-sheets)
* [12-Factor Agents: Patterns of reliable LLM applications — Dex Horthy, HumanLayer (17:05) (3 Jul 2025)](https://www.youtube.com/watch?v=8kMaTybvDUw)
* [Gartner: How to Choose the Right Architecture to Build AI Agents (5 Jun 2025)](https://www.gartner.com/doc/reprints?id=1-2LTE5OVS&ct=250904&st=sb)

## Readings Code

* [Deeplearning.ai: DSPy: Build and Optimize Agentic Apps](https://learn.deeplearning.ai/courses/dspy-build-optimize-agentic-apps/lesson/wwje4/debug-your-dspy-agent-with-mlflow-tracing)
  * [DSPy Docs](https://dspy.ai/)

* [Github: Langfuse](https://github.com/langfuse/langfuse)
* [Colab: Langfuse](https://colab.research.google.com/drive/1KFKG5JShFYzKv3TK2y47SX5sQWUwWkns?usp=sharing)
* [Colab: DSPy + Langfuse](https://colab.research.google.com/drive/1VU6q_MpHwMZzCXA4vsN3ayYEpLezyUkD?usp=sharing)

* [Github: YT AI Bootcamp](https://github.com/curiousily/AI-Bootcamp)

## Prompts

* [Google Vertex Studio with AI](https://console.cloud.google.com/vertex-ai/studio/prompt-gallery)

## Python

* [10 Standard Library Modules That Make Python Insanely Powerful by ArjanCodes (15:38) (5 Sep 2025)](https://www.youtube.com/watch?v=eZ9RqnkJxsk)

## AI Dev Subscriptions

* [GLM Coding Plan V/S Claude Code & Codex: IS THIS THE BEST & CHEAPEST Plan for AI Coding! (10:00) (7 Sep 2025)](https://www.youtube.com/watch?v=BN8LEcEXTZE)

## Tool Directories

* [Github Explore/Trending](https://github.com/explore)
* [TrendShift](https://trendshift.io/)
* [EliateAI.tools](https://eliteai.tools/tag)

## Low/No Code

* [NotebookLM](https://notebooklm.google/)

## IDE
 
### Visual
* [VSCode]()
* [warp](https://www.warp.dev/)

### CLI

* [Claude Code]()
* [OpenCode Agent (22.3k)](https://github.com/sst/opencode)
  - [15 Minutes to Fix Your AI Dev Workflow with OpenCode (14:29) (18 Aug 2025)](https://www.youtube.com/watch?v=EOIzFMdmox8)

## SWE

* [12 Logging BEST Practices in 12 minutes (12:00) (Jan 2025)](https://www.youtube.com/watch?v=I2mWnh66Bkg)

## DevOps

* [Claude.ai Setup New MacBook Pro laptop for AI Development](https://claude.ai/public/artifacts/cba8375c-15f3-4e21-b8a8-f831230d28eb)
* [The BEST Way to Manage Versions of Node, Python, Go (and Much More...) (6:12) (1 Sep 2025)](https://www.youtube.com/watch?v=eKJCnc0t8V0)
* [asdf]()

## MCP

## Tools

### Websearch

* [Tavily](https://www.tavily.com/)
  - [Tavily Playground](https://app.tavily.com/playground)
  - [Tavily Use-Cases](https://app.tavily.com/use-cases)
* [DuckDuckGo]()

## MCP

## A2A


## AI Coders


## NOTES:

[Some Lessons Learned Building LLM-powered Agents (22 Feb 2024)](https://mg.dev/lessons-learned-building-ai-agents/)
In no particular order:

* Keep goals simple. If you're building goal-directed agents, it's tempting to model a hierarchy of different types of goals: a high level persona, that persona's overall directive, the current high-level goal, the current low-level goal (task), and that low-level goal's sub-goals (subtasks). Simplify, simplify, simplify. If you're going for a relatively straightforward request/reply style interaction, stick with a persona + task tree. If you're going for something self-directed, where the agent can choose a course of action without direct user input... think very carefully about whether you need this or not. It's doable, it's just more complicated than you think.
* Limit LLM-driven planning to the simplest of unit of work. LLM-driven planning is when you give the LLM a task and a chest of tools, and ask it to come back with the optimal plan to fulfill the task using only those tools. This works great for things with well-defined inputs, well-defined outputs, and a limited set of intermediary steps with simple inputs/outputs. But even GPT-4 has a rough time constructing long chains of work, unless you're willing to do stepwise planning (e.g., re-plan and course-correct mid-execution).
* Use code when you can. For example, don't use LLMs for open-ended planning and execution when using a workflow engine will do. If you don't NEED dynamic planning, don't make it the central coordinating component in your agent. Even if you NEED dynamic planning, check out things like Goal Oriented Action Planning (GOAP), which will give you much more deterministic results if you're mostly dealing with a closed set of actions and tightly constrained tools.
* LLMs are harsh critics. One approach I recently explored is a "panel of experts"—essentially multiple goal-directed agents collaborating to achieve a larger goal. In one configuration, one one agent is tasked with critiquing another agent's output (requesting changes) before returning an answer to the user. Converging on an answer is a crap shoot. Rather than let them argue forever, it's better to cap the number of loops and/or have the critiquing agent 'score' the reply, and allow answers with an adequately high score.
* RAG + Tools are still your best bet for improving quality. Is your agent failing at basic math? Give it a calculator. Is your agent failing at fixing code? Give it a live environment to evaluate code in, and make it loop until it figures it out. Is your agent making stuff up? Ground its output in real search results. For the most part, I think fine-tuning is mostly useful for effecting more superficial elements of the output—style, tone, format, etc. It's not especially useful for introducing new knowledge.
* The more your agent understands its environment, the better decisions it will make. This needs to dynamically update as it makes progress on its goals.
* LLMs are slow, but they're getting fast quickly. At some point, maybe we'll be able to ignore #5. Groq recently announced 500+ tokens/sec for Mixtral 8x7B-32k, a model competitive with GPT-3.5. Faster and cheaper inferences means being able to use them for things like critical path stepwise planning, multifaceted self-reflection, multi-agent interaction, etc.
* Agents are fun, but chat interfaces are dumb. IMO the best uses of LLMs (and LLM agents) are the ones where you don't know for sure if an LLM is being used. It just seems "magical." Chat is not magical; it's a lowest-common-denominator integration. It's slow to provide input, slow to provide output, slow to read output. It takes you out of a workflow that could be done with a few button clicks, instead forcing your user to read a bunch of text. Do the product and design work necessary to find the best expression of the effect you're hoping to achieve.

* At some point, your prompts start to resemble code. LLM output changes dramatically with even subtle changes to the prompt. Get very good at specifying the outcome you want. Turns out, all those programming skills are useful for something after all!
* Really, the name of the game is context management. Personas, RAG, tool selection, environment updates, chains of thought, hidden dialog, shared dialog... these all need to fit in the context. Even in the future when we have many-million token contexts, you'll still want to dynamically substitute bits of the context based on the current environment/state, IMO. (I prefer this approach to simply stacking new frames to an ever-growing context.) On one hand, having one giant text input provides the ultimate flexibility when designing your prompting strategy. On the other, having one giant text input also means you're operating in a wild west while creating that strategy.




* [Best AI coding Agents with some crazy upsets | GPT 5, Grok Code Fast, Claude, Qwen 3 Coder (25:12) (2 Sep 2025)](https://www.youtube.com/watch?v=bp5TNTl3bZM)

* [AGENTS.md](https://agents.md/)
  - [AGENTS.md Explained: One File to Rule All Agents (3:09) (20 Aug 2025)](https://www.youtube.com/watch?v=TC7dK0gwgg0)
  - [Finally! A Standard for AI Coding Agents (Agents.md Explained) (12:02) (Aug 2025)](https://www.youtube.com/watch?v=XDP94mYMCzA)

* [I Reverse-Engineered Claude Code: Learn These Agent Tricks (20:41) (7 Aug 2025)](https://www.youtube.com/watch?v=i0P56Pm1Q3U)
  
## Prompt Examples

* [Google Vertex](https://console.cloud.google.com/vertex-ai/studio/prompt-gallery?project=gen-lang-client-0588482685)
* [Claude Dev Prompt](https://www.youtube.com/watch?v=i0P56Pm1Q3U)
  - [Git Gist](https://gist.github.com/yifanzz/e60df46ea246de750617105ca56524c1?utm_source=beyondthehype.dev&utm_medium=newsletter&utm_campaign=you-re-in-here-s-your-bonus-bth-starter-pack)

## Prompt Engineering

* [MS Prompt Orchestration Markup Language (POML) (4:49) (Jun 2025)](https://www.youtube.com/watch?v=b9WDcFsKixo)
  * [Microsoft's Secret Tool for PERFECT AI Prompts (7:25) (6 Sep 2025)](https://www.youtube.com/watch?v=tfOwh6YCY8M)

## Benchmarking

* [DeepEval](https://github.com/confident-ai/deepeval)

## Orchestration and Observability

* [LangSmith]()
* [WandB]()

## Context Engineering/Spec Driven Dev (SDD)

* [Github spec-kit](https://github.com/github/spec-kit)
  - [Spec-kit Blog](https://github.blog/ai-and-ml/generative-ai/spec-driven-development-with-ai-get-started-with-a-new-open-source-toolkit/)
  - [Spec-kit Docs]()
  
* I kinda do the exact same thing without needing to add this... i put the copilot in Ask mode and start a "conversation" as if it was a person. Usually i start like "you are in ask mode, no need to code by now, we will only discuss some steps". After any amount of iterations, after i reached the point where it is where I want to go, I create a mardown file with some naming convention like "plan-xxx", where is the plan to whatever has been discussed and another markdown file "flow-xxx"  where it has a mermaid flow to achieve whatever the plan has, then I ask to copilot like "now you are in agent mode,  in the file #plan-xxx make a detailed plan to what we were discussing so far regarding the matter xxx with checkboxes so we can follow along and not get lost and to know where we are and to where we need to to. And also create a mermaid flow in the #flow-xxx so we can follow along." . works 100% of the time... and this i apply for literally anything.... implementations, refactors, doubts, ideas and pretty much everything else... try this anytime and you will make the copilot a real copilot to your workflow =)

* [BMAD]()
* [Spec Kit: Github's NEW tool That FINALLY Fixes AI Coding (10:32) (6 Sep 2025)](https://www.youtube.com/watch?v=em3vIT9aUsg)
  - /specify: what/why user journeys/outcomes
  - /plan: architecture/constraints
  - /tasks: decomposition of tasks/plan
  - implement: verify/control at each step/task
* [Amazon's NEW AI IDE is Actually Different (in a good way!) – Kiro (10:42) (Aug 2025)](https://www.youtube.com/watch?v=Z9fUPyowRLI)


* [12-Factor Agents: Patterns of reliable LLM applications — Dex Horthy, HumanLayer (17:05) (Jul 2025)](https://www.youtube.com/watch?v=8kMaTybvDUw)

## RAG

* [RAG Agents in Prod: 10 Lessons We Learned — Douwe Kiela, creator of RAG (16:55) (May 2025)](https://www.youtube.com/watch?v=kPL-6-9MVyA)

## AI Apps

* [Arindam200/awesome-ai-apps (4.9k)](https://github.com/Arindam200/awesome-ai-apps)
  - [arXiv Researcher Agent Demo with OpenAI Agents & Memori](https://github.com/Arindam200/awesome-ai-apps/tree/main/simple_ai_agents/arxiv_researcher_agent_with_memori)

## UI/UX Wireframes

* [figma]()
* [excalidraw]()
* [draw.io]()

## UI/Mobile

* [Google Labs Stitch](https://stitch.withgoogle.com/)
* [Anything](https://www.createanything.com/)

## Claude

* [Claude Cookbook](https://github.com/anthropics/anthropic-cookbook?ref=dailydev)

## n8n

* [Self-hosted AI Starter Kit is an open-source template that quickly sets up a local AI environment (12.3k)](https://github.com/n8n-io/self-hosted-ai-starter-kit)

## PydanticAI
* [PydanticAI: the AI Agent Framework Winner (15:29) (29 Aug 2025)](https://www.youtube.com/watch?v=-WB0T0XmDrY)










* [LangChain and Ollama: Build Your Personal Coding Assistant in 10 Minutes (20:42) (28 Sep 2024)](https://www.youtube.com/watch?v=fOUng7fMQ1Y)https://github.com/aidev9/tuts/tree/main/langchain-ollama


* [Terminator 3 Skynet Takes Over (4:21) (Terminator 2)](https://www.youtube.com/watch?v=_Wlsd9mljiU)
* [Alien Covenant : David Teach Walter to use Flute (3:44) (Alien Covenant)](https://www.youtube.com/watch?v=skppRyDy2Ng)
* [Alien: Covenant David tells Walter the truth/David kisses Walter (3:28) (Alien Covenant)](https://www.youtube.com/watch?v=G8DueZFJVyo)

https://www.ark-invest.com/articles/analyst-research/how-ark-is-thinking-about-humanoid-robotics
https://gamma.app/docs/a16z-Consumer-Abundance-Agenda-ieotbnzbxj81biu?mode=doc
https://thezvi.substack.com/p/on-the-ubi-paper
https://futureoflife.org/resource/catastrophic-ai-scenarios/
$157B OpenAIhttps://news.ycombinator.com/item?id=41722742
AGIhttps://news.ycombinator.com/item?id=41689558
AI Hypehttps://news.ycombinator.com/item?id=41691943https://www.wheresyoured.at/oai-business/
Solarhttps://reneweconomy.com.au/solar-and-wind-less-than-half-the-cost-of-fossil-fuels-as-price-falls-continue/
UBIhttps://www.scottsantens.com/did-sam-altman-basic-income-experiment-succeed-or-fail-ubi/
NotebookLMhttps://github.com/gormlabenz/topcast
SB 1047 Veto
https://www.gov.ca.gov/wp-content/uploads/2024/09/SB-1047-Veto-Message.pdfhttps://calmatters.org/economy/2024/09/california-artificial-intelligence-bill-veto/

* [Elon Musk - Where AI's Biggest Impact Will Be (15:12) (Sep 2024)](https://www.youtube.com/watch?v=C22VEGVL1oQ)
* [OpenAI’s new “deep-thinking” o1 model crushes coding benchmarks (5:47) (Sep 2024)](https://www.youtube.com/watch?v=6xlPJiNpCVw&t=12s)
* [Top 10 NEW Humanoid Robots of 2024 (Updated) (16:43) (30 Sep 2024)](https://www.youtube.com/watch?v=gTSFBFmRJVs)
* [US sanctions against China are putting global firms to a decision: abandon China, or leave the US (7:03) (Sep 2024)](https://www.youtube.com/watch?v=ZNzixbMiZMQ)
* [7:01 / 1:02:18 Keynote - Ten Key Questions that a Company Should Ask to have Responsible AI (1:02:00) (2 Oct 2024)](Keynote - Ten Key Questions that a Company Should Ask to have Responsible AI)

## Agent Orchestration

* [khaoss85/ai-team-orchestrator](https://github.com/khaoss85/ai-team-orchestrator)
  - [Online Book](https://books.danielepelleri.com/en/ai-team-orchestrator.html)


## Extract Structured Information

* [Long Document Content Extraction by Jarvis (19 Feb 2023) (OpenAI Cookbook) ](https://cookbook.openai.com/examples/entity_extraction_for_long_documents)
  * [Github](https://github.com/lbnlp/NERRE)
* [Structured information extraction from scientific text with large language models by Dagdelen et al. (Feb 2024) (Nature)](https://www.nature.com/articles/s41467-024-45563-x)
  * [Colab](https://colab.research.google.com/github/openai/openai-cookbook/blob/main/examples/Entity_extraction_for_long_documents.ipynb)